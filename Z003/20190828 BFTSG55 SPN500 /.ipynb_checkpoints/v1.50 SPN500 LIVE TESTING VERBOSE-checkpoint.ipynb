{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearall():\n",
    "    all = [var for var in globals() if var[0] != \"_\"]\n",
    "    for var in all:\n",
    "        del globals()[var]\n",
    "clearall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Librairies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies imported\n",
      "\n",
      "Global Optimized LumberJack Environment Motor 55\n",
      "LumberJack Jyss 5779(c)\n",
      "\u001b[34m °0Oo_D.A.G._26_oO0°\n",
      "\u001b[33m \u001b[44m BOOST LIVE SPN500 55 Version v1.50 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Importing Librairies...')\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from colorama import Fore, Back, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yaml\n",
    "from keras.models import model_from_yaml\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,roc_curve,confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print('Librairies imported')\n",
    "print('')\n",
    "\n",
    "___Author___='LumberJack Jyss'\n",
    "print('Global Optimized LumberJack Environment Motor 55\\nLumberJack Jyss 5779(c)')\n",
    "print(Fore.BLUE,'°0Oo_D.A.G._26_oO0°')\n",
    "print(Fore.YELLOW,Back.BLUE,'BOOST LIVE SPN500 55 Version v1.50',Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(dt.date.today())[0:4]+'_'+str(dt.date.today())[5:7]+'_'+str(dt.date.today())[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sraping tickers\n",
      "Scrap -----> ok \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "print('Sraping tickers')\n",
    "constituents_csv = os.path.abspath('constituents_csv.csv')\n",
    "constituents = pd.read_csv(constituents_csv)\n",
    "print('Scrap -----> ok \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml.warnings({'YAMLLoadWarning': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker,'yahoo',start,end)\n",
    "    df = df.drop(['Close'],axis=1)\n",
    "    df['Close'] = df['Adj Close']\n",
    "    df = df.drop(['Adj Close'],axis = 1)    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost(df):\n",
    "    print('Boosting')\n",
    "    X = df\n",
    "    X = X.drop(['Close'],axis=1)\n",
    "    X['Close'] = df['Close']\n",
    "    y = X.iloc[:,-1]\n",
    "    Xtrain = X.iloc[:-2,:-1]\n",
    "    Xtest = X.iloc[-2:-1,:-1]\n",
    "    yshift = y.shift(-1)\n",
    "    ytrain = yshift.iloc[:-2]\n",
    "    ytest = yshift.iloc[-2:-1]\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=20000, objective='reg:squarederror',learning_rate=1, gamma=1, subsample=1, colsample_bytree=1, max_depth=100)\n",
    "\n",
    "    model.fit( Xtrain, ytrain, early_stopping_rounds=150, eval_set=[(Xtest, ytest)], verbose=0)\n",
    "\n",
    "    ytrain_pred = model.predict(Xtrain)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "\n",
    "    pred = model.predict(X.iloc[:,:-1])\n",
    "\n",
    "    df['Close.S'] = pred\n",
    "    df['Close.S2'] = df['Close.S']\n",
    "    df = df.dropna()\n",
    "    print('Boost ok')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepa_data(df):\n",
    "    rsi = talib.RSI(df['Close'],timeperiod=14)\n",
    "    stoc_slowk, stoc_slowd = talib.STOCH(df['High'],df['Low'],df['Close'])\n",
    "    upper, middle, lower =  talib.BBANDS(df['Close'], timeperiod=9, nbdevup=2, nbdevdn=2,matype=0)\n",
    "    sma5 = talib.SMA(df['Close'],timeperiod=5)\n",
    "    sma8 = talib.SMA(df['Close'],timeperiod=8)\n",
    "    sma10 = talib.SMA(df['Close'],timeperiod=10)\n",
    "    sma12 = talib.SMA(df['Close'],timeperiod=12)\n",
    "    sma15 = talib.SMA(df['Close'],timeperiod=15)\n",
    "    sma30 = talib.SMA(df['Close'],timeperiod=30)\n",
    "    sma35 = talib.SMA(df['Close'],timeperiod=35)\n",
    "    sma40 = talib.SMA(df['Close'],timeperiod=40)\n",
    "    sma45 = talib.SMA(df['Close'],timeperiod=45)\n",
    "    sma50 = talib.SMA(df['Close'],timeperiod=50)\n",
    "    atr = talib.ATR(df['High'],df['Low'],df['Close'],timeperiod=10)\n",
    "    delta5_8 = sma5 - sma8\n",
    "    delta8_10 = sma8 - sma10\n",
    "    delta10_12 = sma10 - sma12\n",
    "    delta12_15 = sma12 - sma15\n",
    "    delta15_30 = sma15 - sma30\n",
    "    delta30_35 = sma30 - sma35\n",
    "    delta35_40 = sma35 - sma40\n",
    "    delta40_45 = sma40 - sma45\n",
    "    delta45_50 = sma45 - sma50\n",
    "    bbdelta = upper - middle\n",
    "    price_bolup = df['Close'] - lower\n",
    "    price_bolow = df['Close'] - upper\n",
    "    Ema = talib.EMA(df['Close'],timeperiod=20)\n",
    "    KC_High = Ema + 2*atr\n",
    "    KC_Low = Ema - 2*atr\n",
    "    aroondown, aroonup = talib.AROON(df['High'], df['Low'], timeperiod=9)\n",
    "    aroon = aroonup - aroondown #(aroonup-aroondown)/abs((aroonup-aroondown))\n",
    "    rsi30_list = []\n",
    "    rsi70_list = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        rsi70_list.append(70 - rsi[i])\n",
    "        rsi30_list.append(rsi[i] - 30)\n",
    "        #except:\n",
    "         #   rsi70_list.append(0)\n",
    "          #  rs30_list.append(0)\n",
    "    varop_spy = df['Open'] - df['Close']\n",
    "    varhl_spy = df['High'] - df['Low']\n",
    "    df['Varop_Spy'] = varop_spy\n",
    "    df['Varhl_spy'] = varhl_spy\n",
    "    df['RSI'] = rsi\n",
    "    df['70 - RSI'] = np.array(rsi70_list)\n",
    "    df['RSI - 30'] = np.array(rsi30_list)\n",
    "    df['BBD_Delta_Up'] = bbdelta\n",
    "    df['delta5_8'] = delta5_8\n",
    "    df['delta8_10'] = delta8_10\n",
    "    df['delta10_12'] = delta10_12\n",
    "    df['delta12_15'] = delta12_15\n",
    "    df['delta15_30'] = delta15_30\n",
    "    df['delta30_35'] = delta30_35\n",
    "    df['delta35_40'] = delta35_40\n",
    "    df['delta40_45'] = delta40_45\n",
    "    df['delta45_50'] = delta45_50\n",
    "    df['Stoc_Slowk'] = stoc_slowk\n",
    "    df['Stoc_Slowd'] = stoc_slowd\n",
    "    df['KC_High'] = KC_High\n",
    "    df['KC_Low'] = KC_Low\n",
    "    df['upper'] = upper\n",
    "    df['lower'] = lower\n",
    "    df['var_bollup_kchigh'] = upper-KC_High\n",
    "    df['var_bolllow_kclow'] = lower-KC_Low\n",
    "    df['Aroon Up'] = aroonup\n",
    "    df['Aroon Down'] = aroondown\n",
    "    df['Delta Aroon'] = aroon\n",
    "    up = []\n",
    "    down = []\n",
    "    df = df.dropna()\n",
    "    df = boost(df)\n",
    "    df['%Futur'] = ((df['Close.S']-df['Close']) *100) / (df['Close'])\n",
    "    df['%Futur2'] = ((df['Close.S2']-df['Close']) *100) / (df['Close'])\n",
    "    for i in range(0,df.shape[0]-5):\n",
    "        if df.iloc[i]['%Futur'] > 0.1 :#or df.iloc[i]['%Futur2'] > 0.1:\n",
    "            up.append(1)\n",
    "            down.append(0)\n",
    "        elif df.iloc[i]['%Futur'] < -0.1: #or df.iloc[i]['%Futur2'] < -0.1:\n",
    "            up.append(0)\n",
    "            down.append(1)\n",
    "        else:\n",
    "            up.append(0)\n",
    "            down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    \n",
    "    \n",
    "    df['target_up'] = up  # target_up # abs(np.array(valley))#target_up\n",
    "    df['target_down'] = down # target_down # abs(np.array(peak))#target_down\n",
    "    #df = df.dropna()\n",
    "    tmps2=round(time.time()-tmps1,2)\n",
    "    print (\"Data prepared in = %f\" %tmps2,'seconds')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learning(df):\n",
    "    tmps1=time.time()\n",
    "    X = df.iloc[:,1:-4]\n",
    "    X.astype(np.float64)\n",
    "    y_up = df.iloc[:,-2].values\n",
    "    y_down = df.iloc[:,-1].values\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    y_up = np.array(y_up).reshape(-1,1)\n",
    "    y_down = np.array(y_down).reshape(-1,1)\n",
    "\n",
    "    Xtrain = X[:bloc1,:]\n",
    "    Xtest = X[bloc1:,:]\n",
    "    ytrain_up = y_up[:bloc1,:]\n",
    "    ytest_up = y_up[bloc1:,:]\n",
    "    ytrain_down = y_down[:bloc1,:]\n",
    "    ytest_down = y_down[bloc1:,:]\n",
    "\n",
    "    seed = 770\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ytrain_up = ytrain_up.reshape(ytrain_up.shape[0],)\n",
    "    ytrain_down = ytrain_down.reshape(ytrain_down.shape[0],)\n",
    "\n",
    "    Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1])\n",
    "\n",
    "    yhat_up = model_up.predict_classes(Xtest)\n",
    "    yhat_down = model_down.predict_classes(Xtest)\n",
    "\n",
    "    predict_up = model_up.predict(Xtest)\n",
    "    predict_down = model_down.predict(Xtest)\n",
    "\n",
    "    accuracy_up = accuracy_score(ytest_up, yhat_up)\n",
    "    accuracy_down = accuracy_score(ytest_down, yhat_down)\n",
    "\n",
    "    # La précision permet de mesurer la capacité du modèle à refuser résultats non-pertinents : vrais_positifs/(vrais_positifs+faux_positifs)\n",
    "    precision_up = precision_score(ytest_up, yhat_up)  \n",
    "    precision_down = precision_score(ytest_down, yhat_down) \n",
    "\n",
    "\n",
    "    # Recall : (vrai_positifs/(vrais_positifs+faux_négatifs))\n",
    "    recall_up = recall_score(ytest_up, yhat_up) \n",
    "    recall_down = recall_score(ytest_down, yhat_down) \n",
    "\n",
    "\n",
    "    #roc_up=roc_auc_score(ytest_up,yhat_up)\n",
    "    #roc_down=roc_auc_score(ytest_down,yhat_down)\n",
    "    print('\\n')\n",
    "    print(Fore.GREEN,'RESULTATS UP\\n',Style.RESET_ALL)\n",
    "    print('Accuracy: %.2f%%' % (accuracy_up * 100.0))\n",
    "    print(Fore.BLUE,\"Precision: %.2f%% \" % (precision_up *100),Style.RESET_ALL,' => Discrimnination des vrais positifs parmi les faux positifs')\n",
    "    print(\"Recall: %.2f%% \" % (recall_up * 100),' => Positifs trouvés par Golem sur tous les positifs existants')\n",
    "    #print(\"ROC: %.2f%% \" % (roc_up *100))\n",
    "    # get probabilities for positive class\n",
    "\n",
    "    print(classification_report(ytest_up, yhat_up))\n",
    "    conf_matrix = pd.DataFrame(index = ['vrais_réels','Faux_réels'])\n",
    "    conf_matrix['Vrais_estimés'] = ['Vrais_positifs','Faux_positifs']\n",
    "    conf_matrix['Faux_estimés'] = ['Faux_négatif','Vrais-négatifs']\n",
    "    print(confusion_matrix(ytest_up, yhat_up))\n",
    "\n",
    "    print('\\n')\n",
    "    print('_______________________________________________________________________________________________________________________________________________________________\\n')\n",
    "    print(Fore.RED,'RESULTATS DOWN\\n',Style.RESET_ALL)\n",
    "    print('Accuracy: %.2f%%' % (accuracy_down * 100.0))\n",
    "    print(Fore.BLUE,\"Precision: %.2f%% \" % (precision_down *100),Style.RESET_ALL,' => Discrimnination des vrais positifs parmi les faux positifs')\n",
    "    print(\"Recall: %.2f%% \" % (recall_down * 100),' => Positifs trouvés par Golem sur tous les positifs existants')\n",
    "    #print(\"ROC: %.2f%% \" % (roc_down *100))\n",
    "    # get probabilities for positive class\n",
    "\n",
    "    print(classification_report(ytest_down, yhat_down))\n",
    "    conf_matrix = pd.DataFrame(index = ['vrais_réels','Faux_réels'])\n",
    "    conf_matrix['Vrais_estimés'] = ['Vrais_positifs','Faux_positifs']\n",
    "    conf_matrix['Faux_estimés'] = ['Faux_négatif','Vrais-négatifs']\n",
    "    print(confusion_matrix(ytest_down, yhat_down))\n",
    "    print('\\n')\n",
    "\n",
    "    resultats = pd.DataFrame()\n",
    "    resultats['Date'] = df.index[bloc1:]\n",
    "    resultats.index= df.index[bloc1:]\n",
    "    resultats['Move Up'] = yhat_up\n",
    "    resultats['Confiance up'] = (predict_up)*100\n",
    "    resultats['Move Down'] = yhat_down\n",
    "    resultats['Confiance Down'] = (predict_down)*100\n",
    "    resultats['Actual'] = df.iloc[bloc1:]['Close']\n",
    "    resultats['Actual.S'] = df.iloc[bloc1:]['Close.S']\n",
    "    open_S = df['Open'].shift(-1)\n",
    "    resultats['Open.S'] = open_S.iloc[bloc1:]\n",
    "    dmp_cp=[]\n",
    "    dmp_cp = ((resultats['Confiance up']-resultats['Confiance Down'])/(resultats['Confiance up']+resultats['Confiance Down'])*100)\n",
    "    resultats['DMP_CP'] = dmp_cp\n",
    "    tmps2=round(time.time()-tmps1,2)\n",
    "    print (\"Deep Learning executed in = %f\" %tmps2,'seconds')\n",
    "    #resultats.set_index('Date',inplace=True)\n",
    "    #parse_dates=resultats['Date']\n",
    "    return(resultats,precision_up,precision_down,scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grobeta(df,dfb):\n",
    "    # create a time-series of monthly data points\n",
    "    rts = df.resample('M').last()\n",
    "    rbts = dfb.resample('M').last()\n",
    "    dfsm = pd.DataFrame({'s_adjclose' : rts['Close'],\n",
    "                            'b_adjclose' : rbts['Adj Close']},\n",
    "                            index=rts.index)\n",
    "\n",
    "    # compute returns\n",
    "    dfsm[['s_returns','b_returns']] = dfsm[['s_adjclose','b_adjclose']]/\\\n",
    "        dfsm[['s_adjclose','b_adjclose']].shift(1) -1\n",
    "    dfsm = dfsm.dropna()\n",
    "    covmat = np.cov(dfsm[\"s_returns\"],dfsm[\"b_returns\"])\n",
    "\n",
    "    # calculate measures now\n",
    "    beta = covmat[0,1]/covmat[1,1]\n",
    "    alpha= np.mean(dfsm[\"s_returns\"])-beta*np.mean(dfsm[\"b_returns\"])\n",
    "\n",
    "    # r_squared     = 1. - SS_res/SS_tot\n",
    "    ypred = alpha + beta * dfsm[\"b_returns\"]\n",
    "    SS_res = np.sum(np.power(ypred-dfsm[\"s_returns\"],2))\n",
    "    SS_tot = covmat[0,0]*(len(dfsm)-1) # SS_tot is sample_variance*(n-1)\n",
    "    r_squared = 1. - SS_res/SS_tot\n",
    "    # 5- year volatiity and 1-year momentum\n",
    "    volatility = np.sqrt(covmat[0,0])\n",
    "    momentum = np.prod(1+dfsm[\"s_returns\"].tail(12).values) -1\n",
    "\n",
    "    # annualize the numbers\n",
    "    prd = 12. # used monthly returns; 12 periods to annualize\n",
    "    alpha = alpha*prd\n",
    "    volatility = volatility*np.sqrt(prd)\n",
    "\n",
    "    print ('Beta : ',beta,'\\n Alpha : ',alpha,'\\n R_Squared : ', r_squared, '\\n Volatility : ', volatility, '\\n Momentum : ',momentum)\n",
    "    return(beta,alpha,r_squared,volatility,momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 12:31:59.463621 4556219840 deprecation_wrapper.py:119] From /Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0828 12:31:59.478810 4556219840 deprecation_wrapper.py:119] From /Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0828 12:31:59.637686 4556219840 deprecation_wrapper.py:119] From /Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0828 12:31:59.638576 4556219840 deprecation_wrapper.py:119] From /Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0828 12:31:59.639623 4556219840 deprecation_wrapper.py:119] From /Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Loop : 0  ---  --- Symbol :  \u001b[33m MMM \u001b[0m  ---  --- Name :  3M Company  ---  --- Sector :  Industrials  --- \n",
      "Models loaded from disk in = 0.270000 seconds \n",
      "\n",
      "Scraping Candle of  MMM  \n",
      "\n",
      "GOLEM begins Computing...\n",
      "\n",
      "\n",
      "# of periods :  764\n",
      "On 80% - 20% slash : \n",
      "Bloc 1 :  611 \n",
      "Bloc 2 : 153  periods \n",
      "First period : 2016-08-15 00:00:00\n",
      "Split period : 2019-01-17 00:00:00\n",
      "Last period : 2019-08-27 00:00:00\n",
      "\n",
      "\n",
      "Beta :  1.3036811401294748 \n",
      " Alpha :  -0.1269036020818121 \n",
      " R_Squared :  0.5265274009390246 \n",
      " Volatility :  0.22234976613985105 \n",
      " Momentum :  -0.2380714082623968\n",
      "Last candle scraped from Yahoo! Finance in = 2.000000 seconds \n",
      "\n",
      "Preparing data of  MMM  \n",
      "\n",
      "Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost ok\n",
      "Data prepared in = 2.160000 seconds\n",
      "Data prepared in = 2.160000 seconds \n",
      "\n",
      "Applying Deep Learning data of  MMM  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32m RESULTATS UP\n",
      " \u001b[0m\n",
      "Accuracy: 65.38%\n",
      "\u001b[34m Precision: 54.55%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 60.00%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71        64\n",
      "           1       0.55      0.60      0.57        40\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       104\n",
      "   macro avg       0.64      0.64      0.64       104\n",
      "weighted avg       0.66      0.65      0.66       104\n",
      "\n",
      "[[44 20]\n",
      " [16 24]]\n",
      "\n",
      "\n",
      "_______________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "\u001b[31m RESULTATS DOWN\n",
      " \u001b[0m\n",
      "Accuracy: 68.27%\n",
      "\u001b[34m Precision: 64.91%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 74.00%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67        54\n",
      "           1       0.65      0.74      0.69        50\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       104\n",
      "   macro avg       0.69      0.68      0.68       104\n",
      "weighted avg       0.69      0.68      0.68       104\n",
      "\n",
      "[[34 20]\n",
      " [13 37]]\n",
      "\n",
      "\n",
      "Deep Learning executed in = 0.070000 seconds\n",
      "Deep learned in = 0.070000 seconds \n",
      "\n",
      "\n",
      " \u001b[30m \u001b[43m  Test de precision pour  MMM  non passé. \u001b[0m\n",
      " --- Loop : 1  ---  --- Symbol :  \u001b[33m AOS \u001b[0m  ---  --- Name :  A.O. Smith Corp  ---  --- Sector :  Industrials  --- \n",
      "Models loaded from disk in = 0.170000 seconds \n",
      "\n",
      "Scraping Candle of  AOS  \n",
      "\n",
      "GOLEM begins Computing...\n",
      "\n",
      "\n",
      "# of periods :  764\n",
      "On 80% - 20% slash : \n",
      "Bloc 1 :  611 \n",
      "Bloc 2 : 153  periods \n",
      "First period : 2016-08-15 00:00:00\n",
      "Split period : 2019-01-17 00:00:00\n",
      "Last period : 2019-08-27 00:00:00\n",
      "\n",
      "\n",
      "Beta :  1.642560584328999 \n",
      " Alpha :  -0.1453432277382387 \n",
      " R_Squared :  0.6180261465553324 \n",
      " Volatility :  0.2585792999668512 \n",
      " Momentum :  -0.21962557683142625\n",
      "Last candle scraped from Yahoo! Finance in = 2.090000 seconds \n",
      "\n",
      "Preparing data of  AOS  \n",
      "\n",
      "Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost ok\n",
      "Data prepared in = 2.040000 seconds\n",
      "Data prepared in = 2.040000 seconds \n",
      "\n",
      "Applying Deep Learning data of  AOS  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32m RESULTATS UP\n",
      " \u001b[0m\n",
      "Accuracy: 68.27%\n",
      "\u001b[34m Precision: 78.57%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 26.83%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.78        63\n",
      "           1       0.79      0.27      0.40        41\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       104\n",
      "   macro avg       0.73      0.61      0.59       104\n",
      "weighted avg       0.71      0.68      0.63       104\n",
      "\n",
      "[[60  3]\n",
      " [30 11]]\n",
      "\n",
      "\n",
      "_______________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "\u001b[31m RESULTATS DOWN\n",
      " \u001b[0m\n",
      "Accuracy: 59.62%\n",
      "\u001b[34m Precision: 56.52%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 96.30%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.20      0.32        50\n",
      "           1       0.57      0.96      0.71        54\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       104\n",
      "   macro avg       0.70      0.58      0.52       104\n",
      "weighted avg       0.69      0.60      0.52       104\n",
      "\n",
      "[[10 40]\n",
      " [ 2 52]]\n",
      "\n",
      "\n",
      "Deep Learning executed in = 0.050000 seconds\n",
      "Deep learned in = 0.060000 seconds \n",
      "\n",
      "\n",
      " \u001b[30m \u001b[43m  Test de precision pour  AOS  non passé. \u001b[0m\n",
      " --- Loop : 2  ---  --- Symbol :  \u001b[33m ABT \u001b[0m  ---  --- Name :  Abbott Laboratories  ---  --- Sector :  Health Care  --- \n",
      "Models loaded from disk in = 0.190000 seconds \n",
      "\n",
      "Scraping Candle of  ABT  \n",
      "\n",
      "GOLEM begins Computing...\n",
      "\n",
      "\n",
      "# of periods :  764\n",
      "On 80% - 20% slash : \n",
      "Bloc 1 :  611 \n",
      "Bloc 2 : 153  periods \n",
      "First period : 2016-08-15 00:00:00\n",
      "Split period : 2019-01-17 00:00:00\n",
      "Last period : 2019-08-27 00:00:00\n",
      "\n",
      "\n",
      "Beta :  0.8209286385406849 \n",
      " Alpha :  0.18170348752123316 \n",
      " R_Squared :  0.39484941504648907 \n",
      " Volatility :  0.16168340244696974 \n",
      " Momentum :  0.27238289161741003\n",
      "Last candle scraped from Yahoo! Finance in = 2.120000 seconds \n",
      "\n",
      "Preparing data of  ABT  \n",
      "\n",
      "Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost ok\n",
      "Data prepared in = 2.050000 seconds\n",
      "Data prepared in = 2.050000 seconds \n",
      "\n",
      "Applying Deep Learning data of  ABT  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32m RESULTATS UP\n",
      " \u001b[0m\n",
      "Accuracy: 53.85%\n",
      "\u001b[34m Precision: 49.47%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 100.00%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.27        57\n",
      "           1       0.49      1.00      0.66        47\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       104\n",
      "   macro avg       0.75      0.58      0.47       104\n",
      "weighted avg       0.77      0.54      0.45       104\n",
      "\n",
      "[[ 9 48]\n",
      " [ 0 47]]\n",
      "\n",
      "\n",
      "_______________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "\u001b[31m RESULTATS DOWN\n",
      " \u001b[0m\n",
      "Accuracy: 57.69%\n",
      "\u001b[34m Precision: 100.00%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 4.35%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72        58\n",
      "           1       1.00      0.04      0.08        46\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       104\n",
      "   macro avg       0.78      0.52      0.40       104\n",
      "weighted avg       0.76      0.58      0.44       104\n",
      "\n",
      "[[58  0]\n",
      " [44  2]]\n",
      "\n",
      "\n",
      "Deep Learning executed in = 0.060000 seconds\n",
      "Deep learned in = 0.060000 seconds \n",
      "\n",
      "\n",
      " \u001b[30m \u001b[43m  Test de precision pour  ABT  non passé. \u001b[0m\n",
      " --- Loop : 3  ---  --- Symbol :  \u001b[33m ABBV \u001b[0m  ---  --- Name :  AbbVie Inc.  ---  --- Sector :  Health Care  --- \n",
      "Models loaded from disk in = 0.200000 seconds \n",
      "\n",
      "Scraping Candle of  ABBV  \n",
      "\n",
      "GOLEM begins Computing...\n",
      "\n",
      "\n",
      "# of periods :  764\n",
      "On 80% - 20% slash : \n",
      "Bloc 1 :  611 \n",
      "Bloc 2 : 153  periods \n",
      "First period : 2016-08-15 00:00:00\n",
      "Split period : 2019-01-17 00:00:00\n",
      "Last period : 2019-08-27 00:00:00\n",
      "\n",
      "\n",
      "Beta :  0.6921931185216884 \n",
      " Alpha :  0.020154186813287584 \n",
      " R_Squared :  0.08760895914706823 \n",
      " Volatility :  0.2894201737334978 \n",
      " Momentum :  -0.2798969777668613\n",
      "Last candle scraped from Yahoo! Finance in = 2.490000 seconds \n",
      "\n",
      "Preparing data of  ABBV  \n",
      "\n",
      "Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost ok\n",
      "Data prepared in = 2.130000 seconds\n",
      "Data prepared in = 2.130000 seconds \n",
      "\n",
      "Applying Deep Learning data of  ABBV  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32m RESULTATS UP\n",
      " \u001b[0m\n",
      "Accuracy: 78.85%\n",
      "\u001b[34m Precision: 74.71%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 100.00%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61        39\n",
      "           1       0.75      1.00      0.86        65\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       104\n",
      "   macro avg       0.87      0.72      0.73       104\n",
      "weighted avg       0.84      0.79      0.76       104\n",
      "\n",
      "[[17 22]\n",
      " [ 0 65]]\n",
      "\n",
      "\n",
      "_______________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "\u001b[31m RESULTATS DOWN\n",
      " \u001b[0m\n",
      "Accuracy: 90.38%\n",
      "\u001b[34m Precision: 86.67%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 81.25%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        72\n",
      "           1       0.87      0.81      0.84        32\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       104\n",
      "   macro avg       0.89      0.88      0.89       104\n",
      "weighted avg       0.90      0.90      0.90       104\n",
      "\n",
      "[[68  4]\n",
      " [ 6 26]]\n",
      "\n",
      "\n",
      "Deep Learning executed in = 0.070000 seconds\n",
      "Deep learned in = 0.070000 seconds \n",
      "\n",
      " --- Loop : 4  ---  --- Symbol :  \u001b[33m ACN \u001b[0m  ---  --- Name :  Accenture plc  ---  --- Sector :  Information Technology  --- \n",
      "Models loaded from disk in = 0.210000 seconds \n",
      "\n",
      "Scraping Candle of  ACN  \n",
      "\n",
      "GOLEM begins Computing...\n",
      "\n",
      "\n",
      "# of periods :  764\n",
      "On 80% - 20% slash : \n",
      "Bloc 1 :  611 \n",
      "Bloc 2 : 153  periods \n",
      "First period : 2016-08-15 00:00:00\n",
      "Split period : 2019-01-17 00:00:00\n",
      "Last period : 2019-08-27 00:00:00\n",
      "\n",
      "\n",
      "Beta :  0.9651758408268096 \n",
      " Alpha :  0.11605437668582974 \n",
      " R_Squared :  0.5353533228241479 \n",
      " Volatility :  0.16325330197527685 \n",
      " Momentum :  0.18654961700694406\n",
      "Last candle scraped from Yahoo! Finance in = 1.710000 seconds \n",
      "\n",
      "Preparing data of  ACN  \n",
      "\n",
      "Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost ok\n",
      "Data prepared in = 2.070000 seconds\n",
      "Data prepared in = 2.070000 seconds \n",
      "\n",
      "Applying Deep Learning data of  ACN  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32m RESULTATS UP\n",
      " \u001b[0m\n",
      "Accuracy: 51.92%\n",
      "\u001b[34m Precision: 100.00%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 7.41%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        50\n",
      "           1       1.00      0.07      0.14        54\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       104\n",
      "   macro avg       0.75      0.54      0.40       104\n",
      "weighted avg       0.76      0.52      0.39       104\n",
      "\n",
      "[[50  0]\n",
      " [50  4]]\n",
      "\n",
      "\n",
      "_______________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "\u001b[31m RESULTATS DOWN\n",
      " \u001b[0m\n",
      "Accuracy: 45.19%\n",
      "\u001b[34m Precision: 39.36%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 100.00%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.15      0.26        67\n",
      "           1       0.39      1.00      0.56        37\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       104\n",
      "   macro avg       0.70      0.57      0.41       104\n",
      "weighted avg       0.78      0.45      0.37       104\n",
      "\n",
      "[[10 57]\n",
      " [ 0 37]]\n",
      "\n",
      "\n",
      "Deep Learning executed in = 0.080000 seconds\n",
      "Deep learned in = 0.080000 seconds \n",
      "\n",
      "\n",
      " \u001b[30m \u001b[43m  Test de precision pour  ACN  non passé. \u001b[0m\n",
      " --- Loop : 5  ---  --- Symbol :  \u001b[33m ATVI \u001b[0m  ---  --- Name :  Activision Blizzard  ---  --- Sector :  Information Technology  --- \n",
      "Models loaded from disk in = 0.220000 seconds \n",
      "\n",
      "Scraping Candle of  ATVI  \n",
      "\n",
      "GOLEM begins Computing...\n",
      "\n",
      "\n",
      "# of periods :  764\n",
      "On 80% - 20% slash : \n",
      "Bloc 1 :  611 \n",
      "Bloc 2 : 153  periods \n",
      "First period : 2016-08-15 00:00:00\n",
      "Split period : 2019-01-17 00:00:00\n",
      "Last period : 2019-08-27 00:00:00\n",
      "\n",
      "\n",
      "Beta :  0.8709309046678726 \n",
      " Alpha :  0.04553734372969355 \n",
      " R_Squared :  0.10593194306855858 \n",
      " Volatility :  0.3311662079639409 \n",
      " Momentum :  -0.2857086552272845\n",
      "Last candle scraped from Yahoo! Finance in = 2.410000 seconds \n",
      "\n",
      "Preparing data of  ATVI  \n",
      "\n",
      "Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost ok\n",
      "Data prepared in = 2.030000 seconds\n",
      "Data prepared in = 2.030000 seconds \n",
      "\n",
      "Applying Deep Learning data of  ATVI  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32m RESULTATS UP\n",
      " \u001b[0m\n",
      "Accuracy: 73.08%\n",
      "\u001b[34m Precision: 80.43%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 66.07%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.74        48\n",
      "           1       0.80      0.66      0.73        56\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       104\n",
      "   macro avg       0.74      0.74      0.73       104\n",
      "weighted avg       0.74      0.73      0.73       104\n",
      "\n",
      "[[39  9]\n",
      " [19 37]]\n",
      "\n",
      "\n",
      "_______________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "\u001b[31m RESULTATS DOWN\n",
      " \u001b[0m\n",
      "Accuracy: 78.85%\n",
      "\u001b[34m Precision: 78.57%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 57.89%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85        66\n",
      "           1       0.79      0.58      0.67        38\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       104\n",
      "   macro avg       0.79      0.74      0.76       104\n",
      "weighted avg       0.79      0.79      0.78       104\n",
      "\n",
      "[[60  6]\n",
      " [16 22]]\n",
      "\n",
      "\n",
      "Deep Learning executed in = 0.080000 seconds\n",
      "Deep learned in = 0.080000 seconds \n",
      "\n",
      " --- Loop : 6  ---  --- Symbol :  \u001b[33m AYI \u001b[0m  ---  --- Name :  Acuity Brands Inc  ---  --- Sector :  Industrials  --- \n",
      "Models loaded from disk in = 0.230000 seconds \n",
      "\n",
      "Scraping Candle of  AYI  \n",
      "\n",
      "GOLEM begins Computing...\n",
      "\n",
      "\n",
      "# of periods :  764\n",
      "On 80% - 20% slash : \n",
      "Bloc 1 :  611 \n",
      "Bloc 2 : 153  periods \n",
      "First period : 2016-08-15 00:00:00\n",
      "Split period : 2019-01-17 00:00:00\n",
      "Last period : 2019-08-27 00:00:00\n",
      "\n",
      "\n",
      "Beta :  1.6885509217964156 \n",
      " Alpha :  -0.3711429638625929 \n",
      " R_Squared :  0.3090031465084587 \n",
      " Volatility :  0.3759313065892778 \n",
      " Momentum :  -0.20704540094180046\n",
      "Last candle scraped from Yahoo! Finance in = 2.010000 seconds \n",
      "\n",
      "Preparing data of  AYI  \n",
      "\n",
      "Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost ok\n",
      "Data prepared in = 2.170000 seconds\n",
      "Data prepared in = 2.170000 seconds \n",
      "\n",
      "Applying Deep Learning data of  AYI  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32m RESULTATS UP\n",
      " \u001b[0m\n",
      "Accuracy: 57.69%\n",
      "\u001b[34m Precision: 51.65%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 100.00%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.23      0.37        57\n",
      "           1       0.52      1.00      0.68        47\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       104\n",
      "   macro avg       0.76      0.61      0.53       104\n",
      "weighted avg       0.78      0.58      0.51       104\n",
      "\n",
      "[[13 44]\n",
      " [ 0 47]]\n",
      "\n",
      "\n",
      "_______________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "\u001b[31m RESULTATS DOWN\n",
      " \u001b[0m\n",
      "Accuracy: 68.27%\n",
      "\u001b[34m Precision: 92.86%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 28.89%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.78        59\n",
      "           1       0.93      0.29      0.44        45\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       104\n",
      "   macro avg       0.79      0.64      0.61       104\n",
      "weighted avg       0.77      0.68      0.63       104\n",
      "\n",
      "[[58  1]\n",
      " [32 13]]\n",
      "\n",
      "\n",
      "Deep Learning executed in = 0.090000 seconds\n",
      "Deep learned in = 0.090000 seconds \n",
      "\n",
      "\n",
      " \u001b[30m \u001b[43m  Test de precision pour  AYI  non passé. \u001b[0m\n",
      " --- Loop : 7  ---  --- Symbol :  \u001b[33m ADBE \u001b[0m  ---  --- Name :  Adobe Systems Inc  ---  --- Sector :  Information Technology  --- \n",
      "Models loaded from disk in = 0.260000 seconds \n",
      "\n",
      "Scraping Candle of  ADBE  \n",
      "\n",
      "GOLEM begins Computing...\n",
      "\n",
      "\n",
      "# of periods :  764\n",
      "On 80% - 20% slash : \n",
      "Bloc 1 :  611 \n",
      "Bloc 2 : 153  periods \n",
      "First period : 2016-08-15 00:00:00\n",
      "Split period : 2019-01-17 00:00:00\n",
      "Last period : 2019-08-27 00:00:00\n",
      "\n",
      "\n",
      "Beta :  1.0864072352077294 \n",
      " Alpha :  0.26383849757703426 \n",
      " R_Squared :  0.3940710992819716 \n",
      " Volatility :  0.21418109735958557 \n",
      " Momentum :  0.09844029251290398\n",
      "Last candle scraped from Yahoo! Finance in = 1.970000 seconds \n",
      "\n",
      "Preparing data of  ADBE  \n",
      "\n",
      "Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost ok\n",
      "Data prepared in = 2.160000 seconds\n",
      "Data prepared in = 2.160000 seconds \n",
      "\n",
      "Applying Deep Learning data of  ADBE  \n",
      "\n",
      "\n",
      "\n",
      "\u001b[32m RESULTATS UP\n",
      " \u001b[0m\n",
      "Accuracy: 64.42%\n",
      "\u001b[34m Precision: 55.95%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 100.00%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.35      0.52        57\n",
      "           1       0.56      1.00      0.72        47\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       104\n",
      "   macro avg       0.78      0.68      0.62       104\n",
      "weighted avg       0.80      0.64      0.61       104\n",
      "\n",
      "[[20 37]\n",
      " [ 0 47]]\n",
      "\n",
      "\n",
      "_______________________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "\u001b[31m RESULTATS DOWN\n",
      " \u001b[0m\n",
      "Accuracy: 79.81%\n",
      "\u001b[34m Precision: 77.50%  \u001b[0m  => Discrimnination des vrais positifs parmi les faux positifs\n",
      "Recall: 72.09%   => Positifs trouvés par Golem sur tous les positifs existants\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        61\n",
      "           1       0.78      0.72      0.75        43\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       104\n",
      "   macro avg       0.79      0.79      0.79       104\n",
      "weighted avg       0.80      0.80      0.80       104\n",
      "\n",
      "[[52  9]\n",
      " [12 31]]\n",
      "\n",
      "\n",
      "Deep Learning executed in = 0.100000 seconds\n",
      "Deep learned in = 0.100000 seconds \n",
      "\n",
      "\n",
      " \u001b[30m \u001b[43m  Test de precision pour  ADBE  non passé. \u001b[0m\n",
      " --- Loop : 8  ---  --- Symbol :  \u001b[33m AAP \u001b[0m  ---  --- Name :  Advance Auto Parts  ---  --- Sector :  Consumer Discretionary  --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YTsBaCh/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "start =str(dt.date.today()-dt.timedelta(1110))\n",
    "end = str(dt.date.today())\n",
    "signals = pd.DataFrame(columns = ['Date','Ticker','Open Long','Close Long','Open Short','Close Short'])\n",
    "global delta,bloc1,bloc2,model_up,model_down\n",
    "\n",
    "GREEN = []\n",
    "RED = []\n",
    "GREEN_CLOSE = []\n",
    "RED_CLOSE=[]\n",
    "TICKER = []\n",
    "DATE = []\n",
    "i = -1\n",
    "tmps55=time.time()\n",
    "for loop in range(0, len(constituents)):\n",
    "    try:\n",
    "        tmps1=time.time()\n",
    "        ticker = (constituents.iloc[loop]['Symbol'])\n",
    "        name = constituents.iloc[loop]['Name']\n",
    "        sector = constituents.iloc[loop]['Sector']\n",
    "        print(' --- Loop :',loop,' --- ',end='')\n",
    "        print(' --- Symbol : ',Fore.YELLOW,ticker,Style.RESET_ALL,' --- ',end='')\n",
    "        print(' --- Name : ',name,' --- ',end='')\n",
    "        print(' --- Sector : ',sector,' --- ')\n",
    "\n",
    "        yamlup = os.path.join(os.path.dirname(constituents_csv), 'DONNEES_DL/Save_'+ticker+'_up.yaml')\n",
    "        yamldown = os.path.join(os.path.dirname(constituents_csv), 'DONNEES_DL/Save_'+ticker+'_down.yaml')\n",
    "        modelup = os.path.join(os.path.dirname(constituents_csv), 'DONNEES_DL/Save_'+ticker+'_up.h5')\n",
    "        modeldown = os.path.join(os.path.dirname(constituents_csv), 'DONNEES_DL/Save_'+ticker+'_down.h5')\n",
    "\n",
    "        yaml_file_up = open(yamlup, 'r')\n",
    "        yaml_file_down = open(yamldown, 'r')\n",
    "        model_yaml_up = yaml_file_up.read()\n",
    "        model_yaml_down = yaml_file_down.read()\n",
    "        yaml_file_up.close()\n",
    "        yaml_file_down.close()\n",
    "        model_up = model_from_yaml(model_yaml_up)\n",
    "        model_down = model_from_yaml(model_yaml_down)\n",
    "        # load weights into new model\n",
    "        model_up.load_weights(modelup)\n",
    "        model_down.load_weights(modeldown)\n",
    "        tmps2=round(time.time()-tmps1,2)\n",
    "        print(\"Models loaded from disk in = %f\" %tmps2,'seconds \\n')\n",
    "\n",
    "        tmps1=time.time()\n",
    "        print('Scraping Candle of ',ticker,' \\n')\n",
    "\n",
    "        df = scrap_data(ticker,start,end)\n",
    "        dfb = web.DataReader('^GSPC','yahoo',start,end)\n",
    "        print('GOLEM begins Computing...')\n",
    "        print('\\n')\n",
    "        delta = round(df.shape[0])\n",
    "        bloc1 = round(delta*0.80)\n",
    "        bloc2 = delta - bloc1\n",
    "        print(\"# of periods : \",delta)\n",
    "        print('On 80% - 20% slash : ')\n",
    "        print('Bloc 1 : ',bloc1,'\\nBloc 2 :',bloc2,' periods ')\n",
    "        print('First period :',df.index[0])\n",
    "        print('Split period :',df.index[bloc1-1])\n",
    "        print('Last period :',df.index[df.shape[0]-1])\n",
    "        print('\\n')\n",
    "\n",
    "        beta,alpha, r_squared, volatility, momentum = grobeta(df,dfb)\n",
    "\n",
    "        tmps2=round(time.time()-tmps1,2)\n",
    "        print(\"Last candle scraped from Yahoo! Finance in = %f\" %tmps2,'seconds \\n')\n",
    "\n",
    "        tmps1=time.time()\n",
    "        print('Preparing data of ',ticker,' \\n')\n",
    "\n",
    "        df = prepa_data(df)\n",
    "\n",
    "        tmps2=round(time.time()-tmps1,2)\n",
    "        print(\"Data prepared in = %f\" %tmps2,'seconds \\n')\n",
    "\n",
    "\n",
    "        tmps1=time.time()\n",
    "        print('Applying Deep Learning data of ',ticker,' \\n')\n",
    "\n",
    "        resultats,precision_up,precision_down,scaler = deep_learning(df)\n",
    "\n",
    "        tmps2=round(time.time()-tmps1,2)\n",
    "        print(\"Deep learned in = %f\" %tmps2,'seconds \\n')\n",
    "\n",
    "        if (precision_up * 100) > 59 and (precision_down * 100) > 59:\n",
    "\n",
    "            ####################\n",
    "            ##### SIGNALS #####\n",
    "            ###################\n",
    "\n",
    "            filtre_up = 93\n",
    "            filtre_down = 97\n",
    "            filtre_up_close = 80\n",
    "            filtre_down_close = 80\n",
    "\n",
    "\n",
    "            if resultats.iloc[i]['Confiance Down'] > filtre_down:\n",
    "                doob = -1\n",
    "            elif resultats.iloc[i]['Confiance Down'] > filtre_down_close and resultats.iloc[i]['Confiance Down'] < filtre_down :\n",
    "                waab = -1\n",
    "                doob = 0\n",
    "            elif resultats.iloc[i]['Confiance up'] > filtre_up:\n",
    "                doob = 1\n",
    "            elif resultats.iloc[i]['Confiance up'] > filtre_up_close and resultats.iloc[i]['Confiance up'] < filtre_up:\n",
    "                waab = 1\n",
    "                doob = 0\n",
    "            else :\n",
    "                doob = 0\n",
    "                waab = 0\n",
    "\n",
    "            if doob == 1 :\n",
    "                DATE.append(df.index[i])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(1)\n",
    "                RED.append(0)\n",
    "                GREEN_CLOSE.append(0)\n",
    "                RED_CLOSE.append(1)\n",
    "\n",
    "            elif doob == -1 :\n",
    "                DATE.append(df.index[i])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(0)\n",
    "                RED.append(1)\n",
    "                GREEN_CLOSE.append(1)\n",
    "                RED_CLOSE.append(0)\n",
    "\n",
    "            elif doob == 0 and waab == -1 :\n",
    "                DATE.append(df.index[i])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(0)\n",
    "                RED.append(0)\n",
    "                GREEN_CLOSE.append(0)\n",
    "                RED_CLOSE.append(1)\n",
    "\n",
    "            elif waab == 1 :\n",
    "                DATE.append(df.index[i])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(0)\n",
    "                RED.append(0)\n",
    "                GREEN_CLOSE.append(1)\n",
    "                RED_CLOSE.append(0)  \n",
    "\n",
    "            else:\n",
    "                DATE.append(df.index[i])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(0)\n",
    "                RED.append(0)\n",
    "                GREEN_CLOSE.append(0)\n",
    "                RED_CLOSE.append(0)  \n",
    "\n",
    "\n",
    "        else:\n",
    "            print('\\n',Fore.BLACK,Back.YELLOW,' Test de precision pour ',ticker,' non passé.',Style.RESET_ALL)\n",
    "            DATE.append(df.index[i])\n",
    "            TICKER.append(ticker)\n",
    "            GREEN.append(0)\n",
    "            RED.append(0)\n",
    "            GREEN_CLOSE.append(0)\n",
    "            RED_CLOSE.append(0)  \n",
    "            \n",
    "\n",
    "    except:\n",
    "        print(Fore.RED,Back.GREEN,'Il y a un problème en loop ',loop,', avec le ticker ',ticker,'absent de la base.',Style.RESET_ALL)\n",
    "        continue\n",
    "\n",
    "\n",
    "signals['Date'] = DATE\n",
    "signals['Ticker'] = TICKER\n",
    "signals['Open Long'] = GREEN\n",
    "signals['Close Long'] = GREEN_CLOSE\n",
    "signals['Open Short'] = RED\n",
    "signals['Close Short'] = RED_CLOSE        \n",
    "\n",
    "try:\n",
    "    print('Le fichier SIGNALS.csv existe déjà')\n",
    "    signals_csv = pd.read_csv('SIGNALS.csv')\n",
    "    signals_csv = signals_csv.drop('Unnamed: 0',axis=1)\n",
    "    final_csv = pd.concat([signals_csv,signals],ignore_index=True)\n",
    "    final_csv.to_csv('SIGNALS.csv')\n",
    "    \n",
    "except:\n",
    "    print('Création du fichier SIGNALS.csv')\n",
    "    signals.to_csv('SIGNALS'+today+'.csv')        \n",
    "        \n",
    "\n",
    "tmps22=round(time.time()-tmps55,2)\n",
    "print(\"Time for complete Signals Generation = %f\" %tmps22,'seconds \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
