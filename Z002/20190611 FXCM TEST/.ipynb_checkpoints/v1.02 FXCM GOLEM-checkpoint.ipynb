{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Optimized LumberJack Environment Motor\n",
      "째OoO_FXCM_Oo0째\n",
      "LumberJack Jyss 5779(c)\n",
      "Version v1.02\n",
      "Importing librairies...\n",
      "version fxcmpy : 1.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies imported\n"
     ]
    }
   ],
   "source": [
    "___Author___='LumberJack Jyss'\n",
    "print('Global Optimized LumberJack Environment Motor\\n째OoO_FXCM_Oo0째\\nLumberJack Jyss 5779(c)')\n",
    "print('Version v1.02')\n",
    "print('Importing librairies...')\n",
    "import fxcmpy\n",
    "print('version fxcmpy :',fxcmpy.__version__)\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import talib\n",
    "from zigzag import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "#import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,roc_curve,confusion_matrix,classification_report\n",
    "print('Librairies imported')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = 'e053ac1597cef331df9429ac8151100ea9f1c411'\n",
    "server = 'demo'\n",
    "\n",
    "# minutes: 'm1' , 'm5' , 'm15' , 'm30' \n",
    "# hours: 'H1' , 'H2', 'H3', 'H4', 'H6' 'H8'\n",
    "# one day: 'D1'\n",
    "# one week: 'W1'\n",
    "# one month: 'M1'\n",
    "\n",
    "period = 'm1'\n",
    "number = 10000\n",
    "# Time Windows\n",
    "# start = dt.datetime(2017, 7, 15)\n",
    "# stop = dt.datetime(2017, 8, 1)\n",
    "# con.get_candles('EUR/USD', period='D1',start=start, stop=stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_long = 0\n",
    "pos_short = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting server...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0614 17:00:40.997003 4546254272 fxcmpy.py:222] Default account set to 1147539, to change use set_default_account().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established for [1147539]  - Mode : demo\n",
      "Connexion executed in = 39.180000 secondes\n"
     ]
    }
   ],
   "source": [
    "tmps1=time.time()\n",
    "print('Connecting server...')\n",
    "con = fxcmpy.fxcmpy(access_token=TOKEN, log_level='error',server= server)\n",
    "if con.is_connected():\n",
    "    print('Connection established for',con.get_account_ids(),' - Mode :',server)\n",
    "else:\n",
    "    print('Not connected')\n",
    "tmps2=round(time.time()-tmps1,2)\n",
    "print (\"Connexion executed in = %f\" %tmps2,'secondes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GOLEM...\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Scrap executed in = 13.470000 secondes\n",
      "GOLEM begins Computing...\n",
      "Processing move_up\n",
      "Processing move_down\n",
      "Computing done\n",
      "DL executed in = 35.980000 secondes\n",
      "Resultats :                     Date  Move Up  Confiance up  Move Down  Confiance Down  \\\n",
      "9950 2019-06-14 15:00:00        1      67.79863          0             0.0   \n",
      "\n",
      "       Actual  \n",
      "9950  2886.35   \n",
      "\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Initializing GOLEM...\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Scrap executed in = 24.610000 secondes\n",
      "GOLEM begins Computing...\n",
      "Processing move_up\n",
      "Processing move_down\n",
      "Computing done\n",
      "DL executed in = 37.580000 secondes\n",
      "Resultats :                     Date  Move Up  Confiance up  Move Down  Confiance Down  \\\n",
      "9950 2019-06-14 15:01:00        1      66.16497          0             0.0   \n",
      "\n",
      "       Actual  \n",
      "9950  2886.52   \n",
      "\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Initializing GOLEM...\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Scrap executed in = 22.400000 secondes\n",
      "GOLEM begins Computing...\n",
      "Processing move_up\n",
      "Processing move_down\n",
      "Computing done\n",
      "DL executed in = 38.150000 secondes\n",
      "Resultats :                     Date  Move Up  Confiance up  Move Down  Confiance Down  \\\n",
      "9950 2019-06-14 15:02:00        1      68.57177          0             0.0   \n",
      "\n",
      "       Actual  \n",
      "9950  2886.35   \n",
      "\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Initializing GOLEM...\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Scrap executed in = 20.760000 secondes\n",
      "GOLEM begins Computing...\n",
      "Processing move_up\n",
      "Processing move_down\n",
      "Computing done\n",
      "DL executed in = 39.680000 secondes\n",
      "Resultats :                     Date  Move Up  Confiance up  Move Down  Confiance Down  \\\n",
      "9950 2019-06-14 15:03:00        1     72.394905          0             0.0   \n",
      "\n",
      "       Actual  \n",
      "9950  2886.26   \n",
      "\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Initializing GOLEM...\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Scrap executed in = 17.850000 secondes\n",
      "GOLEM begins Computing...\n",
      "Processing move_up\n",
      "Processing move_down\n",
      "Computing done\n",
      "DL executed in = 40.830000 secondes\n",
      "Resultats :                     Date  Move Up  Confiance up  Move Down  Confiance Down  \\\n",
      "9950 2019-06-14 15:04:00        1     67.689468          0             0.0   \n",
      "\n",
      "       Actual  \n",
      "9950  2886.35   \n",
      "\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Initializing GOLEM...\n",
      "Long Pos = 0\n",
      "Short Pos = 1\n",
      "Scrap executed in = 13.720000 secondes\n",
      "GOLEM begins Computing...\n",
      "Processing move_up\n"
     ]
    }
   ],
   "source": [
    "for loop in range(0,5000):\n",
    "\n",
    "    print('Initializing GOLEM...')\n",
    "    print('Long Pos =',pos_long)\n",
    "    print('Short Pos =',pos_short)\n",
    "    # SCRAP DATA\n",
    "\n",
    "    tmps1=time.time()\n",
    "    data = con.get_candles('SPX500', period=period,number=number) #start=start,stop=stop)\n",
    "    df = pd.DataFrame()\n",
    "    df['Open'] = data['askopen']\n",
    "    df['High'] = data['askhigh']\n",
    "    df['Low'] = data['asklow']\n",
    "    df['Close'] = data['askclose']\n",
    "    df['Date'] = data.index\n",
    "    df = df[['Date'] + df.columns[:-1].tolist()]\n",
    "    #df = data.copy()\n",
    "    tmps2=round(time.time()-tmps1,2)\n",
    "    print (\"Scrap executed in = %f\" %tmps2,'secondes')\n",
    "\n",
    "    # DEEP LEARNING\n",
    "\n",
    "    tmps1=time.time()\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    dataset_1D = df.copy()\n",
    "    dataset_1D = dataset_1D.dropna()\n",
    "    rsi = talib.RSI(dataset_1D['Close'],timeperiod=2)\n",
    "    upper, middle, lower =  talib.BBANDS(dataset_1D['Close'], timeperiod=9, nbdevup=2, nbdevdn=2,matype=0)\n",
    "    sma5 = talib.SMA(dataset_1D['Close'],timeperiod=5)\n",
    "    sma8 = talib.SMA(dataset_1D['Close'],timeperiod=8)\n",
    "    sma10 = talib.SMA(dataset_1D['Close'],timeperiod=10)\n",
    "    sma12 = talib.SMA(dataset_1D['Close'],timeperiod=12)\n",
    "    sma15 = talib.SMA(dataset_1D['Close'],timeperiod=15)\n",
    "    sma30 = talib.SMA(dataset_1D['Close'],timeperiod=30)\n",
    "    sma35 = talib.SMA(dataset_1D['Close'],timeperiod=35)\n",
    "    sma40 = talib.SMA(dataset_1D['Close'],timeperiod=40)\n",
    "    sma45 = talib.SMA(dataset_1D['Close'],timeperiod=45)\n",
    "    sma50 = talib.SMA(dataset_1D['Close'],timeperiod=50)\n",
    "\n",
    "    delta5_8 = sma5 - sma8\n",
    "    delta8_10 = sma8 - sma10\n",
    "    delta10_12 = sma10 - sma12\n",
    "    delta12_15 = sma12 - sma15\n",
    "    delta15_30 = sma15 - sma30\n",
    "    delta30_35 = sma30 - sma35\n",
    "    delta35_40 = sma35 - sma40\n",
    "    delta40_45 = sma40 - sma45\n",
    "    delta45_50 = sma45 - sma50\n",
    "\n",
    "    X = dataset_1D['Close']\n",
    "    pivots = peak_valley_pivots(X.values, 0.001, -0.001)\n",
    "    ts_pivots = pd.Series(X, index=X.index)\n",
    "    ts_pivots = ts_pivots[pivots != 0]\n",
    "\n",
    "    peak = []\n",
    "    valley = []\n",
    "\n",
    "    for i in range(0,dataset_1D.shape[0]):\n",
    "        if pivots[i] == 1:\n",
    "            peak.append(pivots[i])\n",
    "            valley.append(0)\n",
    "        elif pivots[i] == -1:\n",
    "            peak.append(0)\n",
    "            valley.append(pivots[i])\n",
    "        else:\n",
    "            peak.append(0)\n",
    "            valley.append(0)\n",
    "\n",
    "    bbdelta = upper - middle\n",
    "    price_bolup = dataset_1D['Close'] - lower\n",
    "    price_bolow = dataset_1D['Close'] - upper\n",
    "\n",
    "    rsi5_list = []\n",
    "    rsi95_list = []\n",
    "    for i in range(0,dataset_1D.shape[0]):\n",
    "        try:\n",
    "            rsi95_list.append(95 - rsi[i])\n",
    "            rsi5_list.append(rsi[i] - 5)\n",
    "        except:\n",
    "            rsi95_list.append(0)\n",
    "            rsi5_list.append(0)\n",
    "    varop_spy = dataset_1D['Open'] - dataset_1D['Close']\n",
    "    varhl_spy = dataset_1D['High'] - dataset_1D['Low']\n",
    "    dataset_1D['Varop_Spy'] = varop_spy\n",
    "    dataset_1D['Varhl_spy'] = varhl_spy\n",
    "    dataset_1D['RSI'] = rsi\n",
    "    dataset_1D['95 - RSI'] = np.array(rsi95_list)\n",
    "    dataset_1D['RSI - 5'] = np.array(rsi5_list)\n",
    "    dataset_1D['BBD_Delta_Up'] = bbdelta\n",
    "    dataset_1D['delta5_8'] = delta5_8\n",
    "    dataset_1D['delta8_10'] = delta8_10\n",
    "    dataset_1D['delta10_12'] = delta10_12\n",
    "    dataset_1D['delta12_15'] = delta12_15\n",
    "    dataset_1D['delta15_30'] = delta15_30\n",
    "    dataset_1D['delta30_35'] = delta30_35\n",
    "    dataset_1D['delta35_40'] = delta35_40\n",
    "    dataset_1D['delta40_45'] = delta40_45\n",
    "    dataset_1D['delta45_50'] = delta45_50\n",
    "    dataset_1D['Peaks'] = abs(np.array(peak))\n",
    "    dataset_1D['Valley'] = abs(np.array(valley))\n",
    "    tsf = talib.TSF(dataset_1D['Close'],timeperiod=14)\n",
    "    delta_tsf = dataset_1D['Close'] - tsf\n",
    "    dataset_1D['delta_tsf'] = tsf\n",
    "    forosc = []\n",
    "    forosc.append(0)\n",
    "    for i in range(1,dataset_1D.shape[0]):\n",
    "        try:\n",
    "            forosc.append((dataset_1D.iloc[i,4] - tsf[i-1])*100/dataset_1D.iloc[i,4])\n",
    "        except:\n",
    "            forosc.append(0)\n",
    "    dataset_1D['Forcast Oscillator'] = (forosc)\n",
    "    target_up = []\n",
    "    target_down = []\n",
    "\n",
    "    for i in range(0,dataset_1D.shape[0]-5):\n",
    "\n",
    "        if (dataset_1D.iloc[i+1,5] * dataset_1D.iloc[i,5]) < 0 :\n",
    "            if (dataset_1D.iloc[i+1,4] - dataset_1D.iloc[i,4]) > 0.2 : \n",
    "                target_up.append(1)\n",
    "                target_down.append(0)\n",
    "            elif (dataset_1D.iloc[i+1,4] - dataset_1D.iloc[i,4]) < -0.1 : \n",
    "                target_up.append(0)\n",
    "                target_down.append(1)\n",
    "            else:\n",
    "                target_up.append(0)\n",
    "                target_down.append(0)\n",
    "        else :\n",
    "            target_up.append(0)\n",
    "            target_down.append(0) \n",
    "\n",
    "    target_up.append(0)\n",
    "    target_down.append(0)\n",
    "    target_up.append(0)\n",
    "    target_down.append(0)\n",
    "    target_up.append(0)\n",
    "    target_down.append(0)\n",
    "    target_up.append(0)\n",
    "    target_down.append(0)\n",
    "    target_up.append(0)\n",
    "    target_down.append(0)\n",
    "    dataset_1D['target_up'] = target_up  # target_up # abs(np.array(valley))#target_up\n",
    "    dataset_1D['target_down'] = target_down # target_down # abs(np.array(peak))#target_down\n",
    "    dataset_1D['target_value'] = dataset_1D['Close']\n",
    "    dataset_1D = dataset_1D.drop(['Open','High','Low','Close'],axis=1)\n",
    "    df_1D = dataset_1D.copy()\n",
    "    df_1D = df_1D.iloc[:,1:]\n",
    "    df_1D['Date'] = df['Date']\n",
    "    df_1D = df_1D.dropna()\n",
    "    df_1D = df_1D[['Date'] + df_1D.columns[:-1].tolist()]\n",
    "    df_1D.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    print('GOLEM begins Computing...')\n",
    "\n",
    "\n",
    "    X = df_1D.iloc[:,1:-3]\n",
    "    y_up = df_1D.iloc[:,-3].values\n",
    "    y_down = df_1D.iloc[:,-2].values\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    y_up = np.array(y_up).reshape(-1,1)\n",
    "    y_down = np.array(y_down).reshape(-1,1)\n",
    "\n",
    "    Xtrain = X[:-1,:]\n",
    "    Xtest = X[-1:,:]\n",
    "    ytrain_up = y_up[:-1,:]\n",
    "    ytest_up = y_up[-1:,:]\n",
    "    ytrain_down = y_down[:-1,:]\n",
    "    ytest_down = y_down[-1:,:]\n",
    "\n",
    "    seed = 770\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ytrain_up = ytrain_up.reshape(ytrain_up.shape[0],)\n",
    "    ytrain_down = ytrain_down.reshape(ytrain_down.shape[0],)\n",
    "\n",
    "    Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1])\n",
    "\n",
    "    model_up = Sequential()\n",
    "        # Add an input layer \n",
    "    model_up.add(Dense(23, activation='relu'))\n",
    "        # Add one hidden layer \n",
    "    model_up.add(Dense(50, activation='relu'))\n",
    "        # Add an output layer \n",
    "    model_up.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model_down = Sequential()\n",
    "        # Add an input layer \n",
    "    model_down.add(Dense(23, activation='relu'))\n",
    "        # Add one hidden layer \n",
    "    model_down.add(Dense(50, activation='relu'))\n",
    "        # Add an output layer \n",
    "    model_down.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print('Processing move_up')\n",
    "    model_up.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy','mse'])\n",
    "\n",
    "    history_up = model_up.fit(Xtrain, ytrain_up,epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    print('Processing move_down')\n",
    "    model_down.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy','mse'])\n",
    "\n",
    "    history_down = model_down.fit(Xtrain, ytrain_down,epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    print('Computing done')\n",
    "\n",
    "\n",
    "    yhat_up = model_up.predict_classes(Xtest)\n",
    "    yhat_down = model_down.predict_classes(Xtest)\n",
    "\n",
    "    predict_up = model_up.predict(Xtest)\n",
    "    predict_down = model_down.predict(Xtest)\n",
    "\n",
    "    resultats = pd.DataFrame()\n",
    "    resultats['Date'] = df_1D.iloc[-1:,0]\n",
    "    resultats['Move Up'] = yhat_up\n",
    "    resultats['Confiance up'] = (predict_up)*100\n",
    "    resultats['Move Down'] = yhat_down\n",
    "    resultats['Confiance Down'] = (predict_down)*100\n",
    "    resultats['Actual'] = df_1D['target_value']\n",
    "\n",
    "    tmps2=round(time.time()-tmps1,2)\n",
    "    print (\"DL executed in = %f\" %tmps2,'secondes')\n",
    "    print('Resultats :',resultats,'\\n')\n",
    "\n",
    "    # TEST POSITIONS\n",
    "\n",
    "    # TEST POS\n",
    "    \n",
    "    print('Long Pos =',pos_long)\n",
    "    print('Short Pos =',pos_short)\n",
    "\n",
    "    if resultats.iloc[0,1] == 1 and resultats.iloc[0,2] > 83:\n",
    "        \n",
    "        if  pos_long == 0 and pos_short == 1:\n",
    "            order = con.close_all_for_symbol('SPX500')\n",
    "            pos_short = 0\n",
    "            print('Close Short')\n",
    "            \n",
    "        \n",
    "        elif pos_long == 0 and pos_short == 0:\n",
    "            order = con.create_market_buy_order('SPX500', 30)\n",
    "            print('Go Long')\n",
    "            pos_long = 1\n",
    "\n",
    "        \n",
    "\n",
    "    elif resultats.iloc[0,3] == 1 and resultats.iloc[0,4] > 88:\n",
    "        \n",
    "        if  pos_long == 1 and pos_short == 0:\n",
    "            order = con.close_all_for_symbol('SPX500')\n",
    "            print('Close Long')\n",
    "            pos_long = 0\n",
    "            \n",
    "        elif pos_long == 0 and pos_short == 0:\n",
    "            order = con.create_market_sell_order('SPX500', 30)\n",
    "            print('Go Short')\n",
    "            pos_short = 1\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
