{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearall():\n",
    "    all = [var for var in globals() if var[0] != \"_\"]\n",
    "    for var in all:\n",
    "        del globals()[var]\n",
    "clearall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Librairies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies imported\n",
      "\n",
      "Global Optimized LumberJack Environment Motor 55\n",
      "LumberJack Jyss 5779(c)\n",
      "\u001b[34m °0Oo_D.A.G._26_oO0°\n",
      "DEEP LEARNING FOREX V1 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Importing Librairies...')\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from colorama import Fore, Back, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,roc_curve,confusion_matrix,classification_report,r2_score\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print('Librairies imported')\n",
    "print('')\n",
    "\n",
    "___Author___='LumberJack Jyss'\n",
    "print('Global Optimized LumberJack Environment Motor 55\\nLumberJack Jyss 5779(c)')\n",
    "print(Fore.BLUE,'°0Oo_D.A.G._26_oO0°')\n",
    "print('DEEP LEARNING FOREX V1',Style.RESET_ALL)\n",
    "\n",
    "#LaDate = input('Date de DL - YYYY-MM-DD ')\n",
    "LaDate = '2020-01-15'\n",
    "ticker = 'USDJPY_1H'\n",
    "indice = 0.1\n",
    "try:\n",
    "    os.mkdir('DL_'+ticker+'-'+LaDate)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir('Boost_'+ticker+'-'+LaDate)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepa_data(df):\n",
    "    rsi = talib.RSI(df['Close'],timeperiod=14)\n",
    "    stoc_slowk, stoc_slowd = talib.STOCH(df['High'],df['Low'],df['Close'])\n",
    "    upper, middle, lower =  talib.BBANDS(df['Close'], timeperiod=9, nbdevup=2, nbdevdn=2,matype=0)\n",
    "    sma5 = talib.SMA(df['Close'],timeperiod=5)\n",
    "    sma8 = talib.SMA(df['Close'],timeperiod=8)\n",
    "    sma10 = talib.SMA(df['Close'],timeperiod=10)\n",
    "    sma12 = talib.SMA(df['Close'],timeperiod=12)\n",
    "    sma15 = talib.SMA(df['Close'],timeperiod=15)\n",
    "    sma30 = talib.SMA(df['Close'],timeperiod=30)\n",
    "    sma35 = talib.SMA(df['Close'],timeperiod=35)\n",
    "    sma40 = talib.SMA(df['Close'],timeperiod=40)\n",
    "    sma45 = talib.SMA(df['Close'],timeperiod=45)\n",
    "    sma50 = talib.SMA(df['Close'],timeperiod=50)\n",
    "    atr = talib.ATR(df['High'],df['Low'],df['Close'],timeperiod=10)\n",
    "    delta5_8 = sma5 - sma8\n",
    "    delta8_10 = sma8 - sma10\n",
    "    delta10_12 = sma10 - sma12\n",
    "    delta12_15 = sma12 - sma15\n",
    "    delta15_30 = sma15 - sma30\n",
    "    delta30_35 = sma30 - sma35\n",
    "    delta35_40 = sma35 - sma40\n",
    "    delta40_45 = sma40 - sma45\n",
    "    delta45_50 = sma45 - sma50\n",
    "    bbdelta = upper - middle\n",
    "    price_bolup = df['Close'] - lower\n",
    "    price_bolow = df['Close'] - upper\n",
    "    Ema = talib.EMA(df['Close'],timeperiod=20)\n",
    "    KC_High = Ema + 2*atr\n",
    "    KC_Low = Ema - 2*atr\n",
    "    aroondown, aroonup = talib.AROON(df['High'], df['Low'], timeperiod=9)\n",
    "    aroon = aroonup - aroondown \n",
    "    rsi30_list = []\n",
    "    rsi70_list = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        try:\n",
    "            rsi70_list.append(70 - rsi[0])\n",
    "            rsi30_list.append(rsi[i] - 30)\n",
    "        except:\n",
    "            rsi70_list.append(0)\n",
    "            rsi30_list.append(0)\n",
    "        \n",
    "    varop_spy = df['Open'] - df['Close']\n",
    "    varhl_spy = df['High'] - df['Low']\n",
    "    df['Varop_Spy'] = varop_spy\n",
    "    df['Varhl_spy'] = varhl_spy\n",
    "    df['RSI'] = rsi\n",
    "    df['70 - RSI'] = np.array(rsi70_list)\n",
    "    df['RSI - 30'] = np.array(rsi30_list)\n",
    "    df['BBD_Delta_Up'] = bbdelta\n",
    "    df['delta5_8'] = delta5_8\n",
    "    df['delta8_10'] = delta8_10\n",
    "    df['delta10_12'] = delta10_12\n",
    "    df['delta12_15'] = delta12_15\n",
    "    df['delta15_30'] = delta15_30\n",
    "    df['delta30_35'] = delta30_35\n",
    "    df['delta35_40'] = delta35_40\n",
    "    df['delta40_45'] = delta40_45\n",
    "    df['delta45_50'] = delta45_50\n",
    "    df['Stoc_Slowk'] = stoc_slowk\n",
    "    df['Stoc_Slowd'] = stoc_slowd\n",
    "    df['KC_High'] = KC_High\n",
    "    df['KC_Low'] = KC_Low\n",
    "    df['upper'] = upper\n",
    "    df['lower'] = lower\n",
    "    df['var_bollup_kchigh'] = upper-KC_High\n",
    "    df['var_bolllow_kclow'] = lower-KC_Low\n",
    "    df['Aroon Up'] = aroonup\n",
    "    df['Aroon Down'] = aroondown\n",
    "    df['Delta Aroon'] = aroon\n",
    "    up = []\n",
    "    down = []\n",
    "    df = df.dropna()\n",
    "    df['%Futur'] = ((df['Close'].shift(-1)-df['Close']) *100) / (df['Close'])\n",
    "    for i in range(0,df.shape[0]):\n",
    "        if df.iloc[i]['%Futur'] > indice :\n",
    "            up.append(1)\n",
    "            down.append(0)\n",
    "        elif df.iloc[i]['%Futur'] < -indice:\n",
    "            up.append(0)\n",
    "            down.append(1)\n",
    "        else:\n",
    "            up.append(0)\n",
    "            down.append(0)\n",
    "        \n",
    "    df['target_up'] = up  \n",
    "    df['target_down'] = down \n",
    "    #df = df.dropna()\n",
    "    \n",
    "    df = df[['High','Low','Open','Volume','DeltaVol','Close','Varop_Spy','Varhl_spy','RSI',\\\n",
    "             '70 - RSI','RSI - 30','BBD_Delta_Up','delta5_8','delta8_10','delta10_12',\\\n",
    "             'delta12_15','delta15_30','delta30_35','delta35_40','delta40_45','delta45_50',\\\n",
    "             'Stoc_Slowk','Stoc_Slowd','KC_High','KC_Low','upper','lower','var_bollup_kchigh',\\\n",
    "             'var_bolllow_kclow','Aroon Up','Aroon Down','Delta Aroon',\\\n",
    "             '%Futur','target_up','target_down']]\n",
    "        \n",
    "    return(df)\n",
    "    \n",
    "def deep_learning(df):\n",
    "    \n",
    "    seed = 770\n",
    "    np.random.seed(seed)\n",
    "    X = df.iloc[:,:-4]\n",
    "    y_up = df.iloc[:,-2].values\n",
    "    y_down = df.iloc[:,-1].values\n",
    "    X.astype(np.float64)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    y_up = np.array(y_up).reshape(-1,1)\n",
    "    y_down = np.array(y_down).reshape(-1,1)\n",
    "\n",
    "    Xtrain = X[:bloc1,:]\n",
    "    Xtest = X[bloc1:,:]\n",
    "    ytrain_up = y_up[:bloc1,:]\n",
    "    ytest_up = y_up[bloc1:,:]\n",
    "    ytrain_down = y_down[:bloc1,:]\n",
    "    ytest_down = y_down[bloc1:,:]\n",
    "\n",
    "    ytrain_up = ytrain_up.reshape(ytrain_up.shape[0],)\n",
    "    ytrain_down = ytrain_down.reshape(ytrain_down.shape[0],)\n",
    "\n",
    "    Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1])\n",
    "\n",
    "    model_up = Sequential()\n",
    "    # Add an input layer \n",
    "    model_up.add(Dense(50, activation='relu'))\n",
    "    # Add one hidden layer \n",
    "    model_up.add(Dense(23, activation='relu'))\n",
    "    # Add an output layer \n",
    "    model_up.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model_down = Sequential()\n",
    "    # Add an input layer \n",
    "    model_down.add(Dense(50, activation='relu'))\n",
    "    # Add one hidden layer \n",
    "    model_down.add(Dense(23, activation='relu'))\n",
    "    # Add an output layer \n",
    "    model_down.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model_up.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', #rmsprop\n",
    "                  metrics=['accuracy','mse'])\n",
    "    \n",
    "              \n",
    "\n",
    "    history_up = model_up.fit(Xtrain, ytrain_up,epochs=280, batch_size=8, verbose=0)\n",
    "    \n",
    "    model_down.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', #rmsprop\n",
    "                  metrics=['accuracy','mse'])\n",
    "\n",
    "    history_down = model_down.fit(Xtrain, ytrain_down,epochs=280, batch_size=8, verbose=0)\n",
    "    \n",
    "\n",
    "    train_acc_up = model_up.evaluate(Xtrain, ytrain_up,verbose=1)\n",
    "    train_acc_down = model_down.evaluate(Xtrain, ytrain_down,verbose=1)\n",
    "\n",
    "    yhat_up = model_up.predict_classes(Xtest)\n",
    "    yhat_down = model_down.predict_classes(Xtest)\n",
    "\n",
    "    score_up = model_up.evaluate(Xtest, ytest_up,verbose=1)\n",
    "    score_down = model_down.evaluate(Xtest, ytest_down,verbose=1)\n",
    "\n",
    "    predict_up = model_up.predict(Xtest)\n",
    "    predict_down = model_down.predict(Xtest)\n",
    "\n",
    "    accuracy_up = accuracy_score(ytest_up, yhat_up)\n",
    "    accuracy_down = accuracy_score(ytest_down, yhat_down)\n",
    "\n",
    "    # La précision permet de mesurer la capacité du modèle à refuser résultats non-pertinents : vrais_positifs/(vrais_positifs+faux_positifs)\n",
    "    precision_up = precision_score(ytest_up, yhat_up)  \n",
    "    precision_down = precision_score(ytest_down, yhat_down) \n",
    "\n",
    "\n",
    "    # Recall : (vrai_positifs/(vrais_positifs+faux_négatifs))\n",
    "    recall_up = recall_score(ytest_up, yhat_up) \n",
    "    recall_down = recall_score(ytest_down, yhat_down) \n",
    "\n",
    "\n",
    "    resultats = pd.DataFrame()\n",
    "    resultats['Date'] = df.index[bloc1:]\n",
    "    resultats.index= df.index[bloc1:]\n",
    "    resultats['Move Up'] = yhat_up\n",
    "    resultats['Confiance up'] = (predict_up)*100\n",
    "    resultats['Move Down'] = yhat_down\n",
    "    resultats['Confiance Down'] = (predict_down)*100\n",
    "    resultats['Actual'] = df.iloc[bloc1:]['Close']\n",
    "    resultats['Actual.S'] = df.iloc[bloc1:]['Close'].shift(-1)\n",
    "    open_S = df['Open'].shift(-1)\n",
    "    resultats['Open.S'] = open_S.iloc[bloc1:]\n",
    "    dmp_cp=[]\n",
    "    dmp_cp = ((resultats['Confiance up']-resultats['Confiance Down'])/(resultats['Confiance up']+resultats['Confiance Down'])*100)\n",
    "    resultats['DMP_CP'] = dmp_cp\n",
    "    \n",
    "    return(resultats,precision_up,precision_down,model_up,model_down,scaler)\n",
    "\n",
    "\n",
    "def save_model(model_up,model_down):\n",
    "    savename = 'DL_'+ticker+'-'+LaDate+'/Save_'+ticker\n",
    "    # serialize model to YAML\n",
    "    model_up_yaml = model_up.to_yaml()\n",
    "    model_down_yaml = model_down.to_yaml()\n",
    "    with open(savename+\"_up.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_up_yaml)\n",
    "    with open(savename+\"_down.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_down_yaml)\n",
    "    # serialize weights to HDF5\n",
    "    model_up.save_weights(savename+\"_up.h5\")\n",
    "    model_down.save_weights(savename+\"_down.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE ORIGINELLE DU DEBUT DE TOUT... : 2019-06-01\n",
      " - Date de début :  2019-06-01  - Date de fin :  2020-01-15\n",
      "\u001b[33m GENERATION DE LaBase : \u001b[35m 11:55:12\n",
      "\u001b[34m Time for complete Base Preparation = 3.110000 seconds \n",
      " \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-02</th>\n",
       "      <td>108.275</td>\n",
       "      <td>108.348</td>\n",
       "      <td>108.266</td>\n",
       "      <td>108.320</td>\n",
       "      <td>1506.0699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03</th>\n",
       "      <td>108.319</td>\n",
       "      <td>108.324</td>\n",
       "      <td>108.173</td>\n",
       "      <td>108.197</td>\n",
       "      <td>5449.0898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03</th>\n",
       "      <td>108.199</td>\n",
       "      <td>108.300</td>\n",
       "      <td>108.197</td>\n",
       "      <td>108.223</td>\n",
       "      <td>5235.0898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03</th>\n",
       "      <td>108.223</td>\n",
       "      <td>108.319</td>\n",
       "      <td>108.208</td>\n",
       "      <td>108.293</td>\n",
       "      <td>9715.6699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03</th>\n",
       "      <td>108.292</td>\n",
       "      <td>108.302</td>\n",
       "      <td>108.150</td>\n",
       "      <td>108.232</td>\n",
       "      <td>11496.0400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close      Volume\n",
       "2019-06-02  108.275  108.348  108.266  108.320   1506.0699\n",
       "2019-06-03  108.319  108.324  108.173  108.197   5449.0898\n",
       "2019-06-03  108.199  108.300  108.197  108.223   5235.0898\n",
       "2019-06-03  108.223  108.319  108.208  108.293   9715.6699\n",
       "2019-06-03  108.292  108.302  108.150  108.232  11496.0400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARAMETRES TEMPORELS INITIAUX\n",
    "start = '2019-06-01'\n",
    "end = LaDate\n",
    "print('DATE ORIGINELLE DU DEBUT DE TOUT... :',start)\n",
    "error = []\n",
    "\n",
    "        \n",
    "########################\n",
    "#### MAIN SKAN55 #######\n",
    "########################\n",
    "\n",
    "print(' - Date de début : ',start,' - Date de fin : ',end)\n",
    "print(Fore.YELLOW,'GENERATION DE LaBase :',Fore.MAGENTA,time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "tmps55=time.time()\n",
    "LaBase = pd.read_csv('USDJPY_1H.csv')\n",
    "df = LaBase\n",
    "\n",
    "INDEX = []\n",
    "for i in range(0,len(df)):\n",
    "    INDEX.append((str(df.iloc[i,0])[6:10]+'-'+str(df.iloc[i,0])[3:5]+'-'+str(df.iloc[i,0])[:2]))\n",
    "df.index = INDEX\n",
    "df = df.drop(['Local time'],axis=1)\n",
    "df = df[df.index>=start]\n",
    "delta = round(df.shape[0])\n",
    "bloc1 = round(delta*0.75)\n",
    "bloc2 = delta - bloc1\n",
    "\n",
    "tmps22=round(time.time()-tmps55,2)\n",
    "print(Fore.BLUE,\"Time for complete Base Preparation = %f\" %tmps22,'seconds \\n',Style.RESET_ALL)\n",
    "#LaBasePrep.to_csv('LaBasePrep.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computing has begun at  11 : 55 : 15\n",
      "\u001b[34m \n",
      "Time for complete Preparation = 1.930000 seconds \n",
      " \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "###### PREPARATION #########\n",
    "\n",
    "\n",
    "print('The computing has begun at ',dt.datetime.now().hour,':',dt.datetime.now().minute,':',dt.datetime.now().second)\n",
    "\n",
    "BasePrep = pd.DataFrame()\n",
    "tmps55=time.time()\n",
    "\n",
    "df['DeltaVol'] = df['Volume'] - df['Volume'].shift(1)\n",
    "df = df.dropna()\n",
    "df = prepa_data(df)\n",
    "    \n",
    "BasePrep = df\n",
    "tmps22=round(time.time()-tmps55,2)\n",
    "print(Fore.BLUE,\"\\nTime for complete Preparation = %f\" %tmps22,'seconds \\n',Style.RESET_ALL)\n",
    "BasePrep.to_csv('BasePrep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m \n",
      "GENERATION DU BOOST : \u001b[35m 11:55:20\n",
      "\u001b[32m \n",
      "r2_score =  42.77377305076344 %\n",
      "% error :  0.1110723427979384 %\n",
      "\n",
      "Ecart min :  1.7449230326732295e-06 %\n",
      "\n",
      "Ecart max :  1.047000131459823 %\n",
      "\n",
      " {'validation_0': {'mae': [1.427006, 0.294422, 0.28933, 0.292095, 0.289685, 0.2897, 0.2897, 0.2897, 0.2897, 0.2897, 0.2897, 0.2897]}}\n",
      "\u001b[34m \n",
      "Time for complete BOOST GENERATION = 5.120000 seconds \n",
      " \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def boost(df):\n",
    "    print(Fore.YELLOW,'\\nGENERATION DU BOOST :',Fore.MAGENTA,time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "    tmps55=time.time()\n",
    "    \n",
    "    seed = 770\n",
    "    np.random.seed(seed)\n",
    "    X = df.copy()\n",
    "    X = X.drop(['Close'],axis=1)\n",
    "    X['Close'] = df['Close']\n",
    "    y = X.iloc[:,-1]\n",
    "    Xtrain = X.iloc[:bloc1,:-1]\n",
    "    Xtest = X.iloc[bloc1:-1,:-1]\n",
    "    yshift = y.shift(-1)\n",
    "    ytrain = yshift.iloc[:bloc1]\n",
    "    ytest = yshift.iloc[bloc1:-1]\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=200000, learning_rate=1, gamma=1, subsample=1, colsample_bytree=1, max_depth=5,objective='reg:squarederror')\n",
    "\n",
    "    model.fit( Xtrain, ytrain, early_stopping_rounds=10, eval_metric=['mae'],eval_set=[(Xtest, ytest)], verbose=0)\n",
    "\n",
    "    ytrain_pred = model.predict(Xtrain)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "\n",
    "    pred = model.predict(X.iloc[:,:-1])\n",
    "    r2 = r2_score(ytest,y_pred)*100\n",
    "    df['Boost'] = pred\n",
    "    return(df,model,r2)\n",
    "\n",
    "\n",
    "df,model,r2 = boost(df)\n",
    "\n",
    "print(Fore.GREEN,'\\nr2_score = ',r2,'%')\n",
    "\n",
    "print('% error : ',abs(((df['Boost'].shift(+1)-df['Close'])/df['Close']*100)).mean(),'%')\n",
    "\n",
    "print('\\nEcart min : ',abs(((df['Boost'].shift(+1)-df['Close'])/df['Close']*100)).min(),'%')\n",
    "\n",
    "print('\\nEcart max : ',abs(((df['Boost'].shift(+1)-df['Close'])/df['Close']*100)).max(),'%')\n",
    "\n",
    "print('\\n',model.evals_result())\n",
    "\n",
    "pickle.dump(model, open('Boost_'+ticker+'-'+LaDate+'/'+ticker+'_boost.dat', \"wb\"))\n",
    "\n",
    "tmps22=round(time.time()-tmps55,2)\n",
    "print(Fore.BLUE,\"\\nTime for complete BOOST GENERATION = %f\" %tmps22,'seconds \\n',Style.RESET_ALL)\n",
    "\n",
    "df = df[['High','Low','Open','Volume','DeltaVol','Close','Varop_Spy','Varhl_spy','RSI',\\\n",
    "             '70 - RSI','RSI - 30','BBD_Delta_Up','delta5_8','delta8_10','delta10_12',\\\n",
    "             'delta12_15','delta15_30','delta30_35','delta35_40','delta40_45','delta45_50',\\\n",
    "             'Stoc_Slowk','Stoc_Slowd','KC_High','KC_Low','upper','lower','var_bollup_kchigh',\\\n",
    "             'var_bolllow_kclow','Aroon Up','Aroon Down','Delta Aroon',\\\n",
    "             'Boost','%Futur','target_up','target_down']]\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3909, 36), 195, 205)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,df['target_up'].sum(),df['target_down'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>DeltaVol</th>\n",
       "      <th>Close</th>\n",
       "      <th>Varop_Spy</th>\n",
       "      <th>Varhl_spy</th>\n",
       "      <th>RSI</th>\n",
       "      <th>70 - RSI</th>\n",
       "      <th>...</th>\n",
       "      <th>lower</th>\n",
       "      <th>var_bollup_kchigh</th>\n",
       "      <th>var_bolllow_kclow</th>\n",
       "      <th>Aroon Up</th>\n",
       "      <th>Aroon Down</th>\n",
       "      <th>Delta Aroon</th>\n",
       "      <th>Boost</th>\n",
       "      <th>%Futur</th>\n",
       "      <th>target_up</th>\n",
       "      <th>target_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>110.201</td>\n",
       "      <td>110.130</td>\n",
       "      <td>110.165</td>\n",
       "      <td>6862.92</td>\n",
       "      <td>219.54</td>\n",
       "      <td>110.161</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.071</td>\n",
       "      <td>52.703650</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.097428</td>\n",
       "      <td>-0.100640</td>\n",
       "      <td>0.101899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>-88.888889</td>\n",
       "      <td>109.108948</td>\n",
       "      <td>-0.019063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>110.176</td>\n",
       "      <td>110.132</td>\n",
       "      <td>110.161</td>\n",
       "      <td>2539.85</td>\n",
       "      <td>-4323.07</td>\n",
       "      <td>110.140</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.044</td>\n",
       "      <td>50.204228</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.095699</td>\n",
       "      <td>-0.099429</td>\n",
       "      <td>0.094463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>-77.777778</td>\n",
       "      <td>109.108948</td>\n",
       "      <td>-0.002724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>110.155</td>\n",
       "      <td>110.121</td>\n",
       "      <td>110.139</td>\n",
       "      <td>2048.59</td>\n",
       "      <td>-491.26</td>\n",
       "      <td>110.137</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.034</td>\n",
       "      <td>49.840591</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.094733</td>\n",
       "      <td>-0.097726</td>\n",
       "      <td>0.086651</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>109.108948</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>110.149</td>\n",
       "      <td>110.111</td>\n",
       "      <td>110.137</td>\n",
       "      <td>1637.67</td>\n",
       "      <td>-410.92</td>\n",
       "      <td>110.148</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.038</td>\n",
       "      <td>51.235320</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.104881</td>\n",
       "      <td>-0.092830</td>\n",
       "      <td>0.090397</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>109.108948</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>110.173</td>\n",
       "      <td>110.119</td>\n",
       "      <td>110.150</td>\n",
       "      <td>2267.76</td>\n",
       "      <td>630.09</td>\n",
       "      <td>110.153</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.054</td>\n",
       "      <td>51.890157</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.105245</td>\n",
       "      <td>-0.089840</td>\n",
       "      <td>0.087723</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>109.027405</td>\n",
       "      <td>-0.046299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               High      Low     Open   Volume  DeltaVol    Close  Varop_Spy  \\\n",
       "2020-01-17  110.201  110.130  110.165  6862.92    219.54  110.161      0.004   \n",
       "2020-01-17  110.176  110.132  110.161  2539.85  -4323.07  110.140      0.021   \n",
       "2020-01-17  110.155  110.121  110.139  2048.59   -491.26  110.137      0.002   \n",
       "2020-01-17  110.149  110.111  110.137  1637.67   -410.92  110.148     -0.011   \n",
       "2020-01-17  110.173  110.119  110.150  2267.76    630.09  110.153     -0.003   \n",
       "\n",
       "            Varhl_spy        RSI  70 - RSI  ...       lower  \\\n",
       "2020-01-17      0.071  52.703650         0  ...  110.097428   \n",
       "2020-01-17      0.044  50.204228         0  ...  110.095699   \n",
       "2020-01-17      0.034  49.840591         0  ...  110.094733   \n",
       "2020-01-17      0.038  51.235320         0  ...  110.104881   \n",
       "2020-01-17      0.054  51.890157         0  ...  110.105245   \n",
       "\n",
       "            var_bollup_kchigh  var_bolllow_kclow   Aroon Up  Aroon Down  \\\n",
       "2020-01-17          -0.100640           0.101899   0.000000   88.888889   \n",
       "2020-01-17          -0.099429           0.094463   0.000000   77.777778   \n",
       "2020-01-17          -0.097726           0.086651  55.555556   66.666667   \n",
       "2020-01-17          -0.092830           0.090397  44.444444   55.555556   \n",
       "2020-01-17          -0.089840           0.087723  33.333333   44.444444   \n",
       "\n",
       "            Delta Aroon       Boost    %Futur  target_up  target_down  \n",
       "2020-01-17   -88.888889  109.108948 -0.019063          0            0  \n",
       "2020-01-17   -77.777778  109.108948 -0.002724          0            0  \n",
       "2020-01-17   -11.111111  109.108948  0.009988          0            0  \n",
       "2020-01-17   -11.111111  109.108948  0.004539          0            0  \n",
       "2020-01-17   -11.111111  109.027405 -0.046299          0            0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  metrics, model_selection\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = 770\n",
    "np.random.seed(seed)\n",
    "X = df.iloc[:,:-4]\n",
    "y_up = df.iloc[:,-2].values\n",
    "y_down = df.iloc[:,-1].values\n",
    "X.astype(np.float64)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "'''y_up = np.array(y_up).reshape(-1,1)\n",
    "y_down = np.array(y_down).reshape(-1,1)'''\n",
    "\n",
    "Xtrain = X[:bloc1,:]\n",
    "Xtest = X[bloc1:,:]\n",
    "ytrain_up = y_up[:bloc1]\n",
    "ytest_up = y_up[bloc1:]\n",
    "ytrain_down = y_down[:bloc1]\n",
    "ytest_down = y_down[bloc1:]\n",
    "\n",
    "\n",
    "model_up = XGBClassifier(\n",
    "                            max_depth=80,\n",
    "                            learning_rate=1,\n",
    "                            n_estimators=100,\n",
    "                            verbosity=2,\n",
    "                            silent=None,\n",
    "                            objective='binary:logistic',\n",
    "                            booster='dart',\n",
    "                            n_jobs=1,\n",
    "                            nthread=None,\n",
    "                            gamma=1,\n",
    "                            min_child_weight=1,\n",
    "                            max_delta_step=1,\n",
    "                            subsample=1,\n",
    "                            colsample_bytree=1,\n",
    "                            colsample_bylevel=1,\n",
    "                            colsample_bynode=1,\n",
    "                            reg_alpha=1,\n",
    "                            reg_lambda=1,\n",
    "                            scale_pos_weight=1,\n",
    "                            base_score=0.99,\n",
    "                            random_state=1,\n",
    "                            seed=None,\n",
    "                            missing=None,).fit(Xtrain, ytrain_up)\n",
    "\n",
    "model_down = XGBClassifier(\n",
    "                            max_depth=3,\n",
    "                            learning_rate=0.1,\n",
    "                            n_estimators=100,\n",
    "                            verbosity=1,\n",
    "                            silent=None,\n",
    "                            objective='binary:logistic',\n",
    "                            booster='gbtree',\n",
    "                            n_jobs=1,\n",
    "                            nthread=None,\n",
    "                            gamma=0,\n",
    "                            min_child_weight=1,\n",
    "                            max_delta_step=0,\n",
    "                            subsample=1,\n",
    "                            colsample_bytree=1,\n",
    "                            colsample_bylevel=1,\n",
    "                            colsample_bynode=1,\n",
    "                            reg_alpha=0,\n",
    "                            reg_lambda=1,\n",
    "                            scale_pos_weight=1,\n",
    "                            base_score=0.5,\n",
    "                            random_state=0,\n",
    "                            seed=None,\n",
    "                            missing=None,).fit(Xtrain, ytrain_down)\n",
    "\n",
    "# use the model to make predictions with the test data\n",
    "\n",
    "y_pred_up = model_up.predict(Xtest)\n",
    "y_pred_down = model_down.predict(Xtest)\n",
    "# how did our model perform?\n",
    "\n",
    "count_misclassified = (ytest_up != y_pred_up).sum()\n",
    "\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "\n",
    "\n",
    "#yhat_up = model_up.predict_classes(Xtest)\n",
    "#yhat_down = model_down.predict_classes(Xtest)\n",
    "\n",
    "#score_up = model_up.evaluate(Xtest, ytest_up,verbose=1)\n",
    "#score_down = model_down.evaluate(Xtest, ytest_down,verbose=1)\n",
    "\n",
    "predict_up = model_up.predict(Xtest)\n",
    "predict_down = model_down.predict(Xtest)\n",
    "\n",
    "accuracy_up = accuracy_score(ytest_up, y_pred_up)\n",
    "accuracy_down = accuracy_score(ytest_down, y_pred_down)\n",
    "\n",
    "# La précision permet de mesurer la capacité du modèle à refuser résultats non-pertinents : vrais_positifs/(vrais_positifs+faux_positifs)\n",
    "precision_up = precision_score(ytest_up, y_pred_up)  \n",
    "precision_down = precision_score(ytest_down, y_pred_down) \n",
    "\n",
    "\n",
    "# Recall : (vrai_positifs/(vrais_positifs+faux_négatifs))\n",
    "recall_up = recall_score(ytest_up, y_pred_up) \n",
    "recall_down = recall_score(ytest_down, y_pred_down)  \n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy UP: {:.2f}'.format(accuracy_up*100))\n",
    "print('Accuracy DOWN: {:.2f}'.format(accuracy_down*100))\n",
    "#print('SCORE UP: {:.2f}'.format(score_up*100))\n",
    "#print('SCORE DOWN: {:.2f}'.format(score_down*100))\n",
    "print('Precision  UP: {:.2f}'.format(precision_up*100))\n",
    "print('Precision DOWN: {:.2f}'.format(precision_down*100))\n",
    "print('Recall UP: {:.2f}'.format(recall_up*100))\n",
    "print('Recall DOWN: {:.2f}'.format(recall_down*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmps55=time.time()\n",
    "print(Fore.BLUE,'\\nDeeping in blue for ',ticker,Style.RESET_ALL)\n",
    "\n",
    "resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "print(round(time.time()-tmps55,2),' secondes')\n",
    "\n",
    "if (precision_up*100) < 69 or (precision_down*100) < 69:\n",
    "    print('\\nTicker : ',ticker,'Precision Up :',precision_up*100,' ---- Precision Down',precision_down*100,'\\n')\n",
    "    print('Test Raté 1 fois. On remet cela. \\n')\n",
    "    tmps5=time.time()\n",
    "    resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "    print(round(time.time()-tmps5,2),' secondes')\n",
    "    \n",
    "if (precision_up*100) < 69 or (precision_down*100) < 69:\n",
    "    print('\\nTicker : ',ticker,'Precision Up :',precision_up*100,' ---- Precision Down',precision_down*100,'\\n')\n",
    "    print('Test Raté 2 fois. On remet cela. \\n')\n",
    "    tmps5=time.time()\n",
    "    resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "    print(round(time.time()-tmps5,2),' secondes')\n",
    "    \n",
    "if (precision_up*100) < 69 or (precision_down*100) < 69:\n",
    "    print('\\nTicker : ',ticker,'Precision Up :',precision_up*100,' ---- Precision Down',precision_down*100,'\\n')\n",
    "    print('Test Raté 3 fois. \\n')\n",
    "    print('Le ',Fore.BLUE,'Deep Learning',Style.RESET_ALL ,'de ',Fore.YELLOW,ticker,Style.RESET_ALL,' a échoué. Les modèles ne sont pas sauvegardés')\n",
    "    print(Fore.YELLOW,Back.MAGENTA,Style.DIM,'PASSAGE FINI!!!!!!',Style.RESET_ALL)\n",
    "    tmps2=round(time.time()-tmps55,2)\n",
    "    print (\"Job done in = %f\" %tmps2,'seconds')\n",
    "\n",
    "if (precision_up*100) >= 69 and (precision_down*100) >= 69:\n",
    "    save_model(model_up, model_down)\n",
    "\n",
    "    print('Le ',Fore.BLUE,'Deep Learning',Style.RESET_ALL ,'de ',Fore.YELLOW,ticker,Style.RESET_ALL,' a été effecué avec succès. Les modèles ont été sauvegardés')\n",
    "    print(Fore.YELLOW,Back.MAGENTA,Style.DIM,'PASSAGE FINI!!!!!!',Style.RESET_ALL)\n",
    "    tmps2=round(time.time()-tmps55,2)\n",
    "    print (\"Job done in = %f\" %tmps2,'seconds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
