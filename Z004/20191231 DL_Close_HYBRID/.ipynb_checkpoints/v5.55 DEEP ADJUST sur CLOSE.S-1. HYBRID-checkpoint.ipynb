{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearall():\n",
    "    all = [var for var in globals() if var[0] != \"_\"]\n",
    "    for var in all:\n",
    "        del globals()[var]\n",
    "clearall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Librairies...\n",
      "Librairies imported\n",
      "\n",
      "Global Optimized LumberJack Environment Motor 55\n",
      "LumberJack Jyss 5779(c)\n",
      "\u001b[34m °0Oo_D.A.G._26_oO0°\n",
      "BOOST SKAN 55 Version v5.55 \u001b[0m\n",
      "\n",
      "Sraping tickers\n",
      "Scrap -----> ok\n",
      "DATE ORIGINELLE DU DEBUT DE TOUT... : 2015-12-06\n",
      "\u001b[34m Deeping in blue from  A \u001b[0m\n",
      "811/811 [==============================] - 0s 47us/step\n",
      "811/811 [==============================] - 0s 47us/step\n",
      "153/153 [==============================] - 0s 23us/step\n",
      "153/153 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c828431af5b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision_up\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m69\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision_down\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m69\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mresultats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision_up\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision_down\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_up\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_down\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision_up\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m69\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision_down\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m69\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c828431af5b1>\u001b[0m in \u001b[0;36mdeep_learning\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0mhistory_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_up\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_up\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     model_down.compile(loss='binary_crossentropy',\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print('Importing Librairies...')\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from colorama import Fore, Back, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,roc_curve,confusion_matrix,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print('Librairies imported')\n",
    "print('')\n",
    "\n",
    "___Author___='LumberJack Jyss'\n",
    "print('Global Optimized LumberJack Environment Motor 55\\nLumberJack Jyss 5779(c)')\n",
    "print(Fore.BLUE,'°0Oo_D.A.G._26_oO0°')\n",
    "print('BOOST SKAN 55 Version v5.55',Style.RESET_ALL)\n",
    "\n",
    "#LaDate = input('Date de DL - YYYY-MM-DD ')\n",
    "LaDate = '2019-12-16'\n",
    "try:\n",
    "    os.mkdir('DL_'+LaDate)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir('Boost_'+LaDate)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('')\n",
    "print('Sraping tickers')\n",
    "constituents = pd.read_csv('New.csv')\n",
    "constituents = constituents.sort_values(['Symbol'])\n",
    "print('Scrap -----> ok')\n",
    "# PARAMETRES TEMPORELS INITIAUX\n",
    "start = '2015-12-06'  #LaDate[:2]+str(int(LaDate[2:4])-4)+'-'+LaDate[5:]\n",
    "end = LaDate\n",
    "print('DATE ORIGINELLE DU DEBUT DE TOUT... :',start)\n",
    "error = []\n",
    "\n",
    "try:\n",
    "    BasePrep = pd.read_csv('BasePrep'+LaDate+'.csv')\n",
    "    try:\n",
    "        BasePrep = BasePrep.drop(['Unnamed: 0'],axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    BasePrep = BasePrep[['Symbol','High','Low','Open','Volume','Close','Varop_Spy','Varhl_spy','RSI',\\\n",
    "         '70 - RSI','RSI - 30','BBD_Delta_Up','delta5_8','delta8_10','delta10_12',\\\n",
    "         'delta12_15','delta15_30','delta30_35','delta35_40','delta40_45','delta45_50',\\\n",
    "         'Stoc_Slowk','Stoc_Slowd','KC_High','KC_Low','upper','lower','var_bollup_kchigh',\\\n",
    "         'var_bolllow_kclow','Aroon Up','Aroon Down','Delta Aroon','Close.B','Close.S',\\\n",
    "         '%Futur','target_up','target_down']]\n",
    "except:\n",
    "    BasePrep = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "try :\n",
    "    amorceur = pd.read_csv('DL_'+LaDate+'/compteur'+LaDate+'.csv')\n",
    "    amorceur = amorceur.drop(['Unnamed: 0'],axis=1)\n",
    "    amorce = constituents[constituents['Symbol']==amorceur.iloc[-1,0]].index[-1]+1\n",
    "    compteur = pd.read_csv('DL_'+LaDate+'/compteur'+LaDate+'.csv')\n",
    "except:\n",
    "    amorce = 0\n",
    "    compteur = pd.DataFrame(columns = ['Symb.','Name','Sector','Precision_up','Precision_down'])\n",
    "       \n",
    "# SCRAPING DES DONNES BRUTES\n",
    "def scrap_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker,'yahoo',start,end)\n",
    "    df = df.drop(['Close'],axis=1)\n",
    "    df['Close'] = df['Adj Close']\n",
    "    df = df.drop(['Adj Close'],axis = 1)\n",
    "    return(df)\n",
    "\n",
    "def prepa_data(df):\n",
    "    rsi = talib.RSI(df['Close'],timeperiod=14)\n",
    "    stoc_slowk, stoc_slowd = talib.STOCH(df['High'],df['Low'],df['Close'])\n",
    "    upper, middle, lower =  talib.BBANDS(df['Close'], timeperiod=9, nbdevup=2, nbdevdn=2,matype=0)\n",
    "    sma5 = talib.SMA(df['Close'],timeperiod=5)\n",
    "    sma8 = talib.SMA(df['Close'],timeperiod=8)\n",
    "    sma10 = talib.SMA(df['Close'],timeperiod=10)\n",
    "    sma12 = talib.SMA(df['Close'],timeperiod=12)\n",
    "    sma15 = talib.SMA(df['Close'],timeperiod=15)\n",
    "    sma30 = talib.SMA(df['Close'],timeperiod=30)\n",
    "    sma35 = talib.SMA(df['Close'],timeperiod=35)\n",
    "    sma40 = talib.SMA(df['Close'],timeperiod=40)\n",
    "    sma45 = talib.SMA(df['Close'],timeperiod=45)\n",
    "    sma50 = talib.SMA(df['Close'],timeperiod=50)\n",
    "    atr = talib.ATR(df['High'],df['Low'],df['Close'],timeperiod=10)\n",
    "    delta5_8 = sma5 - sma8\n",
    "    delta8_10 = sma8 - sma10\n",
    "    delta10_12 = sma10 - sma12\n",
    "    delta12_15 = sma12 - sma15\n",
    "    delta15_30 = sma15 - sma30\n",
    "    delta30_35 = sma30 - sma35\n",
    "    delta35_40 = sma35 - sma40\n",
    "    delta40_45 = sma40 - sma45\n",
    "    delta45_50 = sma45 - sma50\n",
    "    bbdelta = upper - middle\n",
    "    price_bolup = df['Close'] - lower\n",
    "    price_bolow = df['Close'] - upper\n",
    "    Ema = talib.EMA(df['Close'],timeperiod=20)\n",
    "    KC_High = Ema + 2*atr\n",
    "    KC_Low = Ema - 2*atr\n",
    "    aroondown, aroonup = talib.AROON(df['High'], df['Low'], timeperiod=9)\n",
    "    aroon = aroonup - aroondown \n",
    "    rsi30_list = []\n",
    "    rsi70_list = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        rsi70_list.append(70 - rsi[i])\n",
    "        rsi30_list.append(rsi[i] - 30)\n",
    "        \n",
    "    varop_spy = df['Open'] - df['Close']\n",
    "    varhl_spy = df['High'] - df['Low']\n",
    "    df['Varop_Spy'] = varop_spy\n",
    "    df['Varhl_spy'] = varhl_spy\n",
    "    df['RSI'] = rsi\n",
    "    df['70 - RSI'] = np.array(rsi70_list)\n",
    "    df['RSI - 30'] = np.array(rsi30_list)\n",
    "    df['BBD_Delta_Up'] = bbdelta\n",
    "    df['delta5_8'] = delta5_8\n",
    "    df['delta8_10'] = delta8_10\n",
    "    df['delta10_12'] = delta10_12\n",
    "    df['delta12_15'] = delta12_15\n",
    "    df['delta15_30'] = delta15_30\n",
    "    df['delta30_35'] = delta30_35\n",
    "    df['delta35_40'] = delta35_40\n",
    "    df['delta40_45'] = delta40_45\n",
    "    df['delta45_50'] = delta45_50\n",
    "    df['Stoc_Slowk'] = stoc_slowk\n",
    "    df['Stoc_Slowd'] = stoc_slowd\n",
    "    df['KC_High'] = KC_High\n",
    "    df['KC_Low'] = KC_Low\n",
    "    df['upper'] = upper\n",
    "    df['lower'] = lower\n",
    "    df['var_bollup_kchigh'] = upper-KC_High\n",
    "    df['var_bolllow_kclow'] = lower-KC_Low\n",
    "    df['Aroon Up'] = aroonup\n",
    "    df['Aroon Down'] = aroondown\n",
    "    df['Delta Aroon'] = aroon\n",
    "    up = []\n",
    "    down = []\n",
    "    df = df.dropna()\n",
    "    df['%Futur'] = ((df['Close.S']-df['Close']) *100) / (df['Close'])\n",
    "    for i in range(0,df.shape[0]):\n",
    "        if df.iloc[i]['%Futur'] > 0.5 :\n",
    "            up.append(1)\n",
    "            down.append(0)\n",
    "        elif df.iloc[i]['%Futur'] < -0.5:\n",
    "            up.append(0)\n",
    "            down.append(1)\n",
    "        else:\n",
    "            up.append(0)\n",
    "            down.append(0)\n",
    "        \n",
    "    df['target_up'] = up  \n",
    "    df['target_down'] = down \n",
    "    #df = df.dropna()\n",
    "    \n",
    "    df = df[['High','Low','Open','Volume','Close','Varop_Spy','Varhl_spy','RSI',\\\n",
    "             '70 - RSI','RSI - 30','BBD_Delta_Up','delta5_8','delta8_10','delta10_12',\\\n",
    "             'delta12_15','delta15_30','delta30_35','delta35_40','delta40_45','delta45_50',\\\n",
    "             'Stoc_Slowk','Stoc_Slowd','KC_High','KC_Low','upper','lower','var_bollup_kchigh',\\\n",
    "             'var_bolllow_kclow','Aroon Up','Aroon Down','Delta Aroon','Close.B','Close.S',\\\n",
    "             '%Futur','target_up','target_down']]\n",
    "        \n",
    "    return(df)\n",
    "\n",
    "def boost(df):\n",
    "    X = df.copy()\n",
    "    X = X.drop(['Close'],axis=1)\n",
    "    X['Close'] = df['Close']\n",
    "    y = X.iloc[:,-1]\n",
    "    Xtrain = X.iloc[:-2,:-1]\n",
    "    Xtest = X.iloc[-2:-1,:-1]\n",
    "    yshift = y.shift(-1)\n",
    "    ytrain = yshift.iloc[:-2]\n",
    "    ytest = yshift.iloc[-2:-1]\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=20000, learning_rate=1, gamma=1, subsample=1, colsample_bytree=1, max_depth=100,objective='reg:squarederror')\n",
    "\n",
    "    model.fit( Xtrain, ytrain, early_stopping_rounds=150, eval_set=[(Xtest, ytest)], verbose=0)\n",
    "\n",
    "    ytrain_pred = model.predict(Xtrain)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "\n",
    "    pred = model.predict(X.iloc[:,:-1])\n",
    "\n",
    "    df['Close.B'] = pred\n",
    "    df = df.dropna()\n",
    "    return(df,model)\n",
    "\n",
    "    \n",
    "def deep_learning(df):\n",
    "    X = df.iloc[:,:-4]\n",
    "    y_up = df.iloc[:,-2].values\n",
    "    y_down = df.iloc[:,-1].values\n",
    "    X.astype(np.float64)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    y_up = np.array(y_up).reshape(-1,1)\n",
    "    y_down = np.array(y_down).reshape(-1,1)\n",
    "\n",
    "    Xtrain = X[:bloc1,:]\n",
    "    Xtest = X[bloc1:,:]\n",
    "    ytrain_up = y_up[:bloc1,:]\n",
    "    ytest_up = y_up[bloc1:,:]\n",
    "    ytrain_down = y_down[:bloc1,:]\n",
    "    ytest_down = y_down[bloc1:,:]\n",
    "\n",
    "    seed = 770\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ytrain_up = ytrain_up.reshape(ytrain_up.shape[0],)\n",
    "    ytrain_down = ytrain_down.reshape(ytrain_down.shape[0],)\n",
    "\n",
    "    Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1])\n",
    "\n",
    "    model_up = Sequential()\n",
    "    # Add an input layer \n",
    "    model_up.add(Dense(50, activation='relu'))\n",
    "    # Add one hidden layer \n",
    "    model_up.add(Dense(23, activation='relu'))\n",
    "    # Add an output layer \n",
    "    model_up.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model_down = Sequential()\n",
    "    # Add an input layer \n",
    "    model_down.add(Dense(50, activation='relu'))\n",
    "    # Add one hidden layer \n",
    "    model_down.add(Dense(23, activation='relu'))\n",
    "    # Add an output layer \n",
    "    model_down.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model_up.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', #rmsprop\n",
    "                  metrics=['accuracy','mse'])\n",
    "    \n",
    "              \n",
    "\n",
    "    history_up = model_up.fit(Xtrain, ytrain_up,epochs=280, batch_size=8, verbose=0)\n",
    "    \n",
    "    model_down.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', #rmsprop\n",
    "                  metrics=['accuracy','mse'])\n",
    "\n",
    "    history_down = model_down.fit(Xtrain, ytrain_down,epochs=280, batch_size=8, verbose=0)\n",
    "    \n",
    "\n",
    "    train_acc_up = model_up.evaluate(Xtrain, ytrain_up,verbose=1)\n",
    "    train_acc_down = model_down.evaluate(Xtrain, ytrain_down,verbose=1)\n",
    "\n",
    "    yhat_up = model_up.predict_classes(Xtest)\n",
    "    yhat_down = model_down.predict_classes(Xtest)\n",
    "\n",
    "    score_up = model_up.evaluate(Xtest, ytest_up,verbose=1)\n",
    "    score_down = model_down.evaluate(Xtest, ytest_down,verbose=1)\n",
    "\n",
    "    predict_up = model_up.predict(Xtest)\n",
    "    predict_down = model_down.predict(Xtest)\n",
    "\n",
    "    accuracy_up = accuracy_score(ytest_up, yhat_up)\n",
    "    accuracy_down = accuracy_score(ytest_down, yhat_down)\n",
    "\n",
    "    # La précision permet de mesurer la capacité du modèle à refuser résultats non-pertinents : vrais_positifs/(vrais_positifs+faux_positifs)\n",
    "    precision_up = precision_score(ytest_up, yhat_up)  \n",
    "    precision_down = precision_score(ytest_down, yhat_down) \n",
    "\n",
    "\n",
    "    # Recall : (vrai_positifs/(vrais_positifs+faux_négatifs))\n",
    "    recall_up = recall_score(ytest_up, yhat_up) \n",
    "    recall_down = recall_score(ytest_down, yhat_down) \n",
    "\n",
    "\n",
    "    resultats = pd.DataFrame()\n",
    "    resultats['Date'] = df.index[bloc1:]\n",
    "    resultats.index= df.index[bloc1:]\n",
    "    resultats['Move Up'] = yhat_up\n",
    "    resultats['Confiance up'] = (predict_up)*100\n",
    "    resultats['Move Down'] = yhat_down\n",
    "    resultats['Confiance Down'] = (predict_down)*100\n",
    "    resultats['Actual'] = df.iloc[bloc1:]['Close']\n",
    "    resultats['Actual.S'] = df.iloc[bloc1:]['Close.S']\n",
    "    open_S = df['Open'].shift(-1)\n",
    "    resultats['Open.S'] = open_S.iloc[bloc1:]\n",
    "    dmp_cp=[]\n",
    "    dmp_cp = ((resultats['Confiance up']-resultats['Confiance Down'])/(resultats['Confiance up']+resultats['Confiance Down'])*100)\n",
    "    resultats['DMP_CP'] = dmp_cp\n",
    "    \n",
    "    return(resultats,precision_up,precision_down,model_up,model_down,scaler)\n",
    "\n",
    "\n",
    "def save_model(model_up,model_down):\n",
    "    savename = 'DL_'+LaDate+'/Save_'+ticker\n",
    "    # serialize model to YAML\n",
    "    model_up_yaml = model_up.to_yaml()\n",
    "    model_down_yaml = model_down.to_yaml()\n",
    "    with open(savename+\"_up.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_up_yaml)\n",
    "    with open(savename+\"_down.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_down_yaml)\n",
    "    # serialize weights to HDF5\n",
    "    model_up.save_weights(savename+\"_up.h5\")\n",
    "    model_down.save_weights(savename+\"_down.h5\")\n",
    "    \n",
    "########################\n",
    "#### MAIN SKAN55 #######\n",
    "########################\n",
    "ticker_list = compteur['Symb.'].tolist()\n",
    "name_list = compteur['Name'].tolist()\n",
    "sector_list = compteur['Sector'].tolist()\n",
    "prec_up_list = compteur['Precision_up'].tolist()\n",
    "prec_down_list = compteur['Precision_down'].tolist()\n",
    "\n",
    "tmps55=time.time()\n",
    "try:\n",
    "    print(Fore.BLUE,'Deeping in blue from ',ticker_list[-1],Style.RESET_ALL)\n",
    "except:\n",
    "    print(Fore.BLUE,'Deeping in blue from ','A',Style.RESET_ALL)\n",
    "\n",
    "#for loop in range(amorce,amorce+20):\n",
    "for loop in range(amorce,len(constituents)):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        ticker = (constituents.iloc[loop]['Symbol'])\n",
    "        name = constituents.iloc[loop]['Name']\n",
    "        sector = constituents.iloc[loop]['Sector']\n",
    "\n",
    "        global delta,bloc1,bloc2\n",
    "        tmps1=time.time()\n",
    "        df = scrap_data(ticker,start,end)\n",
    "\n",
    "        tmps2=round(time.time()-tmps1,2)\n",
    "        delta = round(df.shape[0])\n",
    "        bloc1 = round(delta*0.80)\n",
    "        bloc2 = delta - bloc1\n",
    "        #df = boost(df)\n",
    "        df['Close.S'] = df['Close'].shift(-1)\n",
    "        df,model = boost(df)\n",
    "\n",
    "        pickle.dump(model, open('Boost_'+LaDate+'/'+ticker+'_boost.dat', \"wb\"))\n",
    "        df = prepa_data(df)\n",
    "\n",
    "        resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "\n",
    "        if (precision_up*100) < 69 or (precision_down*100) < 69:\n",
    "            resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "\n",
    "        if (precision_up*100) < 69 or (precision_down*100) < 69:\n",
    "            resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "\n",
    "        if (precision_up*100) < 69 or (precision_down*100) < 69:\n",
    "            print('Test precision raté 3 fois pour le ticker ',ticker)\n",
    "            continue\n",
    "\n",
    "        df['Symbol'] = ticker\n",
    "        df = df[['Symbol','High','Low','Open','Volume','Close','Varop_Spy','Varhl_spy','RSI',\\\n",
    "             '70 - RSI','RSI - 30','BBD_Delta_Up','delta5_8','delta8_10','delta10_12',\\\n",
    "             'delta12_15','delta15_30','delta30_35','delta35_40','delta40_45','delta45_50',\\\n",
    "             'Stoc_Slowk','Stoc_Slowd','KC_High','KC_Low','upper','lower','var_bollup_kchigh',\\\n",
    "             'var_bolllow_kclow','Aroon Up','Aroon Down','Delta Aroon','Close.B','Close.S',\\\n",
    "             '%Futur','target_up','target_down']]\n",
    "\n",
    "        BasePrep = pd.concat((BasePrep,df))\n",
    "\n",
    "        df = df.drop(['Symbol'],axis=1)\n",
    "\n",
    "        ticker_list.append(ticker)\n",
    "        name_list.append(name)\n",
    "        sector_list.append(sector)\n",
    "        prec_up_list.append(round(precision_up*100,2))\n",
    "        prec_down_list.append(round(precision_down*100,2))\n",
    "        save_model(model_up, model_down)\n",
    "\n",
    "        print('Le ',Fore.BLUE,'Deep Learning',Style.RESET_ALL ,'de ',Fore.YELLOW,ticker,Style.RESET_ALL,' a été effecué avec succès. Les modèles ont été sauvegardés')\n",
    "\n",
    "    except:\n",
    "        print(Fore.RED,'Problème loop : ',loop,Style.RESET_ALL)\n",
    "        error.append((loop,ticker))\n",
    "         \n",
    "        continue\n",
    "\n",
    "print(Fore.YELLOW,Back.BLUE,'Longueur des listes pour vérification : ',len(ticker_list),len(name_list),len(sector_list),Style.RESET_ALL)\n",
    "\n",
    "compteur = pd.DataFrame(columns = ['Symb.','Name','Sector'])\n",
    "\n",
    "compteur['Symb.'] = ticker_list\n",
    "\n",
    "compteur['Name'] = name_list\n",
    "\n",
    "compteur['Sector'] = sector_list\n",
    "\n",
    "compteur['Precision_up'] = prec_up_list\n",
    "\n",
    "compteur['Precision_down'] = prec_down_list\n",
    "\n",
    "compteur.to_csv('DL_'+LaDate+'/compteur'+LaDate+'.csv')\n",
    "\n",
    "BasePrep.to_csv('BasePrep'+LaDate+'.csv')\n",
    "\n",
    "print(Fore.YELLOW,Back.MAGENTA,Style.DIM,'PASSAGE FINI!!!!!!',Style.RESET_ALL)\n",
    "tmps2=round(time.time()-tmps55,2)\n",
    "print (\"Job done in = %f\" %tmps2,'seconds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close.S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-12-07</th>\n",
       "      <td>41.099998</td>\n",
       "      <td>40.540001</td>\n",
       "      <td>40.919998</td>\n",
       "      <td>2004500.0</td>\n",
       "      <td>39.091465</td>\n",
       "      <td>39.542896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-08</th>\n",
       "      <td>41.279999</td>\n",
       "      <td>40.419998</td>\n",
       "      <td>40.610001</td>\n",
       "      <td>4331800.0</td>\n",
       "      <td>39.542896</td>\n",
       "      <td>39.360390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-09</th>\n",
       "      <td>41.799999</td>\n",
       "      <td>40.910000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>4133300.0</td>\n",
       "      <td>39.360390</td>\n",
       "      <td>39.619732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-10</th>\n",
       "      <td>41.660000</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>40.959999</td>\n",
       "      <td>3709200.0</td>\n",
       "      <td>39.619732</td>\n",
       "      <td>38.601620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-11</th>\n",
       "      <td>40.750000</td>\n",
       "      <td>40.060001</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>2634400.0</td>\n",
       "      <td>38.601620</td>\n",
       "      <td>38.659252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 High        Low       Open     Volume      Close    Close.S\n",
       "Date                                                                        \n",
       "2015-12-07  41.099998  40.540001  40.919998  2004500.0  39.091465  39.542896\n",
       "2015-12-08  41.279999  40.419998  40.610001  4331800.0  39.542896  39.360390\n",
       "2015-12-09  41.799999  40.910000  41.250000  4133300.0  39.360390  39.619732\n",
       "2015-12-10  41.660000  40.650002  40.959999  3709200.0  39.619732  38.601620\n",
       "2015-12-11  40.750000  40.060001  40.750000  2634400.0  38.601620  38.659252"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
