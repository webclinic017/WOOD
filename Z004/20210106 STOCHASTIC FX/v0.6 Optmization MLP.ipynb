{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('DataSciences': conda)",
   "metadata": {
    "interpreter": {
     "hash": "7f9c69b77f8cb78a9d8b8acc2d09c3972908e6673afd8bfd04ee2f6acaaac495"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Importing Librairies...\nversion fxcmpy : 1.2.6\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import colorama as col\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from joblib import Parallel,delayed\n",
    "import datetime as dt\n",
    "import fxcmpy\n",
    "import pyttsx3\n",
    "import datetime as dt\n",
    "from Live import *\n",
    "from librairies.strategy import *\n",
    "from librairies.bt import *\n",
    "from sklearn.metrics import accuracy_score, make_scorer, precision_score, recall_score, precision_recall_curve, confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler,quantile_transform,PolynomialFeatures\n",
    "engine = pyttsx3.init()\n",
    "print('version fxcmpy :',fxcmpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_token = 'dbdc379ce7761772c662c3e92250a0ae38385b2c'\n",
    "_server = 'demo'\n",
    "_user_id = 'D261282181'\n",
    "_compte = '01215060'\n",
    "_password = 'waXz1'\n",
    "\n",
    "_period = 'm15'\n",
    "_name = 'MLPClassifier'\n",
    "\n",
    "TICKER_LIST = ['EUR/USD']\n",
    "x = TICKER_LIST[0]\n",
    "TIK = ['JPY','CHF','CAD','GBP','AUD','NZD','SEK','NOK','MXN','ZAR','TRY','ILS','CNH','USD','HKD']\n",
    "RATE = [105.4,0.8989,1.276,0.877,0.7676,0.7201,8.3684,8.5238,20.09,14.81,7.03,3.28,6.458,1,7.7527]\n",
    "df_ratefx = pd.DataFrame(index=TIK)\n",
    "df_ratefx['rate'] = RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conX():\n",
    "    con = fxcmpy.fxcmpy(access_token=_token, log_level='error',server=_server)\n",
    "    if con.is_connected() == True:\n",
    "        print(col.Fore.GREEN+'Connexion établie'+col.Style.RESET_ALL)\n",
    "        print('Compte utilisé : ',con.get_account_ids())\n",
    "    else:\n",
    "        print(col.Fore.RED+'Connexion non établie'+col.Style.RESET_ALL)\n",
    "    return(con)\n",
    "\n",
    "def deconX(con):\n",
    "    con = con.close()\n",
    "    if con.is_connected() == True:\n",
    "        print(col.Fore.GREEN+'Connexion non intérrompue'+col.Style.RESET_ALL)\n",
    "        print('Compte utilisé : ',con.get_account_ids())\n",
    "    else:\n",
    "        print(col.Fore.RED+'Connexion intérrompue'+col.Style.RESET_ALL)\n",
    "    return()\n",
    "\n",
    "def scrap_hist(ticker,invers = 'non'):\n",
    "    #_debut = pd.to_datetime((dt.datetime.now()-dt.timedelta(minutes=3987165)).strftime('%Y-%m-%d'))\n",
    "    #_fin = pd.to_datetime((dt.datetime.now().strftime('%Y-%m-%d')))\n",
    "    data = con.get_candles(ticker,period=_period,start=_debut,end=_fin)\n",
    "    data['Open'] = (data['bidopen']+data['askopen'])/2\n",
    "    data['High'] = (data['bidhigh']+data['askhigh'])/2\n",
    "    data['Low'] = (data['bidlow']+data['asklow'])/2\n",
    "    data['Close'] = (data['bidclose']+data['askclose'])/2\n",
    "    return(data)\n",
    "\n",
    "def buy(df_all):\n",
    "    print(dt.datetime.now())\n",
    "    ##### BUY \n",
    "    _price = round(con.get_candles(x,period='m15',number=1).askclose[-1],5)\n",
    "    _time = con.get_candles(x,period='m15',number=1).index[-1]\n",
    "    _amount = 50 \n",
    "    _limit = round(_price + _price * 0.004,5)\n",
    "    _stop = round(_price  - _price * 0.002,5)\n",
    "    _atmarket = 3\n",
    "    order = con.open_trade(symbol=x,is_buy=True, is_in_pips=False, amount=20, time_in_force='IOC',order_type='MarketRange',limit=_limit,stop=_stop, at_market=3)\n",
    "    print(\" Bougie de l'opération d'éxecution\",col.Fore.BLUE,_time,col.Style.RESET_ALL)\n",
    "    print(col.Fore.GREEN,'Achat sur le ticker',col.Fore.YELLOW,x,col.Fore.GREEN,'demandé à ',col.Fore.CYAN,_price,col.Style.RESET_ALL)\n",
    "\n",
    "def sell(df_all):\n",
    "    print(dt.datetime.now())\n",
    "    _atmarket = 3\n",
    "    _price = round(con.get_candles(x,period='m15',number=1).bidclose[-1],5)\n",
    "    _amount = 50 \n",
    "    _stop = round(_price + _price * 0.002,5)\n",
    "    _limit = round(_price  - _price * 0.004,5)\n",
    "    order = con.open_trade(symbol=x,is_buy=False, is_in_pips=False, amount=20, time_in_force='IOC',order_type='MarketRange',limit=_limit,stop=_stop, at_market=3)\n",
    "    print(\" Bougie de l'opération d'éxecution\",col.Fore.BLUE,_time,col.Style.RESET_ALL)\n",
    "    print(col.Fore.RED,'Vente sur le ticker',col.Fore.YELLOW,x,col.Fore.RED,'demandé à ',col.Fore.CYAN,_price,col.Style.RESET_ALL)\n",
    "\n",
    "    #expiration = (dt.datetime.now() + dt.timedelta(hours=4)).strftime(format='%Y-%m-%d %H:%M'))\n",
    "    return()\n",
    "\n",
    "def close():\n",
    "    con.close_all_for_symbol(x)\n",
    "    return()\n",
    "\n",
    "def init_df():\n",
    "    _path = 'JOBLIB/Ticker_'+_period+'/df_'+x.replace('/','')\n",
    "    df_all = joblib.load('JOBLIB/Built_bases/df_all')\n",
    "    df_all = df_all[df_all.Symbol==x.replace('/','')]\n",
    "    df_all = df_all[['Close','CloseAsk','CloseBid','High','HighAsk','HighBid','Low','LowAsk','LowBid','Open','OpenAsk','OpenBid','Symbol','Date']]\n",
    "    _fin = dt.datetime.now()\n",
    "    _deb = df_all.index[-1]\n",
    "    _debut = dt.datetime(_deb.year,_deb.month,_deb.day,_deb.hour,_deb.minute)\n",
    "    addon = con.get_candles(x,period='m15',start=_debut,end=_fin).drop(['tickqty'],axis=1)\n",
    "    addon = addon.rename(columns={'bidopen':'OpenBid','bidclose':'CloseBid','bidhigh':'HighBid','bidlow':'LowBid','askopen':'OpenAsk','askclose':'CloseAsk','askhigh':'HighAsk','asklow':'LowAsk'})\n",
    "    addon['Open'] = (addon.OpenAsk + addon.OpenBid)/2\n",
    "    addon['High'] = (addon.HighAsk + addon.HighBid)/2\n",
    "    addon['Low'] = (addon.LowAsk + addon.LowBid)/2\n",
    "    addon['Close'] = (addon.CloseAsk + addon.CloseBid)/2\n",
    "    addon['Symbol'] = x.replace('/','')\n",
    "    addon['Date'] = addon.index\n",
    "    addon['Date'] = pd.to_datetime(addon['Date'].dt.strftime(date_format='%Y-%m-%d'))\n",
    "    df_all = df_all.append(addon.iloc[1:,:])\n",
    "    df_all['WE'] = np.where(((df_all.index.weekday == 5) | (df_all.index.weekday == 6)),None,df_all.index.weekday)\n",
    "    df_all = df_all.dropna()\n",
    "    df_all =df_all.drop(['WE'],axis=1)\n",
    "    joblib.dump(df_all,_path)\n",
    "    return(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Global Optimized LumberJack Environment Motor for For_Ex\n",
      "LumberJack Jyss 5781(c)\n",
      "\u001b[34m °0Oo_D.A.G._26_oO0°\n",
      "\u001b[33m \u001b[44m --- Bigfoot 1. #v0.60 --- \u001b[0m\n",
      "\n",
      "\u001b[32mConnexion établie\u001b[0m\n",
      "Compte utilisé :  [1277536]\n",
      "\u001b[32mConnexion établie\u001b[0m\n",
      "Compte utilisé :  [1277536]\n",
      "Base Chargée.\n",
      "Construction de la base...\n",
      "EUR/USD\n",
      "\n",
      "\u001b[36m ###############################################################################################\n",
      " #################################### TRAIN/TEST WITHOUT AI ####################################\n",
      " ############################################################################################### \u001b[0m\n",
      "Librairies imported\n",
      "\n",
      "Début des opérations horodatée à 2021-02-17 14:54:37.551463\n",
      "\n",
      "Chargement de la nouvelle base\n",
      "\n",
      "\n",
      "\u001b[35m Le rate du ticker EUR/USD est à  1.0 \u001b[0m\n",
      "Bases chargées\n",
      "TETEL process effectué\n",
      "\u001b[36m ENTERING THE BACKTEST \u001b[0m\n",
      "100%|██████████| 179788/179788 [00:12<00:00, 14950.15it/s]\n",
      "\u001b[34m For ticker \u001b[33m EUR/USD \u001b[0m\n",
      "\u001b[35m \n",
      "Total Profit & Loss : $ \u001b[31m -259152.0 . En  2486 \u001b[0m  transactions.\n",
      "\u001b[32m \n",
      "Winners Number : 808 \u001b[0m\n",
      "\u001b[31m \n",
      "Loosers number : 1678 \u001b[0m\n",
      "BT's execution time 0:00:18.448414\n",
      "\u001b[33m EUR/USD \u001b[34m results \u001b[0m\n",
      "\u001b[35m Tested Period 2013-08-30 02:00:00  à 2021-02-17 13:45:00 \u001b[0m\n",
      "\u001b[36m Total Number of trades 2486 \u001b[0m\n",
      "Started Cash : 200000\n",
      "P&L in currency: \u001b[31m -259152.0$ \u001b[0m\n",
      "P&L in %: \u001b[31m -129.58% \u001b[0m\n",
      "Average trade duration 56.45\n",
      "# Winners  808.0\n",
      "# Winners long  414.0\n",
      "# Winners short  394.0\n",
      "# Loosers  1678.0\n",
      "# Loosers  long 882.0\n",
      "# Loosers  short 796.0\n",
      "Cumulated gains 1700572.0\n",
      "Cumulated losses -1959724.0\n",
      "\u001b[34m PROFIT FACTOR :  0.87 \u001b[0m\n",
      "\u001b[36m Winners Ratio : 32.5 % \u001b[0m\n",
      "Average Winners 2104.67\n",
      "% Average Winners 1.05\n",
      "Average Loosers -1167.89\n",
      "% Average Loosers -0.58\n",
      "Average pnl -104.24\n",
      "% Average pnl -0.16\n",
      "Number of opened trades 2486\n",
      "Number of closed trades 2486\n",
      "Max Exposure 1 x  400000 =  400000 $\n",
      "\n",
      "\u001b[34m ###############################################################################################\n",
      " #################################### DENOISING & ENHANCING ####################################\n",
      " ############################################################################################### \u001b[0m\n",
      "Librairies imported\n",
      "\n",
      "Début des opérations horodatée à 2021-02-17 14:54:59.434949\n",
      "\n",
      "Chargement de la nouvelle base\n",
      "\n",
      "\n",
      "\u001b[35m Le rate du ticker EUR/USD est à  1.0 \u001b[0m\n",
      "Bases chargées\n",
      "TETEL process effectué\n",
      "\u001b[36m ENTERING THE BACKTEST \u001b[0m\n",
      "100%|██████████| 179788/179788 [00:06<00:00, 26924.71it/s]\n",
      "\u001b[34m For ticker \u001b[33m EUR/USD \u001b[0m\n",
      "\u001b[35m \n",
      "Total Profit & Loss : $ \u001b[32m 1700572.0 . En  808 \u001b[0m  transactions.\n",
      "\u001b[32m \n",
      "Winners Number : 808 \u001b[0m\n",
      "\u001b[31m \n",
      "Loosers number : 0 \u001b[0m\n",
      "BT's execution time 0:00:13.033479\n",
      "\u001b[33m EUR/USD \u001b[34m results \u001b[0m\n",
      "\u001b[35m Tested Period 2013-08-30 02:00:00  à 2021-02-17 13:45:00 \u001b[0m\n",
      "\u001b[36m Total Number of trades 808 \u001b[0m\n",
      "Started Cash : 200000\n",
      "P&L  in currency: \u001b[32m 1700572.0$ \u001b[0m\n",
      "P&L in %: \u001b[32m 850.29% \u001b[0m\n",
      "Average trade duration 74.8\n",
      "# Winners  808.0\n",
      "# Winners long  414.0\n",
      "# Winners short  394.0\n",
      "# Loosers  0.0\n",
      "# Loosers  long 0.0\n",
      "# Loosers  short 0.0\n",
      "Cumulated gains 1700572.0\n",
      "Cumulated losses 0.0\n",
      "\u001b[34m PROFIT FACTOR :  inf \u001b[0m\n",
      "\u001b[36m Winners Ratio : 100.0 % \u001b[0m\n",
      "Average Winners 2104.67\n",
      "% Average Winners 1.05\n",
      "No looser\n",
      "Average pnl 2104.67\n",
      "% Average pnl 2.32\n",
      "Number of opened trades 808\n",
      "Number of closed trades 808\n",
      "Max Exposure 1 x  400000 =  400000 $\n",
      "CPU times: user 30.2 s, sys: 12.9 s, total: 43.1 s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "___Author___='LumberJack Jyss'\n",
    "print('Global Optimized LumberJack Environment Motor for For_Ex\\nLumberJack Jyss 5781(c)')\n",
    "print(col.Fore.BLUE,'°0Oo_D.A.G._26_oO0°')\n",
    "print(col.Fore.YELLOW,col.Back.BLUE,'--- Bigfoot 1. #v0.60 ---',col.Style.RESET_ALL)\n",
    "\n",
    "\n",
    "print('')\n",
    "engine.say(\" Initialization of Bigfoot 1, FX system\")\n",
    "engine.say(\"Bigfoot's Connexion to the a p i\")\n",
    "engine.runAndWait()\n",
    "\n",
    "try:\n",
    "    con.is_connected() == True\n",
    "    \n",
    "    engine.say(\"already Connected\")\n",
    "    engine.runAndWait()\n",
    "    print(col.Fore.GREEN+'Connexion rétablie'+col.Style.RESET_ALL)\n",
    "    print('Compte utilisé : ',con.get_account_ids())\n",
    "    print('')\n",
    "    \n",
    "except:\n",
    "    try:\n",
    "        con = conX()\n",
    "        con.is_connected() == True\n",
    "        print(col.Fore.GREEN+'Connexion établie'+col.Style.RESET_ALL)\n",
    "        print('Compte utilisé : ',con.get_account_ids())\n",
    "        engine.say(\"Bigfoot is Connected\")\n",
    "        engine.runAndWait()\n",
    "    except:\n",
    "        print(col.Fore.RED+'Connexion non établie'+col.Style.RESET_ALL)\n",
    "        engine.say(\"Mayday, mayday, Not Connected, mauzerfucker!\")\n",
    "        engine.say(\"Check your internet, and launch agin the Bigfoot\")\n",
    "        engine.runAndWait()\n",
    "        print('')\n",
    "        #os._exit(0)\n",
    "        con = deconX()\n",
    "        time.sleep(1)\n",
    "        con = conX()\n",
    "print('\\rChargement de la base...',end='',flush=True)\n",
    "engine.say(\"Ignition of Bigfoot. Loading the database.\")\n",
    "engine.runAndWait()\n",
    "#_path = 'JOBLIB/Ticker_'+_period+'/df_'+x.replace('/','')\n",
    "#df_all = joblib.load(_path)\n",
    "#df_all = df_all[df_all.Symbol==x.replace('/','')]\n",
    "#df_all = df_all[['Close','CloseAsk','CloseBid','High','HighAsk','HighBid','Low','LowAsk','LowBid','Open','OpenAsk','OpenBid','Symbol','Date']]\n",
    "#engine.say(\"Database is loaded. Ready to enter Live\")\n",
    "#engine.runAndWait()\n",
    "print('\\rBase Chargée.',end='',flush=True)\n",
    "\n",
    "engine.say(\"Building the base\")\n",
    "engine.runAndWait()\n",
    "print('\\nConstruction de la base...')\n",
    "##########\n",
    "df_all = init_df()\n",
    "\n",
    "\n",
    "if len(df_all) > 180000:\n",
    "    df_all = df_all.iloc[-180000:,:]\n",
    "\n",
    "if _period == 'H1':\n",
    "    df_all = timerange1D(df_all)\n",
    "    daily_all = get_daily(df_all,TICKER_LIST)\n",
    "\n",
    "##### Si la période n'est pas H1, on récupère d'abord les data en 1H pour tous les tickers, et on construit la base daily à partir du 1H => daily_all\n",
    "else:\n",
    "    _period='H1'\n",
    "    \n",
    "    df_all = timerange1D(df_all)\n",
    "    hourly_all = get_all_data(TICKER_LIST,_period='H1')\n",
    "    _fin = dt.datetime.now()\n",
    "    _deb = hourly_all.index[-1]\n",
    "    _debut = dt.datetime(_deb.year,_deb.month,_deb.day,_deb.hour)\n",
    "    hourly_add = con.get_candles(x,period='H1',start=_debut,end=_fin).drop(['tickqty'],axis=1) # df_all[df_all.index.minute==0] # scrap_hist(x)\n",
    "    hourly_add = hourly_add.rename(columns={'bidopen':'OpenBid','bidclose':'CloseBid','bidhigh':'HighBid','bidlow':'LowBid','askopen':'OpenAsk','askclose':'CloseAsk','askhigh':'HighAsk','asklow':'LowAsk'})\n",
    "    hourly_add['Open'] = (hourly_add.OpenAsk + hourly_add.OpenBid)/2\n",
    "    hourly_add['High'] = (hourly_add.HighAsk + hourly_add.HighBid)/2\n",
    "    hourly_add['Low'] = (hourly_add.LowAsk + hourly_add.LowBid)/2\n",
    "    hourly_add['Close'] = (hourly_add.CloseAsk + hourly_add.CloseBid)/2\n",
    "    hourly_add['Symbol'] = x.replace('/','')\n",
    "    hourly_all = hourly_all.append(hourly_add.iloc[1:,:])\n",
    "    hourly_all = timerange1D(hourly_all)\n",
    "    _period='m15'\n",
    "    daily_all = get_daily(hourly_all,TICKER_LIST)\n",
    "    #del hourly_all\n",
    "daily_all = timerange1W(daily_all)\n",
    "weekly_all = get_weekly(daily_all,TICKER_LIST)\n",
    "daily_all = adr(daily_all,_window=14)\n",
    "df_all = getadr(daily_all,df_all,TICKER_LIST)\n",
    "df_all = adrhnl(daily_all,df_all,TICKER_LIST)\n",
    "df_all = sma(df_all=df_all,_window=200)\n",
    "df_all = bollinger(df_all,_slow=20)\n",
    "df_all = slowstochastic(df_all,TICKER_LIST)\n",
    "df_all = ema(df_all,21,TICKER_LIST)\n",
    "df_all = ema(df_all,8,TICKER_LIST)\n",
    "weekly_all = pivot(weekly_all,TICKER_LIST)\n",
    "df_all = pivotimportdf(df_all,weekly_all,TICKER_LIST)\n",
    "df_all = atr(df_all,TICKER_LIST,14)\n",
    "df_all = rvi(df_all,TICKER_LIST,_window=14)\n",
    "df_all = sbgamma(df_all,TICKER_LIST)\n",
    "df_all = onhisma(df_all,TICKER_LIST,_window=5)\n",
    "df_all = onlosma(df_all,TICKER_LIST,_window=5)\n",
    "df_all = onhisma(df_all,TICKER_LIST,_window=21)\n",
    "df_all = onlosma(df_all,TICKER_LIST,_window=21)\n",
    "df_all = onhisma(df_all,TICKER_LIST,_window=34)\n",
    "df_all = onlosma(df_all,TICKER_LIST,_window=34)\n",
    "df_all = importohlc(df_all,weekly_all,TICKER_LIST,_suffix='_weekly')\n",
    "df_all = importohlc(df_all=df_all,other_all=daily_all,TICKER_LIST=TICKER_LIST,_suffix='_daily')\n",
    "df_all = stochastic(df_all)\n",
    "\n",
    "##### Signal is from strategy. This is potential good one. But we have to create the TRACKER column where the Signal where efficient\n",
    "\n",
    "# Proceed an MaxAbsScaler on features\n",
    "\n",
    "##### On backtest selon le ticker selectionné sur la période déterminée\n",
    "_fin = df_all.index[-1]\n",
    "_debut = df_all.index[0]\n",
    "print(x)\n",
    "\n",
    "_nb_bougie_exit = 2000000\n",
    "_trigger_reengage = 0\n",
    "_trigger_target = 1\n",
    "_trigger_invers = 0\n",
    "_trigger_sl = 1\n",
    "_verbose = 0\n",
    "_cash_ini = 200000\n",
    "_rate = 1/df_ratefx.loc[x[4:],'rate']\n",
    "backtest = df_all[df_all.Symbol == x.replace('/','')]\n",
    "_target =  0.004\n",
    "_exposure = 10\n",
    "_size = 400000\n",
    "_sl =  0.002\n",
    "_open_hour = 8 # day only\n",
    "_close_hour = 23 # day only\n",
    "_window = 0 # day only\n",
    "\n",
    "print()\n",
    "print(col.Fore.CYAN,'###############################################################################################')\n",
    "print(' #################################### TRAIN/TEST WITHOUT AI ####################################')\n",
    "print(' ###############################################################################################',col.Style.RESET_ALL)\n",
    "_year_bottom = _debut\n",
    "_year_top = _fin\n",
    "\n",
    "TRACKER,_nb_looser = bt(backtest,_year_bottom,_year_top,_nb_bougie_exit,_trigger_reengage,_trigger_target,_trigger_invers,_trigger_sl,_verbose,_cash_ini,\\\n",
    "        _rate,x,_target,_exposure,_size,_sl)\n",
    "\n",
    "print()\n",
    "print(col.Fore.BLUE,'###############################################################################################')\n",
    "print(' #################################### DENOISING & ENHANCING ####################################')\n",
    "print(' ###############################################################################################',col.Style.RESET_ALL)\n",
    "while _nb_looser > 0 :\n",
    "    \n",
    "    df_all['TRACKER'] = np.where(df_all.index.isin(TRACKER),1,0)\n",
    "    df_all['Valid'] = np.where(((df_all.Signal!=0)&(df_all.TRACKER==1)),1,0)\n",
    "    df_all['Signal'] = np.where(((df_all.Valid==1)&(df_all.Signal==1)),1,np.where(((df_all.Valid==1)&(df_all.Signal==-1)),-1,0))\n",
    "    backtest = df_all[df_all.Symbol == x.replace('/','')]\n",
    "    ##### Purification of signal by denoising and enhancing\n",
    "    TRACKER,_nb_looser = bt(backtest,_year_bottom,_year_top,_nb_bougie_exit,_trigger_reengage,_trigger_target,_trigger_invers,_trigger_sl,_verbose,_cash_ini,\\\n",
    "            _rate,x,_target,_exposure,_size,_sl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((180000, 59), (2893, 7), (582, 19))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_all.shape,daily_all.shape, weekly_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Featuring...\n",
      "Done\n",
      "CPU times: user 1.71 s, sys: 194 ms, total: 1.9 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Featuring...')\n",
    "   \n",
    "features = featuring(df_all)\n",
    "features = features.dropna()\n",
    "\n",
    "\n",
    "features['TRACKER'] = np.where(features.index.isin(TRACKER),1,0)\n",
    "\n",
    "features['Valid'] = np.where(((features.Signal!=0)&(features.TRACKER==1)),1,0) # Don't miss the point that even a Signal -1 must be considered as a good one by TRACKER\n",
    "\n",
    "_break = int(len(features)*0.7)\n",
    "features_train = features.iloc[:_break,:]\n",
    "features_test = features.iloc[_break:,:]\n",
    "\n",
    "features_train = scaling(features_train,scaler=MaxAbsScaler())\n",
    "\n",
    "features_test = scaling(features_test,scaler=MaxAbsScaler())\n",
    "\n",
    "features_train = quantile(features_train,quantile_transform)\n",
    "\n",
    "features_test = quantile(features_test,quantile_transform)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((179788, 47), (125851, 47), (53937, 47))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "features.shape, features_train.shape, features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[34m                           DEEP LEARNING \u001b[0m\n",
      "Signaux - Accuracy : 98.37 %\n",
      "Signaux - Precision : 3.37 %\n",
      "Signaux - Recall : 11.06 %\n",
      "Achat - F-measure: : 5.17 %\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       1.00      0.99      0.99     53720\n",
      "         Pos       0.03      0.11      0.05       217\n",
      "\n",
      "    accuracy                           0.98     53937\n",
      "   macro avg       0.52      0.55      0.52     53937\n",
      "weighted avg       0.99      0.98      0.99     53937\n",
      "\n",
      "            Bonnes_Estimations Mauvaises_Estimations\n",
      "vrais-réels                 24                   193\n",
      "faux-réels                 688                 53032\n",
      "\n",
      "\u001b[34m Signaux pour \u001b[33m EUR/USD \u001b[0m\n",
      "Vrais signaux trouvés    :  24\n",
      "Vrais signaux non trouvé : 193\n",
      "Total des vrais signaux  : 217\n",
      "\u001b[31m\n",
      "Precision :  11.06 %\n",
      "\u001b[32m\n",
      "Recall 88.94 %\n",
      "\u001b[0m\n",
      "CPU times: user 34min 4s, sys: 25min 24s, total: 59min 28s\n",
      "Wall time: 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(col.Fore.BLUE,'                          DEEP LEARNING',col.Style.RESET_ALL)\n",
    "_name = 'MLPClassifier'\n",
    "_model = MLPClassifier(hidden_layer_sizes=(300,10), activation='relu', solver='adam', alpha=0.000001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=400, shuffle=True, random_state=26, tol=0.0000001, verbose=False, warm_start=True, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.8, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "_model.fit(features_train.drop(['Date','Symbol','TRACKER','Valid','Signal'],axis=1),features_train.Valid)\n",
    "yhat = _model.predict(features_test.drop(['Date','Symbol','TRACKER','Valid','Signal'],axis=1))\n",
    "accu = round(accuracy_score(features_test.Valid, yhat) * 100,2)\n",
    "prec = round(precision_score(features_test.Valid, yhat,pos_label=1) * 100,2)\n",
    "recall = round(recall_score(features_test.Valid, yhat) * 100,2)\n",
    "f1 = round(f1_score(features_test.Valid, yhat) * 100,2)\n",
    "\n",
    "\n",
    "print('Signaux - Accuracy :' ,accu,'%')\n",
    "print('Signaux - Precision :',prec,'%')\n",
    "print('Signaux - Recall :', recall,'%')\n",
    "print('Achat - F-measure: :' ,f1,'%')\n",
    "print('\\n')\n",
    "print(classification_report(features_test.Valid, yhat, target_names=['Neg', 'Pos']))\n",
    "conf_matrix = pd.DataFrame(columns=['Bonnes_Estimations','Mauvaises_Estimations'])\n",
    "tt = confusion_matrix(features_test.Valid, yhat, labels=[1,0])    #_model.classes_)\n",
    "\n",
    "conf_matrix.loc['vrais-réels'] = tt[0]\n",
    "conf_matrix.loc['faux-réels'] = tt[1]\n",
    "\n",
    "print(conf_matrix)\n",
    "print()\n",
    "print(col.Fore.BLUE,'Signaux pour',col.Fore.YELLOW,x,col.Style.RESET_ALL)\n",
    "_tp = tt[0][0]\n",
    "_fn = tt[0][1]\n",
    "_prec = round((tt[0][0]/(tt[0][0]+tt[0][1]))*100,2)\n",
    "_rec = round((tt[0][1]/(tt[0][0]+tt[0][1]))*100,2)\n",
    "\n",
    "print('Vrais signaux trouvés    : ',tt[0][0])\n",
    "print('Vrais signaux non trouvé :',tt[0][1])\n",
    "print('Total des vrais signaux  :',tt[0][0]+tt[0][1])\n",
    "if _prec > 48 and prec > 48 :\n",
    "    print(col.Fore.GREEN)\n",
    "elif _prec < 18 or prec < 18 :\n",
    "    print(col.Fore.RED)\n",
    "else:\n",
    "    print(col.Fore.YELLOW)\n",
    "print('Precision : ',_prec,'%')\n",
    "if _rec > 69 and _rec > 69 :\n",
    "    print(col.Fore.GREEN)\n",
    "elif _rec < 51 or _rec < 51 :\n",
    "    print(col.Fore.RED)\n",
    "else:\n",
    "    print(col.Fore.YELLOW)\n",
    "print('Recall',_rec,'%')\n",
    "print(col.Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(col.Fore.BLUE,'                          DEEP LEARNING',col.Style.RESET_ALL)\n",
    "_name = 'MLPClassifier'\n",
    "_model = MLPClassifier(hidden_layer_sizes=(200,8), activation='relu', solver='adam', alpha=0.000001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=26, tol=0.0000001, verbose=False, warm_start=True, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.8, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "_model.fit(features_train.drop(['Date','Symbol','TRACKER','Valid','Signal'],axis=1),features_train.Valid)\n",
    "yhat = _model.predict(features_test.drop(['Date','Symbol','TRACKER','Valid','Signal'],axis=1))\n",
    "accu = round(accuracy_score(features_test.Valid, yhat) * 100,2)\n",
    "prec = round(precision_score(features_test.Valid, yhat,pos_label=1) * 100,2)\n",
    "recall = round(recall_score(features_test.Valid, yhat) * 100,2)\n",
    "f1 = round(f1_score(features_test.Valid, yhat) * 100,2)\n",
    "\n",
    "\n",
    "print('Signaux - Accuracy :' ,accu,'%')\n",
    "print('Signaux - Precision :',prec,'%')\n",
    "print('Signaux - Recall :', recall,'%')\n",
    "print('Achat - F-measure: :' ,f1,'%')\n",
    "print('\\n')\n",
    "print(classification_report(features_test.Valid, yhat, target_names=['Neg', 'Pos']))\n",
    "conf_matrix = pd.DataFrame(columns=['Bonnes_Estimations','Mauvaises_Estimations'])\n",
    "tt = confusion_matrix(features_test.Valid, yhat, labels=[1,0])    #_model.classes_)\n",
    "\n",
    "conf_matrix.loc['vrais-réels'] = tt[0]\n",
    "conf_matrix.loc['faux-réels'] = tt[1]\n",
    "\n",
    "print(conf_matrix)\n",
    "print()\n",
    "print(col.Fore.BLUE,'Signaux pour',col.Fore.YELLOW,x,col.Style.RESET_ALL)\n",
    "_tp = tt[0][0]\n",
    "_fn = tt[0][1]\n",
    "_prec = round((tt[0][0]/(tt[0][0]+tt[0][1]))*100,2)\n",
    "_rec = round((tt[0][1]/(tt[0][0]+tt[0][1]))*100,2)\n",
    "\n",
    "print('Vrais signaux trouvés    : ',tt[0][0])\n",
    "print('Vrais signaux non trouvé :',tt[0][1])\n",
    "print('Total des vrais signaux  :',tt[0][0]+tt[0][1])\n",
    "if _prec > 69 and prec > 69 :\n",
    "    print(col.Fore.GREEN)\n",
    "elif _prec < 51 or prec < 51 :\n",
    "    print(col.Fore.RED)\n",
    "else:\n",
    "    print(col.Fore.YELLOW)\n",
    "print('Precision : ',_prec,'%')\n",
    "if _rec > 69 and _rec > 69 :\n",
    "    print(col.Fore.GREEN)\n",
    "elif _rec < 51 or _rec < 51 :\n",
    "    print(col.Fore.RED)\n",
    "else:\n",
    "    print(col.Fore.YELLOW)\n",
    "print('Recall',_rec,'%')\n",
    "print(col.Style.RESET_ALL)\n",
    "\n",
    "\n",
    "##### On backtest selon le ticker selectionné sur la période déterminée\n",
    "\n",
    "print(x)\n",
    "\n",
    "print('Training done.\\nWaiting for the candle...')\n",
    "print()\n",
    "\n",
    "##########\n",
    "\n",
    "while dt.datetime.now().minute not in [0,15,30,45]:\n",
    "    print('\\rTicker tracké :',x,' ',dt.datetime.now(),end='',flush=True)\n",
    "    time.sleep(1)\n",
    "print()\n",
    "while con.get_candles(x,period=_period,start=dt.datetime(df_all.index[-1].year,df_all.index[-1].month,df_all.index[-1].day,df_all.index[-1].hour,df_all.index[-1].minute)\\\n",
    "        ,end=dt.datetime.now()).index[-1].minute != dt.datetime.now().minute:\n",
    "\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "_fin = dt.datetime.now()\n",
    "_deb = df_all.index[-1]\n",
    "_debut = dt.datetime(_deb.year,_deb.month,_deb.day,_deb.hour,_deb.minute)\n",
    "addon = con.get_candles(x,period='m15',start=_debut,end=_fin).drop(['tickqty'],axis=1)\n",
    "addon = addon.rename(columns={'bidopen':'OpenBid','bidclose':'CloseBid','bidhigh':'HighBid','bidlow':'LowBid','askopen':'OpenAsk','askclose':'CloseAsk','askhigh':'HighAsk','asklow':'LowAsk'})\n",
    "addon['Open'] = (addon.OpenAsk + addon.OpenBid)/2\n",
    "addon['High'] = (addon.HighAsk + addon.HighBid)/2\n",
    "addon['Low'] = (addon.LowAsk + addon.LowBid)/2\n",
    "addon['Close'] = (addon.CloseAsk + addon.CloseBid)/2\n",
    "addon['Symbol'] = x.replace('/','')\n",
    "addon['Date'] = addon.index\n",
    "addon['Date'] = pd.to_datetime(addon['Date'].dt.strftime(date_format='%Y-%m-%d'))\n",
    "df_all = df_all[['Close','CloseAsk','CloseBid','High','HighAsk','HighBid','Low','LowAsk','LowBid','Open','OpenAsk','OpenBid','Symbol','Date']]\n",
    "df_all = df_all.append(addon.iloc[1:,:])\n",
    "#df_all = df_all.iloc[-263570:,:]\n",
    "\n",
    "\n",
    "##### Si la période demandée est déjà H1, on peut construire directement la base daily pour tous les tickers => daily_all\n",
    "if _period == 'H1':\n",
    "    df_all = timerange1D(df_all)\n",
    "    daily_all = get_daily(df_all,TICKER_LIST)\n",
    "\n",
    "##### Si la période n'est pas H1, on récupère d'abord les data en 1H pour tous les tickers, et on construit la base daily à partir du 1H => daily_all\n",
    "else:\n",
    "    _period='H1'\n",
    "    df_all = timerange1D(df_all)\n",
    "    hourly_all = get_all_data(TICKER_LIST,_period='H1')\n",
    "    _fin = dt.datetime.now()\n",
    "    _deb = hourly_all.index[-1]\n",
    "    _debut = dt.datetime(_deb.year,_deb.month,_deb.day,_deb.hour)\n",
    "    hourly_add = con.get_candles(x,period='H1',start=_debut,end=_fin).drop(['tickqty'],axis=1) # df_all[df_all.index.minute==0] # scrap_hist(x)\n",
    "    hourly_add = hourly_add.rename(columns={'bidopen':'OpenBid','bidclose':'CloseBid','bidhigh':'HighBid','bidlow':'LowBid','askopen':'OpenAsk','askclose':'CloseAsk','askhigh':'HighAsk','asklow':'LowAsk'})\n",
    "    hourly_add['Open'] = (hourly_add.OpenAsk + hourly_add.OpenBid)/2\n",
    "    hourly_add['High'] = (hourly_add.HighAsk + hourly_add.HighBid)/2\n",
    "    hourly_add['Low'] = (hourly_add.LowAsk + hourly_add.LowBid)/2\n",
    "    hourly_add['Close'] = (hourly_add.CloseAsk + hourly_add.CloseBid)/2\n",
    "    hourly_add['Symbol'] = x.replace('/','')\n",
    "    hourly_all = hourly_all.append(hourly_add.iloc[1:,:])\n",
    "    hourly_all = timerange1D(hourly_all)\n",
    "    _period='m15'\n",
    "    daily_all = get_daily(hourly_all,TICKER_LIST)\n",
    "    #del hourly_all\n",
    "daily_all = timerange1W(daily_all)\n",
    "weekly_all = get_weekly(daily_all,TICKER_LIST)\n",
    "daily_all = adr(daily_all,_window=14)\n",
    "df_all = getadr(daily_all,df_all,TICKER_LIST)\n",
    "df_all = adrhnl(daily_all,df_all,TICKER_LIST)\n",
    "df_all = sma(df_all=df_all,_window=200)\n",
    "df_all = bollinger(df_all,_slow=20)\n",
    "df_all = slowstochastic(df_all,TICKER_LIST)\n",
    "df_all = ema(df_all,21,TICKER_LIST)\n",
    "df_all = ema(df_all,8,TICKER_LIST)\n",
    "weekly_all = pivot(weekly_all,TICKER_LIST)\n",
    "df_all = pivotimportdf(df_all,weekly_all,TICKER_LIST)\n",
    "df_all = atr(df_all,TICKER_LIST,14)\n",
    "df_all = rvi(df_all,TICKER_LIST,_window=14)\n",
    "df_all = sbgamma(df_all,TICKER_LIST)\n",
    "df_all = onhisma(df_all,TICKER_LIST,_window=5)\n",
    "df_all = onlosma(df_all,TICKER_LIST,_window=5)\n",
    "df_all = onhisma(df_all,TICKER_LIST,_window=21)\n",
    "df_all = onlosma(df_all,TICKER_LIST,_window=21)\n",
    "df_all = onhisma(df_all,TICKER_LIST,_window=34)\n",
    "df_all = onlosma(df_all,TICKER_LIST,_window=34)\n",
    "df_all = importohlc(df_all,weekly_all,TICKER_LIST,_suffix='_weekly')\n",
    "df_all = importohlc(df_all=df_all,other_all=daily_all,TICKER_LIST=TICKER_LIST,_suffix='_daily')\n",
    "\n",
    "df_all = stochastic(df_all)\n",
    "features = featuring(df_all)\n",
    "\n",
    "# And drop the nan\n",
    "features = features.dropna()\n",
    "##### Signal is from strategy. This is potential good one. But we have to create the TRACKER column where the Signal where efficient\n",
    "\n",
    "# Proceed an MaxAbsScaler on features\n",
    "features = scaling(features,scaler=MaxAbsScaler())\n",
    "\n",
    "features = quantile(features,quantile_transform)\n",
    "\n",
    "_valid = _model.predict(features.drop(['Date','Symbol','TRACKER','Valid','Signal'],axis=1))[-1]\n",
    "\n",
    "_signal = df_all.Signal[-1]\n",
    "\n",
    "print('\\nTest sur la bougie',features.index[-1])\n",
    "if _valid == 1 and _signal == 1 :\n",
    "    buy()\n",
    "\n",
    "elif _valid == 1 and _signal == -1 :\n",
    "    sell()\n",
    "\n",
    "else:\n",
    "    print('\\nnothing for',x)\n",
    "\n",
    "print()\n",
    "\n",
    "df_all = df_all[['Close','CloseAsk','CloseBid','High','HighAsk','HighBid','Low','LowAsk','LowBid','Open','OpenAsk','OpenBid','Symbol','Date']] "
   ]
  }
 ]
}