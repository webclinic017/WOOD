{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearall():\n",
    "    all = [var for var in globals() if var[0] != \"_\"]\n",
    "    for var in all:\n",
    "        del globals()[var]\n",
    "clearall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Librairies...\n"
     ]
    }
   ],
   "source": [
    "print('Importing Librairies...')\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from colorama import Fore, Back, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,roc_curve,confusion_matrix,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies imported\n",
      "\n",
      "Global Optimized LumberJack Environment Motor 55\n",
      "LumberJack Jyss 5779(c)\n",
      "\u001b[34m °0Oo_D.A.G._26_oO0°\n",
      "BOOST SKAN 55 Version v5.55 \u001b[0m\n",
      "\n",
      "Sraping tickers\n",
      "Scrap -----> ok\n",
      "DATE ORIGINELLE DU DEBUT DE TOUT... : 2016-02-07\n",
      "\u001b[34m Deeping in blue from  A \u001b[0m\n",
      "806/806 [==============================] - 0s 55us/step\n",
      "806/806 [==============================] - 0s 50us/step\n",
      "153/153 [==============================] - 0s 27us/step\n",
      "153/153 [==============================] - 0s 25us/step\n",
      "Le  \u001b[34m Deep Learning \u001b[0m de  \u001b[33m A \u001b[0m  a été effecué avec succès. Les modèles ont été sauvegardés\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-597016fb4369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepa_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mresultats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision_up\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision_down\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_up\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_down\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0maaa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision_up\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m69\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision_down\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m69\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-597016fb4369>\u001b[0m in \u001b[0;36mdeep_learning\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    230\u001b[0m                   metrics=['accuracy','mse'])\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mhistory_down\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_down\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain_down\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1218\u001b[0m                          \"Tensor.\" % (self._func_graph.name, i, str(arg)))\n\u001b[1;32m   1219\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_inputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m     \u001b[0mforward_backward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_forward_and_backward_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m     \u001b[0mforward_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_select_forward_and_backward_functions\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \"\"\"\n\u001b[1;32m   1364\u001b[0m     possible_gradient_type = _PossibleTapeGradientTypes(\n\u001b[0;32m-> 1365\u001b[0;31m         pywrap_tensorflow.TFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpossible_gradient_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_PossibleTapeGradientTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIRST_ORDER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/Lumberjack/lib/python3.6/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \"\"\"\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# simple value lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# otherwise, functional API: we're creating a new Enum type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print('Librairies imported')\n",
    "print('')\n",
    "\n",
    "___Author___='LumberJack Jyss'\n",
    "print('Global Optimized LumberJack Environment Motor 55\\nLumberJack Jyss 5779(c)')\n",
    "print(Fore.BLUE,'°0Oo_D.A.G._26_oO0°')\n",
    "print('BOOST SKAN 55 Version v5.55',Style.RESET_ALL)\n",
    "\n",
    "#LaDate = input('Date de DL - YYYY-MM-DD ')\n",
    "LaDate = '2020-02-07'\n",
    "try:\n",
    "    os.mkdir('DL_'+LaDate)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('')\n",
    "print('Sraping tickers')\n",
    "constituents = pd.read_csv('New.csv')\n",
    "constituents = constituents.sort_values(['Symbol'])\n",
    "print('Scrap -----> ok')\n",
    "# PARAMETRES TEMPORELS INITIAUX\n",
    "start = LaDate[:2]+str(int(LaDate[2:4])-4)+'-'+LaDate[5:]\n",
    "end = LaDate\n",
    "print('DATE ORIGINELLE DU DEBUT DE TOUT... :',start)\n",
    "error = []\n",
    "\n",
    "\n",
    "try :\n",
    "    amorceur = pd.read_csv('DL_'+LaDate+'/compteur'+LaDate+'.csv')\n",
    "    amorceur = amorceur.drop(['Unnamed: 0'],axis=1)\n",
    "    amorce = constituents[constituents['Symbol']==amorceur.iloc[-1,0]].index[-1]+1\n",
    "    compteur = pd.read_csv('DL_'+LaDate+'/compteur'+LaDate+'.csv')\n",
    "except:\n",
    "    amorce = 0\n",
    "    compteur = pd.DataFrame(columns = ['Symb.','Name','Sector','Precision_up','Precision_down'])\n",
    "       \n",
    "# SCRAPING DES DONNES BRUTES\n",
    "def scrap_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker,'yahoo',start,end)\n",
    "    df = df.drop(['Close'],axis=1)\n",
    "    df['Close'] = df['Adj Close']\n",
    "    df = df.drop(['Adj Close'],axis = 1)\n",
    "    return(df)\n",
    "\n",
    "def scrap_vix(start,end):\n",
    "    df1 = web.DataReader('^VIX','yahoo',start,end)\n",
    "    df1 = df1.drop(['Close'],axis=1)\n",
    "    df1['Close'] = df1['Adj Close']\n",
    "    df1 = df1.drop(['Adj Close'],axis = 1)\n",
    "    return(df1)\n",
    "\n",
    "def prepa_data(df,df1):\n",
    "    rsi = talib.RSI(df['Close'],timeperiod=14)\n",
    "    stoc_slowk, stoc_slowd = talib.STOCH(df['High'],df['Low'],df['Close'])\n",
    "    upper, middle, lower =  talib.BBANDS(df['Close'], timeperiod=9, nbdevup=2, nbdevdn=2,matype=0)\n",
    "    sma5 = talib.SMA(df['Close'],timeperiod=5)\n",
    "    sma8 = talib.SMA(df['Close'],timeperiod=8)\n",
    "    sma10 = talib.SMA(df['Close'],timeperiod=10)\n",
    "    sma12 = talib.SMA(df['Close'],timeperiod=12)\n",
    "    sma15 = talib.SMA(df['Close'],timeperiod=15)\n",
    "    sma30 = talib.SMA(df['Close'],timeperiod=30)\n",
    "    sma35 = talib.SMA(df['Close'],timeperiod=35)\n",
    "    sma40 = talib.SMA(df['Close'],timeperiod=40)\n",
    "    sma45 = talib.SMA(df['Close'],timeperiod=45)\n",
    "    sma50 = talib.SMA(df['Close'],timeperiod=50)\n",
    "    atr = talib.ATR(df['High'],df['Low'],df['Close'],timeperiod=10)\n",
    "    delta5_8 = sma5 - sma8\n",
    "    delta8_10 = sma8 - sma10\n",
    "    delta10_12 = sma10 - sma12\n",
    "    delta12_15 = sma12 - sma15\n",
    "    delta15_30 = sma15 - sma30\n",
    "    delta30_35 = sma30 - sma35\n",
    "    delta35_40 = sma35 - sma40\n",
    "    delta40_45 = sma40 - sma45\n",
    "    delta45_50 = sma45 - sma50\n",
    "    bbdelta = upper - middle\n",
    "    price_bolup = df['Close'] - lower\n",
    "    price_bolow = df['Close'] - upper\n",
    "    Ema = talib.EMA(df['Close'],timeperiod=20)\n",
    "    KC_High = Ema + 2*atr\n",
    "    KC_Low = Ema - 2*atr\n",
    "    aroondown, aroonup = talib.AROON(df['High'], df['Low'], timeperiod=9)\n",
    "    aroon = aroonup - aroondown \n",
    "    rsi30_list = []\n",
    "    rsi70_list = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        rsi70_list.append(70 - rsi[i])\n",
    "        rsi30_list.append(rsi[i] - 30)\n",
    "        \n",
    "    varop_spy = df['Open'] - df['Close']\n",
    "    varhl_spy = df['High'] - df['Low']\n",
    "    varop_vix = df1['Open'] - df['Close']\n",
    "    varhl_vix = df1['High'] - df['Low']\n",
    "    df['Varop_Spy'] = varop_spy\n",
    "    df['Varhl_spy'] = varhl_spy\n",
    "    df['Varop_vix'] = varop_vix\n",
    "    df['Varhl_vix'] = varhl_vix\n",
    "    df['RSI'] = rsi\n",
    "    df['70 - RSI'] = np.array(rsi70_list)\n",
    "    df['RSI - 30'] = np.array(rsi30_list)\n",
    "    df['BBD_Delta_Up'] = bbdelta\n",
    "    df['delta5_8'] = delta5_8\n",
    "    df['delta8_10'] = delta8_10\n",
    "    df['delta10_12'] = delta10_12\n",
    "    df['delta12_15'] = delta12_15\n",
    "    df['delta15_30'] = delta15_30\n",
    "    df['delta30_35'] = delta30_35\n",
    "    df['delta35_40'] = delta35_40\n",
    "    df['delta40_45'] = delta40_45\n",
    "    df['delta45_50'] = delta45_50\n",
    "    df['Stoc_Slowk'] = stoc_slowk\n",
    "    df['Stoc_Slowd'] = stoc_slowd\n",
    "    df['KC_High'] = KC_High\n",
    "    df['KC_Low'] = KC_Low\n",
    "    df['upper'] = upper\n",
    "    df['lower'] = lower\n",
    "    df['var_bollup_kchigh'] = upper-KC_High\n",
    "    df['var_bolllow_kclow'] = lower-KC_Low\n",
    "    df['Aroon Up'] = aroonup\n",
    "    df['Aroon Down'] = aroondown\n",
    "    df['Delta Aroon'] = aroon\n",
    "    \n",
    "    trend = []\n",
    "    \n",
    "    df = df.dropna()\n",
    "    df['%Futur'] = ((df['Close.S']-df['Close']) *100) / (df['Close'])\n",
    "    for i in range(0,df.shape[0]):\n",
    "        if df.iloc[i]['%Futur'] > 0.5 :\n",
    "            trend.append(1)\n",
    "        elif df.iloc[i]['%Futur'] < -0.5:\n",
    "            trend.append(0)\n",
    "        else:\n",
    "            utrend.append(0)\n",
    "        \n",
    "    df['target'] = trend  \n",
    "    #df = df.dropna()\n",
    "    \n",
    "    df = df[['High','Low','Open','Volume','Close','Varop_Spy','Varhl_spy','Varop_vix','Varhl_vix','RSI',\\\n",
    "             '70 - RSI','RSI - 30','BBD_Delta_Up','delta5_8','delta8_10','delta10_12',\\\n",
    "             'delta12_15','delta15_30','delta30_35','delta35_40','delta40_45','delta45_50',\\\n",
    "             'Stoc_Slowk','Stoc_Slowd','KC_High','KC_Low','upper','lower','var_bollup_kchigh',\\\n",
    "             'var_bolllow_kclow','Aroon Up','Aroon Down','Delta Aroon','Close.S',\\\n",
    "             '%Futur','target']]\n",
    "        \n",
    "    return(df)\n",
    "\n",
    "def boost(df):\n",
    "    limit = round(len(df)*.25)\n",
    "    X = df.copy()\n",
    "    X = X.drop(['Close'],axis=1)\n",
    "    X['Close'] = df['Close']\n",
    "    y = X.iloc[:,-1]\n",
    "    Xtrain = X.iloc[:-limit,:-1]\n",
    "    Xtest = X.iloc[-limit:-1,:-1]\n",
    "    yshift = y.shift(-1)\n",
    "    ytrain = yshift.iloc[:-limit]\n",
    "    ytest = yshift.iloc[-limit:-1]\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=20000, learning_rate=1, gamma=1, subsample=1, colsample_bytree=1, max_depth=100,objective='reg:squarederror')\n",
    "\n",
    "    model.fit( Xtrain, ytrain, early_stopping_rounds=150, eval_set=[(Xtest, ytest)], verbose=0)\n",
    "\n",
    "    ytrain_pred = model.predict(Xtrain)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "\n",
    "    pred = model.predict(X.iloc[:,:-1])\n",
    "\n",
    "    df['Close.S'] = pred\n",
    "    df = df.dropna()\n",
    "    return(df)\n",
    "\n",
    "    \n",
    "def deep_learning(df):\n",
    "    X = df.iloc[:,:-3]\n",
    "    y = df.iloc[:,-1].values\n",
    "    X.astype(np.float64)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    y = np.array(y_up).reshape(-1,1)\n",
    "\n",
    "    Xtrain = X[:bloc1,:]\n",
    "    Xtest = X[bloc1:,:]\n",
    "    ytrain = y_up[:bloc1,:]\n",
    "    ytest = y_up[bloc1:,:]\n",
    "    \n",
    "    seed = 770\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ytrain = ytrain.reshape(ytrain.shape[0],)\n",
    "\n",
    "    Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1])\n",
    "\n",
    "    model = Sequential()\n",
    "    # Add an input layer \n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "    # Add one hidden layer \n",
    "    model.add(Dense(3, activation='tanh'))\n",
    "    # Add an input layer \n",
    "    model.add(Dense(3, activation='tanh'))\n",
    "    # Add an input layer \n",
    "    model.add(Dense(3, activation='tanh'))\n",
    "    # Add an output layer \n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "\n",
    "    model.compile(loss= 'hinge'  #'binary_crossentropy',\n",
    "                  optimizer='rmsprop', #rmsprop #adam\n",
    "                  metrics=['accuracy','mse'])\n",
    "    \n",
    "              \n",
    "\n",
    "    history = model.fit(Xtrain, ytrain,epochs=280, batch_size=8, verbose=0)\n",
    "\n",
    "    train_acc = model.evaluate(Xtrain, ytrain,verbose=1)\n",
    "\n",
    "    yhat = model.predict_classes(Xtest)\n",
    "\n",
    "    score = model.evaluate(Xtest, ytest,verbose=1)\n",
    "\n",
    "    predict = model.predict(Xtest)\n",
    "\n",
    "    accuracy = accuracy_score(ytest, yhat)\n",
    "\n",
    "    # La précision permet de mesurer la capacité du modèle à refuser résultats non-pertinents : vrais_positifs/(vrais_positifs+faux_positifs)\n",
    "    precision = precision_score(ytest, yhat)  \n",
    "\n",
    "\n",
    "    # Recall : (vrai_positifs/(vrais_positifs+faux_négatifs))\n",
    "    recall = recall_score(ytest, yhat) \n",
    "\n",
    "    resultats = pd.DataFrame()\n",
    "    resultats['Date'] = df.index[bloc1:]\n",
    "    resultats.index= df.index[bloc1:]\n",
    "    resultats['Move'] = yhat\n",
    "    resultats['Confiance'] = (predict)*100\n",
    "    resultats['Actual'] = df.iloc[bloc1:]['Close']\n",
    "    resultats['Actual.S'] = df.iloc[bloc1:]['Close.S']\n",
    "    open_S = df['Open'].shift(-1)\n",
    "    resultats['Open.S'] = open_S.iloc[bloc1:]\n",
    "    \n",
    "    return(resultats,precision,model,scaler)\n",
    "\n",
    "\n",
    "def save_model(model_up,model_down):\n",
    "    savename = 'DL_'+LaDate+'/Save_'+ticker\n",
    "    # serialize model to YAML\n",
    "    model_up_yaml = model_up.to_yaml()\n",
    "    model_down_yaml = model_down.to_yaml()\n",
    "    with open(savename+\"_up.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_up_yaml)\n",
    "    with open(savename+\"_down.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_down_yaml)\n",
    "    # serialize weights to HDF5\n",
    "    model_up.save_weights(savename+\"_up.h5\")\n",
    "    model_down.save_weights(savename+\"_down.h5\")\n",
    "    \n",
    "########################\n",
    "#### MAIN SKAN55 #######\n",
    "########################\n",
    "ticker_list = compteur['Symb.'].tolist()\n",
    "name_list = compteur['Name'].tolist()\n",
    "sector_list = compteur['Sector'].tolist()\n",
    "prec_up_list = compteur['Precision_up'].tolist()\n",
    "prec_down_list = compteur['Precision_down'].tolist()\n",
    "\n",
    "tmps55=time.time()\n",
    "try:\n",
    "    print(Fore.BLUE,'Deeping in blue from ',ticker_list[-1],Style.RESET_ALL)\n",
    "except:\n",
    "    print(Fore.BLUE,'Deeping in blue from ','A',Style.RESET_ALL)\n",
    "\n",
    "#for loop in range(amorce,amorce+25):\n",
    "for loop in range(amorce,len(constituents)):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        ticker = (constituents.iloc[loop]['Symbol'])\n",
    "        name = constituents.iloc[loop]['Name']\n",
    "        sector = constituents.iloc[loop]['Sector']\n",
    "\n",
    "        global delta,bloc1,bloc2\n",
    "        tmps1=time.time()\n",
    "        df = scrap_data(ticker,start,end)\n",
    "\n",
    "        tmps2=round(time.time()-tmps1,2)\n",
    "        delta = round(df.shape[0])\n",
    "        bloc1 = round(delta*0.80)\n",
    "        bloc2 = delta - bloc1\n",
    "        df = boost(df)\n",
    "        df1 = scrap_vix(start,end)\n",
    "        df = prepa_data(df,df1)\n",
    "\n",
    "        resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "        aaa = 1\n",
    "        while (precision_up*100) < 83 or (precision_down*100) < 83:\n",
    "            print('\\r Passage N°',aaa,'pour le ticker',ticker,end='',flush=True)\n",
    "            resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "            aaa += 1\n",
    "\n",
    "        ticker_list.append(ticker)\n",
    "        name_list.append(name)\n",
    "        sector_list.append(sector)\n",
    "        prec_up_list.append(round(precision_up*100,2))\n",
    "        prec_down_list.append(round(precision_down*100,2))\n",
    "        save_model(model_up, model_down)\n",
    "\n",
    "        print('Le ',Fore.BLUE,'Deep Learning',Style.RESET_ALL ,'de ',Fore.YELLOW,ticker,Style.RESET_ALL,' a été effecué avec succès. Les modèles ont été sauvegardés')\n",
    "\n",
    "    except:\n",
    "        print(Fore.RED,'Problème loop : ',loop,Style.RESET_ALL)\n",
    "        error.append((loop,ticker))\n",
    "         \n",
    "        continue\n",
    "\n",
    "print(Fore.YELLOW,Back.BLUE,'Longueur des listes pour vérification : ',len(ticker_list),len(name_list),len(sector_list),Style.RESET_ALL)\n",
    "\n",
    "compteur = pd.DataFrame(columns = ['Symb.','Name','Sector'])\n",
    "\n",
    "compteur['Symb.'] = ticker_list\n",
    "\n",
    "compteur['Name'] = name_list\n",
    "\n",
    "compteur['Sector'] = sector_list\n",
    "\n",
    "compteur['Precision_up'] = prec_up_list\n",
    "\n",
    "compteur['Precision_down'] = prec_down_list\n",
    "\n",
    "compteur.to_csv('DL_'+LaDate+'/compteur'+LaDate+'.csv')\n",
    "\n",
    "print(Fore.YELLOW,Back.MAGENTA,Style.DIM,'PASSAGE FINI!!!!!!',Style.RESET_ALL)\n",
    "tmps2=round(time.time()-tmps55,2)\n",
    "print (\"Job done in = %f\" %tmps2,'seconds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
