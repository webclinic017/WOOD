{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from colorama import Fore, Back, Style\n",
    "import time\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeChemin = 'DL_2019-12-06/'\n",
    "start = '2015-12-06'\n",
    "end = '2019-12-10'\n",
    "list_dir = os.listdir(LeChemin+'.')\n",
    "NEW_LIST = []\n",
    "for pikunichihouahoua in range(0,len(str(list_dir).split(','))):\n",
    "    if str(list_dir).split(',')[pikunichihouahoua].split(',')[0].split('.')[1].split(\"'\")[0]=='yaml':\n",
    "        NEW_LIST.append(str(list_dir).split(',')[pikunichihouahoua].split(',')[0].split('.')[0].split(\"'\")[1].split('_')[1])\n",
    "NEW_LIST = sorted(set(NEW_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Optimized LumberJack Environment Motor 55\n",
      "LumberJack Jyss 5780(c)\n",
      "\u001b[34m °Go!em 73°\n",
      "ULTIMATE BACKTEST v0.5 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "___Author___='LumberJack Jyss'\n",
    "print('Global Optimized LumberJack Environment Motor 55\\nLumberJack Jyss 5780(c)')\n",
    "print(Fore.BLUE,'°Go!em 73°')\n",
    "print('ULTIMATE BACKTEST v0.5',Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker,'yahoo',start,end)\n",
    "    df = df.drop(['Close'],axis=1)\n",
    "    df['Close'] = df['Adj Close']\n",
    "    df = df.drop(['Adj Close'],axis = 1)    \n",
    "    return(df)\n",
    "\n",
    "def boost(df):\n",
    "    X = df.copy()\n",
    "    X = X.drop(['Close'],axis=1)\n",
    "    X['Close'] = df['Close']\n",
    "    y = X.iloc[:,-1]\n",
    "    Xtrain = X.iloc[:-2,:-1]\n",
    "    Xtest = X.iloc[-2:-1,:-1]\n",
    "    yshift = y.shift(-1)\n",
    "    ytrain = yshift.iloc[:-2]\n",
    "    ytest = yshift.iloc[-2:-1]\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=20000, learning_rate=1, gamma=1, subsample=1, colsample_bytree=1,\\\n",
    "                             max_depth=100,objective='reg:squarederror',random_state=26)\n",
    "    \n",
    "    model.fit( Xtrain, ytrain, early_stopping_rounds=150, eval_set=[(Xtest, ytest)], verbose=0)\n",
    "\n",
    "    ytrain_pred = model.predict(Xtrain)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "\n",
    "    pred = model.predict(X.iloc[:,:-1])\n",
    "\n",
    "    df['Close.S'] = pred\n",
    "    df['Close.S2'] = df['Close.S']\n",
    "    df = df.dropna()\n",
    "    return(df)\n",
    "def prepa_data(df):\n",
    "    rsi = talib.RSI(df['Close'],timeperiod=14)\n",
    "    stoc_slowk, stoc_slowd = talib.STOCH(df['High'],df['Low'],df['Close'])\n",
    "    upper, middle, lower =  talib.BBANDS(df['Close'], timeperiod=9, nbdevup=2, nbdevdn=2,matype=0)\n",
    "    sma5 = talib.SMA(df['Close'],timeperiod=5)\n",
    "    sma8 = talib.SMA(df['Close'],timeperiod=8)\n",
    "    sma10 = talib.SMA(df['Close'],timeperiod=10)\n",
    "    sma12 = talib.SMA(df['Close'],timeperiod=12)\n",
    "    sma15 = talib.SMA(df['Close'],timeperiod=15)\n",
    "    sma30 = talib.SMA(df['Close'],timeperiod=30)\n",
    "    sma35 = talib.SMA(df['Close'],timeperiod=35)\n",
    "    sma40 = talib.SMA(df['Close'],timeperiod=40)\n",
    "    sma45 = talib.SMA(df['Close'],timeperiod=45)\n",
    "    sma50 = talib.SMA(df['Close'],timeperiod=50)\n",
    "    atr = talib.ATR(df['High'],df['Low'],df['Close'],timeperiod=10)\n",
    "    delta5_8 = sma5 - sma8\n",
    "    delta8_10 = sma8 - sma10\n",
    "    delta10_12 = sma10 - sma12\n",
    "    delta12_15 = sma12 - sma15\n",
    "    delta15_30 = sma15 - sma30\n",
    "    delta30_35 = sma30 - sma35\n",
    "    delta35_40 = sma35 - sma40\n",
    "    delta40_45 = sma40 - sma45\n",
    "    delta45_50 = sma45 - sma50\n",
    "    bbdelta = upper - middle\n",
    "    price_bolup = df['Close'] - lower\n",
    "    price_bolow = df['Close'] - upper\n",
    "    Ema = talib.EMA(df['Close'],timeperiod=20)\n",
    "    KC_High = Ema + 2*atr\n",
    "    KC_Low = Ema - 2*atr\n",
    "    aroondown, aroonup = talib.AROON(df['High'], df['Low'], timeperiod=9)\n",
    "    aroon = aroonup - aroondown #(aroonup-aroondown)/abs((aroonup-aroondown))\n",
    "    rsi30_list = []\n",
    "    rsi70_list = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        rsi70_list.append(70 - rsi[i])\n",
    "        rsi30_list.append(rsi[i] - 30)\n",
    "        #except:\n",
    "         #   rsi70_list.append(0)\n",
    "          #  rs30_list.append(0)\n",
    "    varop_spy = df['Open'] - df['Close']\n",
    "    varhl_spy = df['High'] - df['Low']\n",
    "    df['Varop_Spy'] = varop_spy\n",
    "    df['Varhl_spy'] = varhl_spy\n",
    "    df['RSI'] = rsi\n",
    "    df['70 - RSI'] = np.array(rsi70_list)\n",
    "    df['RSI - 30'] = np.array(rsi30_list)\n",
    "    df['BBD_Delta_Up'] = bbdelta\n",
    "    df['delta5_8'] = delta5_8\n",
    "    df['delta8_10'] = delta8_10\n",
    "    df['delta10_12'] = delta10_12\n",
    "    df['delta12_15'] = delta12_15\n",
    "    df['delta15_30'] = delta15_30\n",
    "    df['delta30_35'] = delta30_35\n",
    "    df['delta35_40'] = delta35_40\n",
    "    df['delta40_45'] = delta40_45\n",
    "    df['delta45_50'] = delta45_50\n",
    "    df['Stoc_Slowk'] = stoc_slowk\n",
    "    df['Stoc_Slowd'] = stoc_slowd\n",
    "    df['KC_High'] = KC_High\n",
    "    df['KC_Low'] = KC_Low\n",
    "    df['upper'] = upper\n",
    "    df['lower'] = lower\n",
    "    df['var_bollup_kchigh'] = upper-KC_High\n",
    "    df['var_bolllow_kclow'] = lower-KC_Low\n",
    "    df['Aroon Up'] = aroonup\n",
    "    df['Aroon Down'] = aroondown\n",
    "    df['Delta Aroon'] = aroon\n",
    "    up = []\n",
    "    down = []\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df['%Futur'] = ((df['Close.S']-df['Close']) *100) / (df['Close'])\n",
    "    df['%Futur2'] = ((df['Close.S2']-df['Close']) *100) / (df['Close'])\n",
    "    for i in range(0,df.shape[0]):\n",
    "        if df.iloc[i]['%Futur'] > 0.5 :#or df.iloc[i]['%Futur2'] > 0.1:\n",
    "            up.append(1)\n",
    "            down.append(0)\n",
    "        elif df.iloc[i]['%Futur'] < -0.5: #or df.iloc[i]['%Futur2'] < -0.1:\n",
    "            up.append(0)\n",
    "            down.append(1)\n",
    "        else:\n",
    "            up.append(0)\n",
    "            down.append(0)\n",
    "\n",
    "    df['target_up'] = up  # target_up # abs(np.array(valley))#target_up\n",
    "    df['target_down'] = down # target_down # abs(np.array(peak))#target_down\n",
    "    df = df[['High','Low','Open','Volume','Close','Varop_Spy','Varhl_spy','RSI','70 - RSI','RSI - 30','BBD_Delta_Up','delta5_8','delta8_10','delta10_12','delta12_15','delta15_30','delta30_35','delta35_40','delta40_45','delta45_50','Stoc_Slowk','Stoc_Slowd','KC_High','KC_Low','upper','lower','var_bollup_kchigh','var_bolllow_kclow','Aroon Up','Aroon Down','Delta Aroon','Close.S','Close.S2','%Futur','%Futur2','target_up','target_down']]\n",
    "    #df = df.dropna()\n",
    "    return(df)\n",
    "def deep_learning(df):\n",
    "    X = df.copy()\n",
    "    #####################X = X.iloc[:,1:-4]\n",
    "    X = X.iloc[:,:-4]\n",
    "    X.astype(np.float64)\n",
    "    y_up = df.iloc[:,-2].values\n",
    "    y_down = df.iloc[:,-1].values\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    y_up = np.array(y_up).reshape(-1,1)\n",
    "    y_down = np.array(y_down).reshape(-1,1)\n",
    "\n",
    "    Xtrain = X[:bloc1,:]\n",
    "    Xtest = X[bloc1:,:]\n",
    "    ytrain_up = y_up[:bloc1,:]\n",
    "    ytest_up = y_up[bloc1:,:]\n",
    "    ytrain_down = y_down[:bloc1,:]\n",
    "    ytest_down = y_down[bloc1:,:]\n",
    "\n",
    "    seed = 770\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ytrain_up = ytrain_up.reshape(ytrain_up.shape[0],)\n",
    "    ytrain_down = ytrain_down.reshape(ytrain_down.shape[0],)\n",
    "\n",
    "    Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1])\n",
    "\n",
    "    yhat_up = model_up.predict_classes(Xtest)\n",
    "    yhat_down = model_down.predict_classes(Xtest)\n",
    "\n",
    "    predict_up = model_up.predict(Xtest)\n",
    "    predict_down = model_down.predict(Xtest)\n",
    "\n",
    "    precision_up = precision_score(ytest_up, yhat_up)  \n",
    "    precision_down = precision_score(ytest_down, yhat_down) \n",
    "\n",
    "    resultats = pd.DataFrame()\n",
    "    resultats['Date'] = df.index[bloc1:].strftime('%Y-%m-%d')\n",
    "    resultats.index= df.index[bloc1:]\n",
    "    resultats['Move Up'] = yhat_up\n",
    "    resultats['Confiance up'] = (predict_up)*100\n",
    "    resultats['Move Down'] = yhat_down\n",
    "    resultats['Confiance Down'] = (predict_down)*100\n",
    "    resultats['Actual'] = df.iloc[bloc1:]['Close']\n",
    "    resultats['Actual.S'] = df.iloc[bloc1:]['Close.S']\n",
    "    open_S = df['Open'].shift(-1)\n",
    "    resultats['Open.S'] = open_S.iloc[bloc1:]\n",
    "    dmp_cp=[]\n",
    "    dmp_cp = ((resultats['Confiance up']-resultats['Confiance Down'])/(resultats['Confiance up']+resultats['Confiance Down'])*100)\n",
    "    resultats['DMP_CP'] = dmp_cp\n",
    "    \n",
    "    return(resultats,precision_up,precision_down,scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "########### GENERATION DE BASE ####################\n",
    "###################################################\n",
    "\n",
    "print(Fore.YELLOW,'ON GENERE LaBase',Style.RESET_ALL)\n",
    "tmps55=time.time()\n",
    "LaBase = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "BADTICKER = ['AMCR']\n",
    "for loop,ticker in enumerate(NEW_LIST):\n",
    "    try:\n",
    "        df = web.DataReader(ticker,'yahoo',start,end)\n",
    "        df['Date'] = df.index\n",
    "        df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        BADTICKER.append(ticker)\n",
    "        continue\n",
    "    df['Symbol'] = ticker\n",
    "    df = df[['Symbol','High','Low','Open','Close','Volume','Adj Close']]\n",
    "    LaBase = pd.concat((LaBase,df),ignore_index=False)\n",
    "tmps22=round(time.time()-tmps55,2)\n",
    "print(Fore.BLUE,\"Time for completing LaBase Generation = %f\" %tmps22,'seconds \\n',Style.RESET_ALL)\n",
    "\n",
    "print('Il y a ',len(BADTICKER),' mauvais tickers')\n",
    "print('Les voici')\n",
    "print(BADTICKER)\n",
    "\n",
    "#LaBase[LaBase.duplicated()].shape\n",
    "\n",
    "print('Base générée : ',LaBase.shape)\n",
    "print('Il y a ',LaBase[LaBase.duplicated()].shape,' Duplicats')\n",
    "print('Hors AMCR, voici les duplicats') \n",
    "print(LaBase[(LaBase.duplicated()==True)&(LaBase['Symbol'] != 'AMCR')])\n",
    "\n",
    "###########################################################\n",
    "############## SI BESOIN DE RETIRER LA DATE DU JOUR #######\n",
    "##\n",
    "#  LaBase = LaBase[LaBase.index != '2019-09-18 00:00:00'] #\n",
    "##\n",
    "#\n",
    "# LaBase.index = pd.to_datetime(LaBase['Date'],format='%Y-%m-%d')\n",
    "###########################################################\n",
    "try:\n",
    "    os.remove('LaBase.csv')\n",
    "except:\n",
    "    pass\n",
    "LaBase.to_csv('LaBase.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaBase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaBase.to_csv('Base_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09 = pd.read_csv('Base_09.csv')\n",
    "df_10 = pd.read_csv('Base_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09 = df_09[df_09['Symbol']=='AMZN']\n",
    "df_10 = df_10[df_10['Symbol']=='AMZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09 = df_09.drop(['Symbol'],axis=1)\n",
    "df_10 = df_10.drop(['Symbol'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09.index = pd.to_datetime(df_09['Date'],format='%Y-%m-%d')\n",
    "df_10.index = pd.to_datetime(df_10['Date'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09 = df_09.drop(['Date'],axis=1)\n",
    "df_10 = df_10.drop(['Date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09 = df_09.iloc[-200:,:]\n",
    "df_10 = df_10.iloc[-200:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 150 ms, sys: 4.21 ms, total: 154 ms\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = df_09.copy()\n",
    "X = X.drop(['Close'],axis=1)\n",
    "X['Close'] = df_09['Close']\n",
    "y = X.iloc[:,-1]\n",
    "Xtrain = X.iloc[:-2,:-1]\n",
    "Xtest = X.iloc[-2:-1,:-1]\n",
    "yshift = y.shift(-1)\n",
    "ytrain = yshift.iloc[:-2]\n",
    "ytest = yshift.iloc[-2:-1]\n",
    "\n",
    "model = xgb.XGBRegressor(n_estimators=20000, learning_rate=1, gamma=1, subsample=1, colsample_bytree=1,\\\n",
    "                         max_depth=100,objective='reg:squarederror',random_state=26)\n",
    "\n",
    "model.fit( Xtrain, ytrain, early_stopping_rounds=150, eval_set=[(Xtest, ytest)], verbose=0)\n",
    "\n",
    "ytrain_pred = model.predict(Xtrain)\n",
    "\n",
    "y_pred = model.predict(Xtest)\n",
    "\n",
    "pred = model.predict(X.iloc[:,:-1])\n",
    "\n",
    "df_09['Close.S'] = pred\n",
    "df_09['Close.S2'] = df_09['Close.S']\n",
    "df_09 = df_09.dropna()\n",
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1738.9363], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1638.68  , 1673.2673, 1695.6863, 1689.2324, 1668.9354, 1629.5874,\n",
       "       1629.5874, 1672.7124, 1673.9524, 1693.0062, 1686.2446, 1703.7812,\n",
       "       1742.6863, 1767.9608, 1796.4404, 1818.5068, 1769.0895, 1776.2361,\n",
       "       1784.2827, 1765.3269, 1773.8542, 1780.4769, 1814.6455, 1813.4989,\n",
       "       1820.6406, 1818.7158, 1836.1719, 1848.7698, 1835.188 , 1848.0703,\n",
       "       1844.111 , 1842.6897, 1844.6149, 1864.178 , 1863.6057, 1862.3398,\n",
       "       1879.9144, 1915.4427, 1901.2732, 1903.3453, 1947.6727, 1938.2251,\n",
       "       1927.7974, 1910.851 , 1903.4628, 1958.166 , 1954.74  , 1920.9497,\n",
       "       1917.6897, 1901.5734, 1890.8446, 1822.6865, 1840.1268, 1872.8431,\n",
       "       1908.4861, 1871.4132, 1858.8328, 1861.6133, 1858.5239, 1816.4146,\n",
       "       1821.9891, 1835.8152, 1820.219 , 1817.0297, 1774.5382, 1711.0023,\n",
       "       1729.6953, 1738.4176, 1750.0956, 1804.5441, 1852.356 , 1863.6512,\n",
       "       1855.741 , 1869.4739, 1872.6548, 1885.6394, 1901.9551, 1907.1449,\n",
       "       1918.8813, 1910.851 , 1913.833 , 1879.0859, 1895.4204, 1905.2885,\n",
       "       1891.6714, 1918.4331, 1931.6924, 1939.0289, 1943.9578, 1943.9578,\n",
       "       1988.5052, 2010.0548, 2000.7781, 2010.0548, 2007.6276, 2012.5084,\n",
       "       1989.9656, 1977.825 , 1964.9481, 1987.633 , 1998.1221, 2000.8096,\n",
       "       1974.7653, 1952.0222, 1913.7683, 1901.1802, 1869.3407, 1854.2092,\n",
       "       1822.1456, 1769.224 , 1788.0157, 1793.2529, 1833.0021, 1807.8989,\n",
       "       1783.313 , 1824.3499, 1763.7148, 1776.2361, 1788.9275, 1815.8574,\n",
       "       1800.5808, 1822.8961, 1804.2955, 1758.0756, 1767.9608, 1762.2601,\n",
       "       1764.6724, 1784.6049, 1777.8308, 1790.4922, 1800.3599, 1836.6925,\n",
       "       1834.6362, 1830.2683, 1823.1671, 1822.5703, 1842.8179, 1839.7828,\n",
       "       1808.2117, 1818.1759, 1816.5847, 1822.5084, 1794.9979, 1785.875 ,\n",
       "       1747.8289, 1767.6764, 1745.5598, 1729.2917, 1735.9384, 1736.3455,\n",
       "       1711.1674, 1725.6366, 1738.4485, 1734.0768, 1713.2854, 1720.8866,\n",
       "       1720.8866, 1729.8335, 1736.8385, 1759.8181, 1777.6824, 1786.6957,\n",
       "       1763.7316, 1782.8065, 1765.7823, 1762.9528, 1780.3379, 1761.82  ,\n",
       "       1775.9735, 1763.5173, 1780.3379, 1778.0173, 1788.9314, 1805.1715,\n",
       "       1802.1498, 1795.9062, 1788.7535, 1777.9166, 1770.164 , 1775.4225,\n",
       "       1756.3174, 1751.7732, 1738.9363, 1752.0353, 1753.309 , 1745.8981,\n",
       "       1738.9363, 1744.1725, 1773.0876, 1792.579 , 1818.1841, 1796.0684,\n",
       "       1782.5574, 1770.4545, 1760.3013, 1740.0162, 1751.7732, 1748.2643,\n",
       "       1738.9363, 1720.4954], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-27</th>\n",
       "      <td>1641.810059</td>\n",
       "      <td>1615.099976</td>\n",
       "      <td>1628.180054</td>\n",
       "      <td>3148800.0</td>\n",
       "      <td>1641.089966</td>\n",
       "      <td>1641.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1651.770020</td>\n",
       "      <td>1633.829956</td>\n",
       "      <td>1635.250000</td>\n",
       "      <td>3025900.0</td>\n",
       "      <td>1639.829956</td>\n",
       "      <td>1639.829956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>1674.260010</td>\n",
       "      <td>1651.000000</td>\n",
       "      <td>1655.130005</td>\n",
       "      <td>4974900.0</td>\n",
       "      <td>1671.729980</td>\n",
       "      <td>1671.729980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>1709.430054</td>\n",
       "      <td>1674.359985</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>6167400.0</td>\n",
       "      <td>1696.170044</td>\n",
       "      <td>1696.170044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>1707.800049</td>\n",
       "      <td>1689.010010</td>\n",
       "      <td>1702.949951</td>\n",
       "      <td>3681500.0</td>\n",
       "      <td>1692.430054</td>\n",
       "      <td>1692.430054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>1789.089966</td>\n",
       "      <td>1760.219971</td>\n",
       "      <td>1774.010010</td>\n",
       "      <td>2670100.0</td>\n",
       "      <td>1760.689941</td>\n",
       "      <td>1760.689941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>1763.500000</td>\n",
       "      <td>1740.000000</td>\n",
       "      <td>1763.500000</td>\n",
       "      <td>2823800.0</td>\n",
       "      <td>1740.479980</td>\n",
       "      <td>1740.479980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>1754.400024</td>\n",
       "      <td>1740.130005</td>\n",
       "      <td>1751.199951</td>\n",
       "      <td>3117400.0</td>\n",
       "      <td>1751.599976</td>\n",
       "      <td>1751.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09</th>\n",
       "      <td>1766.890015</td>\n",
       "      <td>1745.609985</td>\n",
       "      <td>1750.660034</td>\n",
       "      <td>2442800.0</td>\n",
       "      <td>1749.510010</td>\n",
       "      <td>1749.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10</th>\n",
       "      <td>1750.670044</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>1747.400024</td>\n",
       "      <td>2514300.0</td>\n",
       "      <td>1739.209961</td>\n",
       "      <td>1739.209961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   High          Low         Open     Volume    Adj Close  \\\n",
       "Date                                                                        \n",
       "2019-02-27  1641.810059  1615.099976  1628.180054  3148800.0  1641.089966   \n",
       "2019-02-28  1651.770020  1633.829956  1635.250000  3025900.0  1639.829956   \n",
       "2019-03-01  1674.260010  1651.000000  1655.130005  4974900.0  1671.729980   \n",
       "2019-03-04  1709.430054  1674.359985  1685.000000  6167400.0  1696.170044   \n",
       "2019-03-05  1707.800049  1689.010010  1702.949951  3681500.0  1692.430054   \n",
       "...                 ...          ...          ...        ...          ...   \n",
       "2019-12-04  1789.089966  1760.219971  1774.010010  2670100.0  1760.689941   \n",
       "2019-12-05  1763.500000  1740.000000  1763.500000  2823800.0  1740.479980   \n",
       "2019-12-06  1754.400024  1740.130005  1751.199951  3117400.0  1751.599976   \n",
       "2019-12-09  1766.890015  1745.609985  1750.660034  2442800.0  1749.510010   \n",
       "2019-12-10  1750.670044  1735.000000  1747.400024  2514300.0  1739.209961   \n",
       "\n",
       "                  Close  \n",
       "Date                     \n",
       "2019-02-27  1641.089966  \n",
       "2019-02-28  1639.829956  \n",
       "2019-03-01  1671.729980  \n",
       "2019-03-04  1696.170044  \n",
       "2019-03-05  1692.430054  \n",
       "...                 ...  \n",
       "2019-12-04  1760.689941  \n",
       "2019-12-05  1740.479980  \n",
       "2019-12-06  1751.599976  \n",
       "2019-12-09  1749.510010  \n",
       "2019-12-10  1739.209961  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = df_10.copy()\n",
    "X = X.drop(['Close'],axis=1)\n",
    "X['Close'] = df_10['Close']\n",
    "y = X.iloc[:,-1]\n",
    "Xtrain = X.iloc[:-2,:-1]\n",
    "Xtest = X.iloc[-2:-1,:-1]\n",
    "yshift = y.shift(-1)\n",
    "ytrain = yshift.iloc[:-2]\n",
    "ytest = yshift.iloc[-2:-1]\n",
    "\n",
    "#model = xgb.XGBRegressor(n_estimators=20000, learning_rate=1, gamma=1, subsample=1, colsample_bytree=1,\\\n",
    "#                         max_depth=100,objective='reg:squarederror',random_state=26)\n",
    "\n",
    "#model.fit( Xtrain, ytrain, early_stopping_rounds=150, eval_set=[(Xtest, ytest)], verbose=0)\n",
    "\n",
    "ytrain_pred = model.predict(Xtrain)\n",
    "\n",
    "y_pred = model.predict(Xtest)\n",
    "\n",
    "pred = model.predict(X.iloc[:,:-1])\n",
    "\n",
    "df_10['Close.S'] = pred\n",
    "df_10['Close.S2'] = df_10['Close.S']\n",
    "df_10 = df_10.dropna()\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"xgboost.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1651.770020</td>\n",
       "      <td>1633.829956</td>\n",
       "      <td>1635.250000</td>\n",
       "      <td>3025900.0</td>\n",
       "      <td>1639.829956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>1674.260010</td>\n",
       "      <td>1651.000000</td>\n",
       "      <td>1655.130005</td>\n",
       "      <td>4974900.0</td>\n",
       "      <td>1671.729980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>1709.430054</td>\n",
       "      <td>1674.359985</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>6167400.0</td>\n",
       "      <td>1696.170044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>1707.800049</td>\n",
       "      <td>1689.010010</td>\n",
       "      <td>1702.949951</td>\n",
       "      <td>3681500.0</td>\n",
       "      <td>1692.430054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06</th>\n",
       "      <td>1697.750000</td>\n",
       "      <td>1668.280029</td>\n",
       "      <td>1695.969971</td>\n",
       "      <td>3996000.0</td>\n",
       "      <td>1668.949951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>1763.500000</td>\n",
       "      <td>1740.000000</td>\n",
       "      <td>1763.500000</td>\n",
       "      <td>2823800.0</td>\n",
       "      <td>1740.479980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>1754.400024</td>\n",
       "      <td>1740.130005</td>\n",
       "      <td>1751.199951</td>\n",
       "      <td>3117400.0</td>\n",
       "      <td>1751.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09</th>\n",
       "      <td>1766.890015</td>\n",
       "      <td>1745.609985</td>\n",
       "      <td>1750.660034</td>\n",
       "      <td>2442800.0</td>\n",
       "      <td>1749.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10</th>\n",
       "      <td>1750.670044</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>1747.400024</td>\n",
       "      <td>2514300.0</td>\n",
       "      <td>1739.209961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11</th>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1735.709961</td>\n",
       "      <td>1741.670044</td>\n",
       "      <td>2097600.0</td>\n",
       "      <td>1748.719971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   High          Low         Open     Volume    Adj Close\n",
       "Date                                                                     \n",
       "2019-02-28  1651.770020  1633.829956  1635.250000  3025900.0  1639.829956\n",
       "2019-03-01  1674.260010  1651.000000  1655.130005  4974900.0  1671.729980\n",
       "2019-03-04  1709.430054  1674.359985  1685.000000  6167400.0  1696.170044\n",
       "2019-03-05  1707.800049  1689.010010  1702.949951  3681500.0  1692.430054\n",
       "2019-03-06  1697.750000  1668.280029  1695.969971  3996000.0  1668.949951\n",
       "...                 ...          ...          ...        ...          ...\n",
       "2019-12-05  1763.500000  1740.000000  1763.500000  2823800.0  1740.479980\n",
       "2019-12-06  1754.400024  1740.130005  1751.199951  3117400.0  1751.599976\n",
       "2019-12-09  1766.890015  1745.609985  1750.660034  2442800.0  1749.510010\n",
       "2019-12-10  1750.670044  1735.000000  1747.400024  2514300.0  1739.209961\n",
       "2019-12-11  1750.000000  1735.709961  1741.670044  2097600.0  1748.719971\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_10.drop(['Close'],axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['High', 'Low', 'Open', 'Volume', 'Adj]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"xgboost.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.drop(['Close'])\n",
    "y_pred = model.predict(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235, 49.947235, 49.947235, 49.947235, 49.947235,\n",
       "       49.947235, 49.947235], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yaml\n",
    "from keras.models import model_from_yaml\n",
    "from sklearn.metrics import  precision_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "yaml.warnings({'YAMLLoadWarning': False})\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaBase = pd.read_csv('LaBase.csv')\n",
    "try:\n",
    "    LaBAse = LaBase.drop(['Unnamed: 0'],axis=1)\n",
    "except :\n",
    "    pass\n",
    "LaBase.index = pd.to_datetime(LaBase['Date'],format='%Y-%m-%d')\n",
    "LaBase = LaBase.drop(['Date'],axis=1)\n",
    "LaBase = LaBase.drop(['Close'],axis=1)\n",
    "LaBase['Close'] = LaBase['Adj Close']\n",
    "LaBase = LaBase.drop(['Adj Close'],axis=1)\n",
    "LaBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = len(NEW_LIST)\n",
    "\n",
    "delta = round(LaBase.shape[0])\n",
    "bloc1 = 616 # round(delta*0.80)\n",
    "bloc2 = delta - bloc1\n",
    "\n",
    "filtre_up = 93\n",
    "filtre_down = 97\n",
    "filtre_up_close = 80\n",
    "filtre_down_close = 80\n",
    "\n",
    "error = []\n",
    "\n",
    "signals = pd.DataFrame(columns = ['Date','Ticker','Open Long','Close Long','Open Short','Close Short','Buy/Sell Price',\\\n",
    "                                  'Quantity','Actual','PNL','Cumulative PNL','Latent PNL'])\n",
    "\n",
    "backtest = pd.DataFrame(columns = ['Symb.','Name','Sector','Period','Begin.','End',\\\n",
    "                          'Pnl $','Pnl %','Gross Profit','Gross Loss','# Winners','# Loosers',\\\n",
    "                          '% Winners','MaxDD $','MaxDD %','Aver. Win $',\\\n",
    "                          'Aver. Loos $','Aver. Duration',\\\n",
    "                          'Total Trades','% Long','% Short','Profit Factor'])\n",
    "\n",
    "\n",
    "print(Fore.GREEN,'Initiating Calculation',Style.RESET_ALL)\n",
    "\n",
    "Resultats = pd.DataFrame()\n",
    "\n",
    "GREEN = []\n",
    "RED = []\n",
    "GREEN_CLOSE = []\n",
    "RED_CLOSE=[]\n",
    "TICKER = []\n",
    "DATE = []\n",
    "PRICE = []\n",
    "OPEN_S = []\n",
    "\n",
    "tmps55=time.time()\n",
    "for loop,ticker in enumerate(NEW_LIST):\n",
    "    \n",
    "    if loop == 1:\n",
    "            print('\\r',Fore.GREEN,' |==',Fore.BLUE,'O',Fore.RED,'==================|',end='',flush=True)\n",
    "    if loop == round(1 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |====',Fore.BLUE,'O',Fore.RED,'================|',end='',flush=True)\n",
    "    if loop == round(2 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |======',Fore.BLUE,'O',Fore.RED,'==============|',end='',flush=True)\n",
    "    if loop == round(3 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |========',Fore.BLUE,'O',Fore.RED,'============|',end='',flush=True)\n",
    "    if loop == round(4 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |==========',Fore.BLUE,'O',Fore.RED,'==========|',end='',flush=True)\n",
    "    if loop == round(5 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |============',Fore.BLUE,'O',Fore.RED,'========|',end='',flush=True)\n",
    "    if loop == round(6 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |==============',Fore.BLUE,'O',Fore.RED,'======|',end='',flush=True)\n",
    "    if loop == round(7 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |================',Fore.BLUE,'O',Fore.RED,'====|',end='',flush=True)\n",
    "    if loop == round(8 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |==================',Fore.BLUE,'O',Fore.RED,'==|',Style.RESET_ALL,end='',flush=True)\n",
    "    \n",
    "    \n",
    "    yamlup = (LeChemin+'Save_'+ticker+'_up.yaml')\n",
    "    yamldown = (LeChemin+'Save_'+ticker+'_down.yaml')\n",
    "    modelup = (LeChemin+'Save_'+ticker+'_up.h5')\n",
    "    modeldown = (LeChemin+'Save_'+ticker+'_down.h5')\n",
    "\n",
    "    yaml_file_up = open(yamlup, 'r')\n",
    "    yaml_file_down = open(yamldown, 'r')\n",
    "    model_yaml_up = yaml_file_up.read()\n",
    "    model_yaml_down = yaml_file_down.read()\n",
    "    yaml_file_up.close()\n",
    "    yaml_file_down.close()\n",
    "    model_up = model_from_yaml(model_yaml_up)\n",
    "    model_down = model_from_yaml(model_yaml_down)\n",
    "    # load weights into new model\n",
    "    model_up.load_weights(modelup)\n",
    "    model_down.load_weights(modeldown)\n",
    "    \n",
    "    df = LaBase[LaBase['Symbol']==ticker]\n",
    "    if df.shape[0]<771:\n",
    "        error.append(ticker)\n",
    "        continue\n",
    "    df = df.drop(['Symbol'],axis=1)\n",
    "    df = boost(df)\n",
    "    df = prepa_data(df)\n",
    "    \n",
    "    resultats,precision_up,precision_down,scaler = deep_learning(df)\n",
    "    if len(resultats) < 252:\n",
    "        error.append(ticker)\n",
    "        continue\n",
    "    \n",
    "    if (precision_up * 100) > 69 and (precision_down * 100) > 69:\n",
    "\n",
    "        ####################\n",
    "        ##### SIGNALS #####\n",
    "        ###################\n",
    "\n",
    "        filtre_up = 93\n",
    "        filtre_down = 97\n",
    "        filtre_up_close = 80\n",
    "        filtre_down_close = 80\n",
    "\n",
    "        for i in range(0,len(resultats)):\n",
    "\n",
    "            price = resultats.iloc[i]['Actual']\n",
    "\n",
    "            if resultats.iloc[i]['Confiance Down'] > filtre_down:\n",
    "                doob = -1\n",
    "            elif resultats.iloc[i]['Confiance Down'] > filtre_down_close and resultats.iloc[i]['Confiance Down'] < filtre_down :\n",
    "                waab = -1\n",
    "                doob = 0\n",
    "            elif resultats.iloc[i]['Confiance up'] > filtre_up:\n",
    "                doob = 1\n",
    "            elif resultats.iloc[i]['Confiance up'] > filtre_up_close and resultats.iloc[i]['Confiance up'] < filtre_up:\n",
    "                waab = 1\n",
    "                doob = 0\n",
    "            else :\n",
    "                doob = 0\n",
    "                waab = 0\n",
    "\n",
    "            if doob == 1 :\n",
    "                DATE.append(resultats.iloc[i]['Date'])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(1)\n",
    "                RED.append(0)\n",
    "                GREEN_CLOSE.append(0)\n",
    "                RED_CLOSE.append(1)\n",
    "                PRICE.append(price)\n",
    "                OPEN_S.append(resultats.iloc[i]['Open.S'])\n",
    "\n",
    "            elif doob == -1 :\n",
    "                DATE.append(resultats.iloc[i]['Date'])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(0)\n",
    "                RED.append(1)\n",
    "                GREEN_CLOSE.append(1)\n",
    "                RED_CLOSE.append(0)\n",
    "                PRICE.append(price)\n",
    "                OPEN_S.append(resultats.iloc[i]['Open.S'])\n",
    "\n",
    "            elif doob == 0 and waab == -1 :\n",
    "                DATE.append(resultats.iloc[i]['Date'])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(0)\n",
    "                RED.append(0)\n",
    "                GREEN_CLOSE.append(1)\n",
    "                RED_CLOSE.append(0)\n",
    "                PRICE.append(price)\n",
    "                OPEN_S.append(resultats.iloc[i]['Open.S'])\n",
    "\n",
    "            elif doob == 0 and waab == 1 :\n",
    "                DATE.append(resultats.iloc[i]['Date'])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(0)\n",
    "                RED.append(0)\n",
    "                GREEN_CLOSE.append(0)\n",
    "                RED_CLOSE.append(1)\n",
    "                PRICE.append(price)\n",
    "                OPEN_S.append(resultats.iloc[i]['Open.S'])\n",
    "\n",
    "            else:\n",
    "                DATE.append(resultats.iloc[i]['Date'])\n",
    "                TICKER.append(ticker)\n",
    "                GREEN.append(0)\n",
    "                RED.append(0)\n",
    "                GREEN_CLOSE.append(0)\n",
    "                RED_CLOSE.append(0)\n",
    "                PRICE.append(price)\n",
    "                OPEN_S.append(resultats.iloc[i]['Open.S'])\n",
    "\n",
    "    '''else:\n",
    "        DATE.append(resultats.iloc[i]['Date'])\n",
    "        TICKER.append(ticker)\n",
    "        GREEN.append(0)\n",
    "        RED.append(0)\n",
    "        GREEN_CLOSE.append(0)\n",
    "        RED_CLOSE.append(0)\n",
    "        PRICE.append(price)\n",
    "        OPEN_S.append(resultats.iloc[i]['Open.S'])'''\n",
    "\n",
    "Resultats['Date'] = DATE\n",
    "Resultats['Ticker'] = TICKER\n",
    "Resultats['Green'] = GREEN\n",
    "Resultats['Red'] = RED\n",
    "Resultats['Green_Close'] = GREEN_CLOSE\n",
    "Resultats['Red_Close'] = RED_CLOSE\n",
    "Resultats['Price'] = PRICE\n",
    "Resultats['Open.S'] = OPEN_S\n",
    "#Resultats = pd.concat((Resultats,resultats))\n",
    "tmps22=round(time.time()-tmps55,2)\n",
    "print(Fore.BLUE,\"\\n Time for completing Signal Generation = %f\" %tmps22,'seconds \\n',Style.RESET_ALL)\n",
    "print('\\n Tickers en error :',error)\n",
    "Resultats = Resultats[(Resultats['Green_Close']==1)|(Resultats['Red_Close']==1)]\n",
    "Resultats.to_csv('Resultats.csv')\n",
    "Resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop,ticker,sum(GREEN),sum(GREEN_CLOSE),sum(RED),sum(RED_CLOSE),len(GREEN),sum(RED_CLOSE)+sum(GREEN_CLOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sys\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "orig_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "####### BACKTEST########\n",
    "########################\n",
    "resultats = Resultats\n",
    "resultats['Date'] = pd.to_datetime(resultats['Date'],format='%Y-%m-%d')\n",
    "tmps55=time.time()\n",
    "for ticker in NEW_LIST:\n",
    "    if ticker in error:\n",
    "        continue\n",
    "    pos_long = 0\n",
    "    pos_short = 0\n",
    "    pactol = 50000\n",
    "    price_buy = 0\n",
    "    price_sell = 0\n",
    "    x = 0\n",
    "    winners = []\n",
    "    loosers = []\n",
    "    nb_win = 0\n",
    "    nb_los = 0\n",
    "    mini_pnl = 0\n",
    "    pos_duration = []\n",
    "    average_duration = [] # pd.Timedelta(resultats.iloc[0,0] - resultats.iloc[0,0])\n",
    "    trades = []\n",
    "    eq_curx = []\n",
    "    eq_cury = []\n",
    "    maxdd = []\n",
    "    nbS = 0\n",
    "    nbL = 0\n",
    "    \n",
    "    \n",
    "    f = open('backtest de '+str(ticker)+'.txt', 'w')\n",
    "    sys.stdout = f\n",
    "    print('TICKER : ',ticker)\n",
    "    resultats = Resultats[Resultats['Ticker'] == ticker]\n",
    "    if resultats.shape[0] < 250:\n",
    "        error.append(ticker)\n",
    "        continue\n",
    "    for i in range(0,len(resultats)-1):\n",
    "        if pos_long == 0 and pos_short == 0 and resultats.iloc[i]['Green'] == 1 :\n",
    "            pos_long = 1\n",
    "            nbL+=1\n",
    "            x = round((1500)/resultats.iloc[i]['Open.S'])\n",
    "            price_buy = round(resultats.iloc[i]['Open.S'],2)\n",
    "            time_enter = resultats.iloc[i]['Date']\n",
    "\n",
    "            signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 1,\\\n",
    "                               'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                               'Buy/Sell Price' : price_buy, 'Quantity' : x,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : 0,\\\n",
    "                                       'Cumulative PNL':round(signals.iloc[:i]['PNL'].sum(),2),\\\n",
    "                                       'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "            print('\\n Le ',str(resultats.iloc[i]['Date']),', achat de ',x,' actions à',round(resultats.iloc[i]['Open.S'],2),'$')\n",
    "            print('Nouveau pactol : ',round(pactol,2))\n",
    "            print('Le Cumulative PNL est de : ',round(signals.iloc[:i]['PNL'].sum(),2))\n",
    "            print('Le Latent PNL est de : 0')\n",
    "            trades.append((round(resultats.iloc[i]['Open.S'],2),resultats.iloc[i]['Date'],1))\n",
    "\n",
    "        elif pos_long == 1 and resultats.iloc[i]['Green_Close'] == 0 :\n",
    "\n",
    "            signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                               'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                               'Buy/Sell Price' : price_buy, 'Quantity' : x,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : 0,\\\n",
    "                                       'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),\\\n",
    "                                       'Latent PNL':round((resultats.iloc[i]['Open.S'] - price_buy)*x,2)}],ignore_index=True)\n",
    "            try:\n",
    "                maxdd.append(round((resultats.iloc[i]['Open.S'] - price_buy)*x,2))\n",
    "            except:\n",
    "                print('Null val of maxdd')\n",
    "                maxdd.append(0)\n",
    "                print('\\n Le ',str(resultats.iloc[i]['Date']))\n",
    "                print('Nouveau pactol : ',round(pactol,2))\n",
    "                print('Le Cumulative PNL est de : ',round(signals.iloc[:i]['PNL'].sum(),2))\n",
    "                print('Le Latent PNL est de : ',maxdd[-1])\n",
    "\n",
    "        elif pos_long == 1 and resultats.iloc[i]['Green_Close'] == 1 :\n",
    "            old_pactol = round(pactol,2)\n",
    "            eq_curx.append(resultats.iloc[i]['Date'])\n",
    "            eq_cury.append(old_pactol)\n",
    "            pos_long = 0\n",
    "            price_sell = round(resultats.iloc[i]['Open.S'],2)\n",
    "            mini_pnl = round(x*(price_sell-price_buy),2)\n",
    "            trades.append((round(resultats.iloc[i]['Open.S'],2),resultats.iloc[i]['Date'],2))\n",
    "\n",
    "            signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                               'Close Long' : 1, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                               'Buy/Sell Price' : price_sell, 'Quantity' : x,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : mini_pnl,\\\n",
    "                                       'Cumulative PNL':round(signals.iloc[:i]['PNL'].sum(),2),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "            pactol = round((pactol + mini_pnl),2)\n",
    "            pos_duration.append(resultats.iloc[i]['Date'] - time_enter)\n",
    "            print('\\n Le ',str(resultats.iloc[i]['Date']),', vente pour close de ',x,' actions à',round(resultats.iloc[i]['Open.S'],2),'$')\n",
    "            print('Nouveau pactol : ',pactol)\n",
    "            print('pnl:', mini_pnl)\n",
    "            print('prix de vente',price_sell)\n",
    "            print('prix d achat',price_buy)\n",
    "            print('Le Cumulative PNL est de : ',round(signals.iloc[:i]['PNL'].sum(),2))\n",
    "            print('Le Latent PNL est de : 0')\n",
    "            print('Duration : ',pos_duration[-1])\n",
    "            \n",
    "\n",
    "            if mini_pnl > 0:\n",
    "                winners.append(mini_pnl)\n",
    "                mini_pnl = 0\n",
    "                nb_win +=1\n",
    "            else :\n",
    "                loosers.append(mini_pnl)\n",
    "                mini_pnl = 0\n",
    "                nb_los +=1\n",
    "\n",
    "\n",
    "        elif pos_short == 0 and pos_long == 0 and resultats.iloc[i]['Red']==1:\n",
    "            pos_short = 1\n",
    "            nbS+=1\n",
    "            x = round((1500)/resultats.iloc[i]['Open.S'])\n",
    "            price_sell = round(resultats.iloc[i]['Open.S'],2)\n",
    "            time_enter = resultats.iloc[i]['Date']\n",
    "\n",
    "            signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                               'Close Long' : 0, 'Open Short' : 1, 'Close Short' : 0,\\\n",
    "                               'Buy/Sell Price' : price_sell, 'Quantity' : x,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : 0,\\\n",
    "                                       'Cumulative PNL':round(signals.iloc[:i]['PNL'].sum(),2),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "            print('\\n Le ',str(resultats.iloc[i]['Date']),', vente de ',x,' actions à',round(resultats.iloc[i]['Open.S'],2),'$')\n",
    "            print('Nouveau pactol : ',pactol)\n",
    "            print('Le Cumulative PNL est de : ',round(signals.iloc[:i]['PNL'].sum(),2))\n",
    "            print('Le Latent PNL est de : 0')\n",
    "            \n",
    "            trades.append((round(resultats.iloc[i]['Open.S'],2),resultats.iloc[i]['Date'],-1))\n",
    "\n",
    "\n",
    "        elif pos_short == 1 and resultats.iloc[i]['Red_Close'] == 0 :\n",
    "\n",
    "            signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                               'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                               'Buy/Sell Price' : price_sell, 'Quantity' : x,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : 0,\\\n",
    "                                       'Cumulative PNL':round(signals.iloc[:i]['PNL'].sum(),2),\\\n",
    "                                       'Latent PNL':-round((resultats.iloc[i]['Open.S'] - price_sell)*x,2)}],ignore_index=True)\n",
    "            try:\n",
    "                maxdd.append(-round((resultats.iloc[i]['Open.S'] - price_sell)*x,2))\n",
    "            except:\n",
    "                print('Null val of maxdd')\n",
    "                maxdd.append(0)\n",
    "                print('\\n Le ',str(resultats.iloc[i]['Date']))\n",
    "                print('Nouveau pactol : ',round(pactol,2))\n",
    "                print('Le Cumulative PNL est de : ',round(signals.iloc[:i]['PNL'].sum(),2))\n",
    "                print('Le Latent PNL est de : ',maxdd[-1])\n",
    "\n",
    "        elif pos_short == 1 and resultats.iloc[i]['Red_Close'] == 1 :\n",
    "            old_pactol = round(pactol,2)\n",
    "            eq_curx.append(resultats.iloc[i]['Date'])\n",
    "            eq_cury.append(old_pactol)\n",
    "            pos_short = 0\n",
    "            price_buy = round(resultats.iloc[i]['Open.S'],2)\n",
    "            trades.append((round(resultats.iloc[i]['Open.S'],2),resultats.iloc[i]['Date'],-2))\n",
    "            mini_pnl = round(x*(price_sell-price_buy),2)\n",
    "\n",
    "            signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                               'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 1,\\\n",
    "                               'Buy/Sell Price' : price_buy,'Quantity' : x,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : mini_pnl,\\\n",
    "                                       'Cumulative PNL':round(signals.iloc[:i]['PNL'].sum(),2),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "            pactol = round((pactol + mini_pnl),2)\n",
    "            print('\\n Le ',str(resultats.iloc[i]['Date']),', achat pour close de ',x,' actions à',round(resultats.iloc[i]['Open.S'],2),'$')\n",
    "            print('Nouveau pactol : ',pactol)\n",
    "\n",
    "            print('prix de vente',price_sell)\n",
    "            print('prix d achat',price_buy)\n",
    "\n",
    "            print('pnl:', mini_pnl)\n",
    "            pos_duration.append(resultats.iloc[i]['Date'] - time_enter)\n",
    "            \n",
    "            print('Le Cumulative PNL est de : ',round(signals.iloc[:i]['PNL'].sum(),2))\n",
    "            print('Le Latent PNL est de : 0')\n",
    "            print('Duration : ',pos_duration[-1])\n",
    "            \n",
    "            if mini_pnl > 0:\n",
    "                winners.append(mini_pnl)\n",
    "                mini_pnl = 0\n",
    "                nb_win +=1\n",
    "            else :\n",
    "                loosers.append(mini_pnl)\n",
    "                mini_pnl = 0\n",
    "                nb_los +=1\n",
    "        else:\n",
    "\n",
    "            signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                           'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                           'Buy/Sell Price' : 0, 'Quantity' : 0,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : 0,\\\n",
    "                                       'Cumulative PNL':round(signals.iloc[:i]['PNL'].sum(),2),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "    if pos_long == 1:\n",
    "        pos_long = 0\n",
    "        print('Cutting unresolved position')\n",
    "        print(' Le price buy était de : ',price_buy)\n",
    "        x = round((1500)/resultats.iloc[i]['Open.S'])\n",
    "        print('x = ',x)\n",
    "        price_sell = round(resultats.iloc[i]['Open.S'],2)\n",
    "        print('Et le price sell : ',price_sell)\n",
    "        mini_pnl = round(x*(price_sell-price_buy),2)\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                               'Close Long' : 1, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                               'Buy/Sell Price' : price_sell, 'Quantity' : x,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : mini_pnl,\\\n",
    "                                   'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "        pactol = round((pactol + mini_pnl),2)\n",
    "        print('pnl : ',mini_pnl)\n",
    "        if mini_pnl > 0:\n",
    "            winners.append(mini_pnl)\n",
    "            mini_pnl = 0\n",
    "            nb_win +=1\n",
    "        else :\n",
    "            loosers.append(mini_pnl)\n",
    "            mini_pnl = 0\n",
    "            nb_los +=1\n",
    "\n",
    "\n",
    "    if pos_short == 1:\n",
    "        pos_short = 0\n",
    "        print('Cutting uresolved position')\n",
    "        print(' Le price sell était de : ',price_sell)\n",
    "        x = round((1500)/resultats.iloc[i]['Open.S'])\n",
    "        print('x = ',x)\n",
    "        price_buy = round(resultats.iloc[i]['Open.S'],2)\n",
    "        print('Et le price_buy : ',price_buy)\n",
    "        mini_pnl = round(x*(price_sell-price_buy),2)\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                               'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 1,\\\n",
    "                               'Buy/Sell Price' : price_buy, 'Quantity' : x,'Actual' : round(resultats.iloc[i]['Price'],2), 'PNL' : mini_pnl,\\\n",
    "                                   'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "        pactol = round((pactol + mini_pnl),2)\n",
    "        print('pnl : ',mini_pnl)\n",
    "\n",
    "        if mini_pnl > 0:\n",
    "            winners.append(mini_pnl)\n",
    "            mini_pnl = 0\n",
    "            nb_win +=1\n",
    "        else :\n",
    "            loosers.append(mini_pnl)\n",
    "            mini_pnl = 0\n",
    "            nb_los +=1\n",
    "\n",
    "\n",
    "    pnl = round(pactol - (50000),2)\n",
    "    print('\\n Begining of BackTest :',resultats.iloc[0]['Date'])\n",
    "    print('Instrument :',ticker)\n",
    "    print('Face value per trade : $',1500)\n",
    "    print('End of BackTest :',resultats.iloc[-1]['Date'])\n",
    "    duration = pd.to_timedelta((resultats.iloc[-1]['Date'] - resultats.iloc[0]['Date']),unit='d')\n",
    "    print(\"BackTest's period :\",duration)\n",
    "    print('Pnl :',round(pnl,2),'$')\n",
    "    print('% Pnl : ',round(pnl/(1500)*100,2))\n",
    "    if pnl == 0:\n",
    "        continue\n",
    "    print('Total winners :',round(sum(winners),2),'$')\n",
    "    print('Total loosers :',round(sum(loosers),2),'$')\n",
    "    print('Number of winners :',round(nb_win))\n",
    "    print('Number of loosers :',round(nb_los))\n",
    "    if nb_win == 0:\n",
    "        nb_win += 0.00001\n",
    "    if nb_los == 0:\n",
    "        nb_los += 0.00001\n",
    "    print('Maximum Drawdown : ',round(min(maxdd),2))\n",
    "    print('% Max Drawdown : ',round(min(maxdd)/(1500)*100,2),'%')\n",
    "    print('Nombre toatl de trades : ',round(nbL+nbS,2))\n",
    "    print('% de trades Long : ',round((nbL*100)/(nbL+nbS),2))\n",
    "    print('% de trades Short : ',round((nbS*100)/(nbL+nbS),2))\n",
    "    try:\n",
    "        print('% winners :', round((nb_win/(nb_win+nb_los) * 100),2),'%')\n",
    "        print('Average winners :',(round(sum(winners)/(nb_win))))\n",
    "    except:\n",
    "        print('% winners : null')\n",
    "    try:\n",
    "        print('Average losers :',(round(sum(loosers)/(nb_los))))\n",
    "    except:\n",
    "        print('Average losers : Inf')\n",
    "    try:\n",
    "        for t in range(0,len(pos_duration)):\n",
    "            average_duration = pd.to_timedelta((average_duration + pos_duration[t]),unit='d')\n",
    "        average_duration = average_duration/(nb_los+nb_win)\n",
    "        print('Average Duration :', average_duration)\n",
    "    except:\n",
    "        print('No Average Duration available')\n",
    "    try:\n",
    "        print('Profit Factor : ',abs(round((sum(winners)/sum(loosers)),2)))\n",
    "    except:\n",
    "        print('Profit Factor : null')\n",
    "        \n",
    "    \n",
    "\n",
    "    ########################\n",
    "    ##### PLOT TRADES ######\n",
    "    ########################\n",
    "\n",
    "    #plt.figure(figsize=(26,8),dpi=300)\n",
    "    #plt.title('Deep Learning '+ticker+' Trades')\n",
    "    #plt.plot(resultats['Open.S'],color='blue',lw=0.9)\n",
    "    #for i in range(0,len(trades)):\n",
    "    #    if trades[i][2] == 1:\n",
    "    #        plt.scatter(x=trades[i][1],y=trades[i][0],c='green',marker='^',lw=2.5)\n",
    "    #    elif trades[i][2] == -1:\n",
    "    #        plt.scatter(x=trades[i][1],y=trades[i][0],c='red',marker='^',lw=2.5)\n",
    "    #    elif trades[i][2] == 2:\n",
    "    #        plt.scatter(x=trades[i][1],y=trades[i][0],c='g',marker='x',lw=2.5)\n",
    "    #    elif trades[i][2] == -2:\n",
    "    #        plt.scatter(x=trades[i][1],y=trades[i][0],c='r',marker='x',lw=2.5)\n",
    "\n",
    "    #plt.scatter(x=resultats.iloc[i]['Date'],y=resultats.iloc[i]['Open.S'],c='g',marker='^',label='Open Long')\n",
    "    #plt.scatter(x=resultats.iloc[i]['Date'],y=resultats.iloc[i]['Open.S'],c='r',marker='^',label='Open Short')\n",
    "    #plt.scatter(x=resultats.iloc[i]['Date'],y=resultats.iloc[i]['Open.S'],c='g',marker='x',label='Close Long')\n",
    "    #plt.scatter(x=resultats.iloc[i]['Date'],y=resultats.iloc[i]['Open.S'],c='r',marker='x',label='Close Short')\n",
    "    \n",
    "    #plt.legend()\n",
    "    #plt.savefig('backtest de '+str(ticker)+'_02.pdf')\n",
    "    #plt.close()\n",
    "\n",
    "    #########################\n",
    "    ##### PLOT E-CURVE ######\n",
    "    #########################\n",
    "    plt.figure(figsize=(26,8),dpi=300)\n",
    "    plt.title('Deep Learning '+ticker+' Equity Curve')\n",
    "    plt.plot(eq_curx,eq_cury)\n",
    "    plt.scatter(x=eq_curx,y=eq_cury,c='orange',marker='o',lw=2.5)\n",
    "    plt.savefig('backtest de '+str(ticker)+'_e_curve.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    \n",
    "    #print('\\r Boucle ', loop, 'terminée...',end='')\n",
    "    #print('Opération restantes :', len(constituents)-loop,'/',len(constituents),'\\n')\n",
    "\n",
    "    name = 'Name'\n",
    "    sector = 'Sector'\n",
    "    backtest = backtest.append([{'Symb.':ticker,'Name':name,'Sector':sector,'Period':average_duration,'Begin.':resultats.iloc[0,0],'End':resultats.iloc[-1,0],\\\n",
    "                      'Pnl $':pnl,'Pnl %':round(pnl/(1500)*100,2),'Gross Profit':round(sum(winners),2),'Gross Loss':round(sum(loosers),2),'# Winners':nb_win,'# Loosers':nb_los,\\\n",
    "                      '% Winners':round((nb_win/(nb_win+nb_los) * 100),2),'MaxDD $':round(min(maxdd),2),'MaxDD %':round(min(maxdd)/(1500)*100,2),'Aver. Win $':(round(sum(winners)/(nb_win+0.0001))),\\\n",
    "                      'Aver. Loos $':(round(sum(loosers)/(nb_los+0.0001))),'Aver. Duration':average_duration,\\\n",
    "                      'Total Trades':nbL+nbS,'% Long':round((nbL*100)/(nbL+nbS),2),'% Short':round((nbS*100)/(nbL+nbS),2), 'Profit Factor':abs(round((sum(winners)/sum(loosers)),2))}], ignore_index=True)\n",
    "\n",
    "\n",
    "    #signals = signals.append([{ 'Date': list_signals[0], 'Ticker' : list_signals[8], 'Open Long' : list_signals[1],\\\n",
    "                               #'Close Long' : list_signals[2], 'Open Short' : list_signals[3], 'Close Short' : list_signals[4],\\\n",
    "                               #'Buy/Sell Price' : list_signals[5], 'Quantity' : list_signals[6], ' tPNL' : list_signals[7]}])\n",
    "\n",
    "    #signals['Date'] = list_signals[0]\n",
    "    #signals['Ticker'] = list_signals[8]\n",
    "    #signals['Open Long'] = list_signals[1]\n",
    "    #signals['Close Long'] = list_signals[2]\n",
    "    #signals['Open Short'] = list_signals[3]\n",
    "    #signals['Close Short'] = list_signals[4]\n",
    "    #signals['Buy/Sell Price'] = list_signals[5]\n",
    "    #signals['Quantity'] = list_signals[6]\n",
    "    #signals['tPNL'] = list_signals[7]\n",
    "\n",
    "    # symbol / name / sector / period of backtest / debut / fin / pnl / total winners / total loosers / Nb winners / nb loosers / \n",
    "    # / % winners / Max DD / Aver Win / Aver Loos / Average duration / Profit Factor\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = orig_stdout\n",
    "#sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Fore.YELLOW,'Writing BACKTEST CSV AND SIGNALS.CSV',Style.RESET_ALL)\n",
    "backtest.to_csv('BackTest.csv')\n",
    "signals = signals.sort_values(by=['Date'])\n",
    "signals = signals.drop(['Cumulative PNL'],axis=1)\n",
    "signals = signals.reset_index(drop=True)\n",
    "signals.to_csv('SIGNALS.csv')\n",
    "\n",
    "tmps22=round(time.time()-tmps55,2)\n",
    "print(Fore.BLUE,\"\\n Time for completing BackTest Generation = %f\" %tmps22,'seconds \\n',Style.RESET_ALL)\n",
    "\n",
    "print(Fore.CYAN,'BACKTEST CSV WRITED AND SIGNALS.CSV',Style.RESET_ALL)\n",
    "    #except:\n",
    "     #   print(Fore.RED,'Problème loop : ',loop,Style.RESET_ALL)\n",
    "      #  error.append((loop,ticker))\n",
    "\n",
    "        #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,nb_los,nb_win,nbL,nbS,ticker,resultats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultats[Resultats['Date']=='2019-12-11']['Red'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUMULGLOB = []\n",
    "for dujour in sorted(signals['Date'].unique())[:-1]:\n",
    "    cumul = signals[signals['Date']==dujour]['PNL'].sum()\n",
    "    CUMULGLOB.append(cumul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "###### CHOUPINET!! ################\n",
    "###################################\n",
    "\n",
    "\n",
    "tmps55=time.time()\n",
    "df = pd.read_csv('SIGNALS.csv')\n",
    "\n",
    "try:\n",
    "    df = df.drop(['Unnamed: 0'],axis=1)\n",
    "except:\n",
    "    pass\n",
    "choupinet = pd.DataFrame()\n",
    "\n",
    "DT = []\n",
    "OL = []\n",
    "CL = []\n",
    "OS = []\n",
    "CS = []\n",
    "XP = []\n",
    "PNL = []\n",
    "CUM = []\n",
    "YMCA = []\n",
    "NETL = []\n",
    "NETS = []\n",
    "LAT = []\n",
    "XPL = []\n",
    "XPS = []\n",
    "MDD = []\n",
    "NXP = []\n",
    "\n",
    "ol = 0\n",
    "cl = 0\n",
    "os = 0\n",
    "cs = 0\n",
    "xp = 0\n",
    "pnl = 0\n",
    "cum = 0\n",
    "ymca = 0\n",
    "netl = 0\n",
    "nets = 0\n",
    "lat = 0\n",
    "xpl = 0\n",
    "xps = 0\n",
    "mdd = 0\n",
    "nxp = 0\n",
    "\n",
    "df.head(0)\n",
    "\n",
    "for i in range(0,df.shape[0]-1):\n",
    "    \n",
    "    long = df.shape[0]-1\n",
    "    \n",
    "    if i == 1:\n",
    "            print('\\r',Fore.GREEN,' |==',Fore.BLUE,'O',Fore.RED,'==================|',end='',flush=True)\n",
    "    if i == round(1 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |====',Fore.BLUE,'O',Fore.RED,'================|',end='',flush=True)\n",
    "    if i == round(2 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |======',Fore.BLUE,'O',Fore.RED,'==============|',end='',flush=True)\n",
    "    if i == round(3 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |========',Fore.BLUE,'O',Fore.RED,'============|',end='',flush=True)\n",
    "    if i == round(4 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |==========',Fore.BLUE,'O',Fore.RED,'==========|',end='',flush=True)\n",
    "    if i == round(5 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |============',Fore.BLUE,'O',Fore.RED,'========|',end='',flush=True)\n",
    "    if i == round(6 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |==============',Fore.BLUE,'O',Fore.RED,'======|',end='',flush=True)\n",
    "    if i == round(7 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |================',Fore.BLUE,'O',Fore.RED,'====|',end='',flush=True)\n",
    "    if i == round(8 * long / 9):\n",
    "        print('\\r',Fore.GREEN,' |==================',Fore.BLUE,'O',Fore.RED,'==|',Style.RESET_ALL,end='',flush=True)\n",
    "    \n",
    "    \n",
    "    if df.iloc[i+1,0] == df.iloc[i,0]:\n",
    "        ol += df.iloc[i,2]\n",
    "        cl += df.iloc[i,3]\n",
    "        os += df.iloc[i,4]\n",
    "        cs += df.iloc[i,5]\n",
    "        if df.iloc[i,3] == 1 or df.iloc[i,5] == 1 :\n",
    "            xp = xp - (df.iloc[i,6] * df.iloc[i,7])\n",
    "        if df.iloc[i,2] == 1 or df.iloc[i,4] == 1 :\n",
    "            xp = xp + (df.iloc[i,6] * df.iloc[i,7])\n",
    "        \n",
    "        try:\n",
    "            cum += df.iloc[i,9]\n",
    "        except:\n",
    "            cum += 0\n",
    "        pnl += df.iloc[i,9]\n",
    "        lat += df.iloc[i,10]\n",
    "        \n",
    "        if df.iloc[i,2] == 1:\n",
    "            xpl = xpl + (df.iloc[i,6] * df.iloc[i,7])\n",
    "        if df.iloc[i,3] == 1:\n",
    "            xpl = xpl - (df.iloc[i,6] * df.iloc[i,7])\n",
    "        \n",
    "        if df.iloc[i,4] == 1:\n",
    "            xps = xps  -(df.iloc[i,6] * df.iloc[i,7])\n",
    "        if df.iloc[i,5] == 1:\n",
    "            xps = xps + (df.iloc[i,6] * df.iloc[i,7])\n",
    "        \n",
    "        \n",
    "        nxp =xpl+  xps\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ymca = 50000 + cum +lat\n",
    "        netl = netl + ol - cl\n",
    "        nets = nets + os - cs\n",
    "        DT.append(df.iloc[i-1,0])\n",
    "        OL.append(ol)\n",
    "        CL.append(cl)\n",
    "        OS.append(os)\n",
    "        CS.append(cs)\n",
    "        XP.append(xp)\n",
    "        PNL.append(pnl)\n",
    "        CUM.append(cum)\n",
    "        YMCA.append(ymca)\n",
    "        NETL.append(netl)\n",
    "        NETS.append(nets)\n",
    "        LAT.append(lat)\n",
    "        if min(LAT) < 0:\n",
    "             mdd = min(LAT)\n",
    "        XPL.append(xpl)\n",
    "        XPS.append(xps)\n",
    "        MDD.append(mdd)\n",
    "        NXP.append(nxp)\n",
    "        ol = 0\n",
    "        cl = 0\n",
    "        os = 0\n",
    "        cs = 0\n",
    "        pnl = 0\n",
    "        lat = 0\n",
    "        mdd = 0\n",
    "\n",
    "choupinet['Date'] = DT\n",
    "choupinet['Open Long'] = OL\n",
    "choupinet['Close Long'] = CL\n",
    "choupinet['Open Short'] = OS\n",
    "choupinet['Close Short'] = CS\n",
    "choupinet['Exposure Long'] = XPL\n",
    "choupinet['Exposure Short'] = XPS\n",
    "choupinet['Exposure'] = XP\n",
    "choupinet['Net Exposure'] = NXP\n",
    "choupinet['PNL'] = PNL\n",
    "choupinet['Unrealized PNL'] = LAT\n",
    "choupinet['Cumulative PNL'] = CUMULGLOB\n",
    "choupinet['NAV'] = YMCA\n",
    "choupinet['Net Long'] = NETL\n",
    "choupinet['Net Short'] = NETS\n",
    "choupinet['Maximum Drawdown'] = MDD\n",
    "\n",
    "choupinet.to_csv('portfolio_2019.csv')\n",
    "\n",
    "plt.figure(figsize=(26,8),dpi=300)\n",
    "plt.title('Equity curve 2019')\n",
    "plt.ylabel('NAV')\n",
    "plt.xlabel('Days')\n",
    "plt.plot(choupinet['NAV'],color='purple',lw=0.9)\n",
    "plt.savefig('nav_2019.png')\n",
    "tmps22=round(time.time()-tmps55,2)\n",
    "print(Fore.BLUE,\"/n Time for completing Choupinetisation Generation = %f\" %tmps22,'seconds \\n',Style.RESET_ALL)\n",
    "choupinet.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CUMULGLOB),len(LAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals[signals['Date']=='2019-12-10']['Close Long'].sum(),signals[signals['Date']=='2019-12-10']['Open Long'].sum(),\\\n",
    "signals[signals['Date']=='2019-12-10']['Close Short'].sum(),signals[signals['Date']=='2019-12-10']['Open Short'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultats[Resultats['Date']=='2019-12-10']['Green_Close'].sum(),Resultats[Resultats['Date']=='2019-12-10']['Green'].sum(),\\\n",
    "Resultats[Resultats['Date']=='2019-12-10']['Red_Close'].sum(),Resultats[Resultats['Date']=='2019-12-10']['Red'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choupinet['Unrealized PNL'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choupinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leneuf = signals[signals['Date']=='2019-12-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LaBase[(LaBase.index =='2019-12-09')&(LaBase['Symbol']=='VNO')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultats[(Resultats['Date'] =='2019-12-09')&(Resultats['Ticker']=='CSX')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals[(signals['Date'] =='2019-12-09')&(signals['Ticker']=='CSX')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
