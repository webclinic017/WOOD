{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearall():\n",
    "    all = [var for var in globals() if var[0] != \"_\"]\n",
    "    for var in all:\n",
    "        del globals()[var]\n",
    "clearall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Librairies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies imported\n",
      "\n",
      "Global Optimized LumberJack Environment Motor 55\n",
      "LumberJack Jyss 5779(c)\n",
      "\u001b[34m °0Oo_D.A.G._26_oO0°\n",
      "BOOST SKAN 55 Version v1.35 \u001b[0m\n",
      "\n",
      "Sraping tickers\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'constituents_csv.csv' does not exist: b'constituents_csv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-555befe6f559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sraping tickers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mconstituents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'constituents_csv.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scrap -----> ok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# PARAMETRES TEMPORELS INITIAUX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/LumberJack/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'constituents_csv.csv' does not exist: b'constituents_csv.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Importing Librairies...')\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from colorama import Fore, Back, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "import time\n",
    "import datetime as dt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,roc_curve,confusion_matrix,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print('Librairies imported')\n",
    "print('')\n",
    "\n",
    "___Author___='LumberJack Jyss'\n",
    "print('Global Optimized LumberJack Environment Motor 55\\nLumberJack Jyss 5779(c)')\n",
    "print(Fore.BLUE,'°0Oo_D.A.G._26_oO0°')\n",
    "print('BOOST SKAN 55 Version v1.35',Style.RESET_ALL)\n",
    "\n",
    "\n",
    "\n",
    "print('')\n",
    "print('Sraping tickers')\n",
    "constituents = pd.read_csv('constituents_csv.csv')\n",
    "print('Scrap -----> ok')\n",
    "# PARAMETRES TEMPORELS INITIAUX\n",
    "start = pd.to_datetime('2014-01-06')\n",
    "end = pd.to_datetime('2020-01-03')\n",
    "\n",
    "error = []\n",
    "signals = pd.DataFrame(columns = ['Date','Ticker','Open Long','Close Long','Open Short','Close Short','Buy/Sell Price','Quantity','PNL','Cumulative PNL','Latent PNL'])\n",
    "backtest = pd.DataFrame(columns = ['Symb.','Name','Sector','Period','Begin.','End',\\\n",
    "                          'Pnl $','Pnl %','Gross Profit','Gross Loss','# Winners','# Loosers',\\\n",
    "                          '% Winners','MaxDD $','MaxDD %','Aver. Win $',\\\n",
    "                          'Aver. Loos $','Aver. Duration',\\\n",
    "                          'Total Trades','% Long','% Short','Profit Factor'])\n",
    "try :\n",
    "    amorce = pd.read_csv('backTest.csv').index[-1] + 1\n",
    "except:\n",
    "    amorce = 0\n",
    "    backtest = pd.DataFrame(columns = ['Symb.','Name','Sector','Period','Begin.','End',\\\n",
    "                          'Pnl $','Pnl %','Gross Profit','Gross Loss','# Winners','# Loosers',\\\n",
    "                          '% Winners','MaxDD $','MaxDD %','Aver. Win $',\\\n",
    "                          'Aver. Loos $','Aver. Duration',\\\n",
    "                          'Total Trades','% Long','% Short','Profit Factor'])\n",
    "    \n",
    "    \n",
    "try:\n",
    "    amorce2 = pd.read_csv('SIGNALS.csv').index[-1] + 1\n",
    "except:\n",
    "    amorce2 = 0\n",
    "    signals = pd.DataFrame(columns = ['Date','Ticker','Open Long','Close Long','Open Short','Close Short','Buy/Sell Price','Quantity','PNL','Cumulative PNL','Latent PNL'])\n",
    "\n",
    "    \n",
    "# SCRAPING DES DONNES BRUTES\n",
    "def scrap_data(ticker,start,end):\n",
    "    df = web.DataReader(ticker,'yahoo',start,end)\n",
    "    df = df.drop(['Close'],axis=1)\n",
    "    df['Close'] = df['Adj Close']\n",
    "    df = df.drop(['Adj Close'],axis = 1)    \n",
    "    return(df)\n",
    "\n",
    "def prepa_data(df):\n",
    "    tmps1=time.time()\n",
    "    print('Preparing data...')\n",
    "    rsi = talib.RSI(df['Close'],timeperiod=14)\n",
    "    stoc_slowk, stoc_slowd = talib.STOCH(df['High'],df['Low'],df['Close'])\n",
    "    upper, middle, lower =  talib.BBANDS(df['Close'], timeperiod=9, nbdevup=2, nbdevdn=2,matype=0)\n",
    "    sma5 = talib.SMA(df['Close'],timeperiod=5)\n",
    "    sma8 = talib.SMA(df['Close'],timeperiod=8)\n",
    "    sma10 = talib.SMA(df['Close'],timeperiod=10)\n",
    "    sma12 = talib.SMA(df['Close'],timeperiod=12)\n",
    "    sma15 = talib.SMA(df['Close'],timeperiod=15)\n",
    "    sma30 = talib.SMA(df['Close'],timeperiod=30)\n",
    "    sma35 = talib.SMA(df['Close'],timeperiod=35)\n",
    "    sma40 = talib.SMA(df['Close'],timeperiod=40)\n",
    "    sma45 = talib.SMA(df['Close'],timeperiod=45)\n",
    "    sma50 = talib.SMA(df['Close'],timeperiod=50)\n",
    "    atr = talib.ATR(df['High'],df['Low'],df['Close'],timeperiod=10)\n",
    "    delta5_8 = sma5 - sma8\n",
    "    delta8_10 = sma8 - sma10\n",
    "    delta10_12 = sma10 - sma12\n",
    "    delta12_15 = sma12 - sma15\n",
    "    delta15_30 = sma15 - sma30\n",
    "    delta30_35 = sma30 - sma35\n",
    "    delta35_40 = sma35 - sma40\n",
    "    delta40_45 = sma40 - sma45\n",
    "    delta45_50 = sma45 - sma50\n",
    "    bbdelta = upper - middle\n",
    "    price_bolup = df['Close'] - lower\n",
    "    price_bolow = df['Close'] - upper\n",
    "    Ema = talib.EMA(df['Close'],timeperiod=20)\n",
    "    KC_High = Ema + 2*atr\n",
    "    KC_Low = Ema - 2*atr\n",
    "    aroondown, aroonup = talib.AROON(df['High'], df['Low'], timeperiod=9)\n",
    "    aroon = aroonup - aroondown #(aroonup-aroondown)/abs((aroonup-aroondown))\n",
    "    rsi30_list = []\n",
    "    rsi70_list = []\n",
    "    for i in range(0,df.shape[0]):\n",
    "        rsi70_list.append(70 - rsi[i])\n",
    "        rsi30_list.append(rsi[i] - 30)\n",
    "        #except:\n",
    "         #   rsi70_list.append(0)\n",
    "          #  rs30_list.append(0)\n",
    "    varop_spy = df['Open'] - df['Close']\n",
    "    varhl_spy = df['High'] - df['Low']\n",
    "    df['Varop_Spy'] = varop_spy\n",
    "    df['Varhl_spy'] = varhl_spy\n",
    "    df['RSI'] = rsi\n",
    "    df['70 - RSI'] = np.array(rsi70_list)\n",
    "    df['RSI - 30'] = np.array(rsi30_list)\n",
    "    df['BBD_Delta_Up'] = bbdelta\n",
    "    df['delta5_8'] = delta5_8\n",
    "    df['delta8_10'] = delta8_10\n",
    "    df['delta10_12'] = delta10_12\n",
    "    df['delta12_15'] = delta12_15\n",
    "    df['delta15_30'] = delta15_30\n",
    "    df['delta30_35'] = delta30_35\n",
    "    df['delta35_40'] = delta35_40\n",
    "    df['delta40_45'] = delta40_45\n",
    "    df['delta45_50'] = delta45_50\n",
    "    df['Stoc_Slowk'] = stoc_slowk\n",
    "    df['Stoc_Slowd'] = stoc_slowd\n",
    "    df['KC_High'] = KC_High\n",
    "    df['KC_Low'] = KC_Low\n",
    "    df['upper'] = upper\n",
    "    df['lower'] = lower\n",
    "    df['var_bollup_kchigh'] = upper-KC_High\n",
    "    df['var_bolllow_kclow'] = lower-KC_Low\n",
    "    df['Aroon Up'] = aroonup\n",
    "    df['Aroon Down'] = aroondown\n",
    "    df['Delta Aroon'] = aroon\n",
    "    up = []\n",
    "    down = []\n",
    "    df = df.dropna()\n",
    "    df = boost(df)\n",
    "    df['%Futur'] = ((df['Close.S']-df['Close']) *100) / (df['Close'])\n",
    "    df['%Futur2'] = ((df['Close.S2']-df['Close']) *100) / (df['Close'])\n",
    "    for i in range(0,df.shape[0]-5):\n",
    "        if df.iloc[i]['%Futur'] > 0.5 :#or df.iloc[i]['%Futur2'] > 0.1:\n",
    "            up.append(1)\n",
    "            down.append(0)\n",
    "        elif df.iloc[i]['%Futur'] < -0.5: #or df.iloc[i]['%Futur2'] < -0.1:\n",
    "            up.append(0)\n",
    "            down.append(1)\n",
    "        else:\n",
    "            up.append(0)\n",
    "            down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    up.append(0)\n",
    "    down.append(0)\n",
    "    \n",
    "    \n",
    "    df['target_up'] = up  # target_up # abs(np.array(valley))#target_up\n",
    "    df['target_down'] = down # target_down # abs(np.array(peak))#target_down\n",
    "    #df = df.dropna()\n",
    "    tmps2=round(time.time()-tmps1,2)\n",
    "    print (\"Data prepared in = %f\" %tmps2,'seconds')\n",
    "    return(df)\n",
    "\n",
    "def boost(df):\n",
    "    print('Boosting')\n",
    "    X = df.copy()\n",
    "    X = X.drop(['Close'],axis=1)\n",
    "    X['Close'] = df['Close']\n",
    "    y = X.iloc[:,-1]\n",
    "    Xtrain = X.iloc[:-2,:-1]\n",
    "    Xtest = X.iloc[-2:-1,:-1]\n",
    "    yshift = y.shift(-1)\n",
    "    ytrain = yshift.iloc[:-2]\n",
    "    ytest = yshift.iloc[-2:-1]\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=20000, learning_rate=1, gamma=1, subsample=1, colsample_bytree=1, max_depth=100)\n",
    "\n",
    "    model.fit( Xtrain, ytrain, early_stopping_rounds=150, eval_set=[(Xtest, ytest)], verbose=0)\n",
    "\n",
    "    ytrain_pred = model.predict(Xtrain)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "\n",
    "    pred = model.predict(X.iloc[:,:-1])\n",
    "\n",
    "    df['Close.S'] = pred\n",
    "    df['Close.S2'] = df['Close.S']\n",
    "    df = df.dropna()\n",
    "    print('Boost ok')\n",
    "    return(df)\n",
    "\n",
    "    \n",
    "def deep_learning(df):\n",
    "    tmps1=time.time()\n",
    "    X = df.iloc[:,1:-4]\n",
    "    y_up = df.iloc[:,-2].values\n",
    "    y_down = df.iloc[:,-1].values\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    y_up = np.array(y_up).reshape(-1,1)\n",
    "    y_down = np.array(y_down).reshape(-1,1)\n",
    "\n",
    "    Xtrain = X[:bloc1,:]\n",
    "    Xtest = X[bloc1:,:]\n",
    "    ytrain_up = y_up[:bloc1,:]\n",
    "    ytest_up = y_up[bloc1:,:]\n",
    "    ytrain_down = y_down[:bloc1,:]\n",
    "    ytest_down = y_down[bloc1:,:]\n",
    "\n",
    "    seed = 770\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ytrain_up = ytrain_up.reshape(ytrain_up.shape[0],)\n",
    "    ytrain_down = ytrain_down.reshape(ytrain_down.shape[0],)\n",
    "\n",
    "    Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1])\n",
    "\n",
    "    model_up = Sequential()\n",
    "    # Add an input layer \n",
    "    model_up.add(Dense(50, activation='relu'))\n",
    "    # Add one hidden layer \n",
    "    model_up.add(Dense(23, activation='relu'))\n",
    "    # Add an output layer \n",
    "    model_up.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model_down = Sequential()\n",
    "    # Add an input layer \n",
    "    model_down.add(Dense(50, activation='relu'))\n",
    "    # Add one hidden layer \n",
    "    model_down.add(Dense(23, activation='relu'))\n",
    "    # Add an output layer \n",
    "    model_down.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print('Processing move_up')\n",
    "    model_up.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', #rmsprop\n",
    "                  metrics=['accuracy','mse'])\n",
    "    \n",
    "              \n",
    "\n",
    "    history_up = model_up.fit(Xtrain, ytrain_up,epochs=280, batch_size=8, verbose=0)\n",
    "    print('\\n')\n",
    "    print('Processing move_down')\n",
    "    model_down.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', #rmsprop\n",
    "                  metrics=['accuracy','mse'])\n",
    "\n",
    "    history_down = model_down.fit(Xtrain, ytrain_down,epochs=280, batch_size=8, verbose=0)\n",
    "    print('\\n')\n",
    "    print('Computing done')\n",
    "    print('\\n')\n",
    "\n",
    "    train_acc_up = model_up.evaluate(Xtrain, ytrain_up,verbose=1)\n",
    "    train_acc_down = model_down.evaluate(Xtrain, ytrain_down,verbose=1)\n",
    "\n",
    "    yhat_up = model_up.predict_classes(Xtest)\n",
    "    yhat_down = model_down.predict_classes(Xtest)\n",
    "\n",
    "    score_up = model_up.evaluate(Xtest, ytest_up,verbose=1)\n",
    "    score_down = model_down.evaluate(Xtest, ytest_down,verbose=1)\n",
    "\n",
    "    predict_up = model_up.predict(Xtest)\n",
    "    predict_down = model_down.predict(Xtest)\n",
    "\n",
    "    accuracy_up = accuracy_score(ytest_up, yhat_up)\n",
    "    accuracy_down = accuracy_score(ytest_down, yhat_down)\n",
    "\n",
    "    # La précision permet de mesurer la capacité du modèle à refuser résultats non-pertinents : vrais_positifs/(vrais_positifs+faux_positifs)\n",
    "    precision_up = precision_score(ytest_up, yhat_up)  \n",
    "    precision_down = precision_score(ytest_down, yhat_down) \n",
    "\n",
    "\n",
    "    # Recall : (vrai_positifs/(vrais_positifs+faux_négatifs))\n",
    "    recall_up = recall_score(ytest_up, yhat_up) \n",
    "    recall_down = recall_score(ytest_down, yhat_down) \n",
    "\n",
    "\n",
    "    #roc_up=roc_auc_score(ytest_up,yhat_up)\n",
    "    #roc_down=roc_auc_score(ytest_down,yhat_down)\n",
    "    print('\\n')\n",
    "    print(Fore.GREEN,'RESULTATS UP\\n',Style.RESET_ALL)\n",
    "    print('Accuracy: %.2f%%' % (accuracy_up * 100.0))\n",
    "    print(Fore.BLUE,\"Precision: %.2f%% \" % (precision_up *100),Style.RESET_ALL,' => Discrimnination des vrais positifs parmi les faux positifs')\n",
    "    print(\"Recall: %.2f%% \" % (recall_up * 100),' => Positifs trouvés par Golem sur tous les positifs existants')\n",
    "    #print(\"ROC: %.2f%% \" % (roc_up *100))\n",
    "    # get probabilities for positive class\n",
    "\n",
    "    print(classification_report(ytest_up, yhat_up))\n",
    "    conf_matrix = pd.DataFrame(index = ['vrais_réels','Faux_réels'])\n",
    "    conf_matrix['Vrais_estimés'] = ['Vrais_positifs','Faux_positifs']\n",
    "    conf_matrix['Faux_estimés'] = ['Faux_négatif','Vrais-négatifs']\n",
    "    print(confusion_matrix(ytest_up, yhat_up))\n",
    "\n",
    "    print('\\n')\n",
    "    print('_______________________________________________________________________________________________________________________________________________________________\\n')\n",
    "    print(Fore.RED,'RESULTATS DOWN\\n',Style.RESET_ALL)\n",
    "    print('Accuracy: %.2f%%' % (accuracy_down * 100.0))\n",
    "    print(Fore.BLUE,\"Precision: %.2f%% \" % (precision_down *100),Style.RESET_ALL,' => Discrimnination des vrais positifs parmi les faux positifs')\n",
    "    print(\"Recall: %.2f%% \" % (recall_down * 100),' => Positifs trouvés par Golem sur tous les positifs existants')\n",
    "    #print(\"ROC: %.2f%% \" % (roc_down *100))\n",
    "    # get probabilities for positive class\n",
    "\n",
    "    print(classification_report(ytest_down, yhat_down))\n",
    "    conf_matrix = pd.DataFrame(index = ['vrais_réels','Faux_réels'])\n",
    "    conf_matrix['Vrais_estimés'] = ['Vrais_positifs','Faux_positifs']\n",
    "    conf_matrix['Faux_estimés'] = ['Faux_négatif','Vrais-négatifs']\n",
    "    print(confusion_matrix(ytest_down, yhat_down))\n",
    "    print('\\n')\n",
    "\n",
    "    resultats = pd.DataFrame()\n",
    "    resultats['Date'] = df.index[bloc1:]\n",
    "    resultats.index= df.index[bloc1:]\n",
    "    resultats['Move Up'] = yhat_up\n",
    "    resultats['Confiance up'] = (predict_up)*100\n",
    "    resultats['Move Down'] = yhat_down\n",
    "    resultats['Confiance Down'] = (predict_down)*100\n",
    "    resultats['Actual'] = df.iloc[bloc1:]['Close']\n",
    "    resultats['Actual.S'] = df.iloc[bloc1:]['Close.S']\n",
    "    open_S = df['Open'].shift(-1)\n",
    "    resultats['Open.S'] = open_S.iloc[bloc1:]\n",
    "    dmp_cp=[]\n",
    "    dmp_cp = ((resultats['Confiance up']-resultats['Confiance Down'])/(resultats['Confiance up']+resultats['Confiance Down'])*100)\n",
    "    resultats['DMP_CP'] = dmp_cp\n",
    "    tmps2=round(time.time()-tmps1,2)\n",
    "    print (\"Deep Learning executed in = %f\" %tmps2,'seconds')\n",
    "    #resultats.set_index('Date',inplace=True)\n",
    "    #parse_dates=resultats['Date']\n",
    "    return(resultats,precision_up,precision_down,model_up,model_down,scaler)\n",
    "\n",
    "def learn(df):\n",
    "    resultats,precision_up,precision_down,model_up,model_down,scaler = deep_learning(df)\n",
    "    return(resultats,precision_up,precision_down,model_up,model_down,scaler)\n",
    "\n",
    "def grobeta(df,dfb):\n",
    "    # create a time-series of monthly data points\n",
    "    rts = df.resample('M').last()\n",
    "    rbts = dfb.resample('M').last()\n",
    "    dfsm = pd.DataFrame({'s_adjclose' : rts['Close'],\n",
    "                            'b_adjclose' : rbts['Adj Close']},\n",
    "                            index=rts.index)\n",
    "\n",
    "    # compute returns\n",
    "    dfsm[['s_returns','b_returns']] = dfsm[['s_adjclose','b_adjclose']]/\\\n",
    "        dfsm[['s_adjclose','b_adjclose']].shift(1) -1\n",
    "    dfsm = dfsm.dropna()\n",
    "    covmat = np.cov(dfsm[\"s_returns\"],dfsm[\"b_returns\"])\n",
    "\n",
    "    # calculate measures now\n",
    "    beta = covmat[0,1]/covmat[1,1]\n",
    "    alpha= np.mean(dfsm[\"s_returns\"])-beta*np.mean(dfsm[\"b_returns\"])\n",
    "\n",
    "    # r_squared     = 1. - SS_res/SS_tot\n",
    "    ypred = alpha + beta * dfsm[\"b_returns\"]\n",
    "    SS_res = np.sum(np.power(ypred-dfsm[\"s_returns\"],2))\n",
    "    SS_tot = covmat[0,0]*(len(dfsm)-1) # SS_tot is sample_variance*(n-1)\n",
    "    r_squared = 1. - SS_res/SS_tot\n",
    "    # 5- year volatiity and 1-year momentum\n",
    "    volatility = np.sqrt(covmat[0,0])\n",
    "    momentum = np.prod(1+dfsm[\"s_returns\"].tail(12).values) -1\n",
    "\n",
    "    # annualize the numbers\n",
    "    prd = 12. # used monthly returns; 12 periods to annualize\n",
    "    alpha = alpha*prd\n",
    "    volatility = volatility*np.sqrt(prd)\n",
    "\n",
    "    print ('Beta : ',beta,'\\n Alpha : ',alpha,'\\n R_Squared : ', r_squared, '\\n Volatility : ', volatility, '\\n Momentum : ',momentum)\n",
    "    return(beta,alpha,r_squared,volatility,momentum)\n",
    "\n",
    "########################\n",
    "#### MAIN SKAN55 #######\n",
    "########################\n",
    "\n",
    "#for loop in range(0,49):    \n",
    "#for loop in range(amorce,len(constituents)):\n",
    "#print('Loop :',loop)\n",
    "#print('amorce : ',amorce)\n",
    "#print('amorce2 : ',amorce2)\n",
    "\n",
    "#try:\n",
    "ticker = 'ALXN'\n",
    "name = 'smarties'\n",
    "sector = 'S'\n",
    "#ticker = (constituents.iloc[loop]['Symbol'])\n",
    "#name = constituents.iloc[loop]['Name']\n",
    "#sector = constituents.iloc[loop]['Sector']\n",
    "\n",
    "#print(' --- Loop :',loop,' --- ',end='')\n",
    "print(' --- Symbol : ',Fore.YELLOW,ticker,Style.RESET_ALL,' --- ',end='')\n",
    "print(' --- Name : ',name,' --- ',end='')\n",
    "print(' --- Sector : ',sector,' --- ')\n",
    "\n",
    "global delta,bloc1,bloc2\n",
    "tmps1=time.time()\n",
    "print('Scraping data...')\n",
    "\n",
    "df = scrap_data(ticker,start,end)\n",
    "\n",
    "dfb = web.DataReader('^GSPC','yahoo',start,end)\n",
    "\n",
    "beta,alpha, r_squared, volatility, momentum = grobeta(df,dfb)\n",
    "\n",
    "tmps2=round(time.time()-tmps1,2)\n",
    "print (\"executed in = %f\" %tmps2,'seconds')\n",
    "\n",
    "print('\\n')\n",
    "print('GOLEM begins Computing...')\n",
    "print('\\n')\n",
    "delta = round(df.shape[0])\n",
    "bloc1 = round(delta*0.80)\n",
    "bloc2 = delta - bloc1\n",
    "print(\"# of periods : \",delta)\n",
    "print('On 80% - 20% slash : ')\n",
    "print('Bloc 1 : ',bloc1,'\\nBloc 2 :',bloc2,' periods ')\n",
    "print('First period :',df.index[0])\n",
    "print('Split period :',df.index[bloc1-1])\n",
    "print('Last period :',df.index[df.shape[0]-1])\n",
    "print('\\n')\n",
    "\n",
    "print('Data prep')\n",
    "df = prepa_data(df)\n",
    "\n",
    "print(Fore.BLUE,'Deeping in blue',Style.RESET_ALL)\n",
    "print('')\n",
    "#print(' --- Loop :',loop,' --- ',end='')\n",
    "print(' --- Symbol : ',Fore.YELLOW,ticker,Style.RESET_ALL,' --- ',end='')\n",
    "print(' --- Name : ',name,' --- ',end='')\n",
    "print(' --- Sector : ',sector,' --- ')\n",
    "\n",
    "resultats,precision_up,precision_down,model_up,model_down,scaler = learn(df)\n",
    "\n",
    "import sys\n",
    "orig_stdout = sys.stdout\n",
    "f = open('backtest de '+str(ticker)+'.txt', 'w')\n",
    "sys.stdout = f\n",
    "\n",
    "####################\n",
    "#### TEST PLOT ####\n",
    "###################\n",
    "\n",
    "filtre_up = 93\n",
    "filtre_down = 97\n",
    "filtre_up_close = 80\n",
    "filtre_down_close = 80\n",
    "\n",
    "\n",
    "plt.figure(figsize=(26,8),dpi=300)\n",
    "#plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "plt.title('Deep Learning '+name+' Trade Signals')\n",
    "plt.plot(resultats['Actual'],color='purple',lw=0.9,label=ticker)\n",
    "\n",
    "green=[]\n",
    "red=[]\n",
    "green_close=[]\n",
    "red_close=[]\n",
    "\n",
    "for i in range(0,len(resultats)-1):\n",
    "\n",
    "    if resultats.iloc[i]['Confiance Down'] > filtre_down:\n",
    "        doob = -1\n",
    "    elif resultats.iloc[i]['Confiance Down'] > filtre_down_close and resultats.iloc[i]['Confiance Down'] < filtre_down :\n",
    "        waab = -1\n",
    "        doob = 0\n",
    "    elif resultats.iloc[i]['Confiance up'] > filtre_up:\n",
    "        doob = 1\n",
    "    elif resultats.iloc[i]['Confiance up'] > filtre_up_close and resultats.iloc[i]['Confiance up'] < filtre_up:\n",
    "        waab = 1\n",
    "        doob = 0\n",
    "    else :\n",
    "        doob = 0\n",
    "        waab = 0\n",
    "\n",
    "    if doob == 1 :#and resultats.iloc[i]['Confiance up'] > filtre_up:\n",
    "        plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Actual'],c='g',marker='o')\n",
    "        #doob = -1\n",
    "        green.append(1)\n",
    "        red.append(0)\n",
    "        green_close.append(0)\n",
    "        red_close.append(1)\n",
    "\n",
    "    elif doob == -1 :#and resultats.iloc[i]['Confiance Down'] > filtre_down:\n",
    "        plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Actual'],c='r',marker='o')\n",
    "        #doob = 1\n",
    "        green.append(0)\n",
    "        red.append(1)\n",
    "        green_close.append(1)\n",
    "        red_close.append(0)\n",
    "\n",
    "    elif doob == 0 and waab == -1 :#and resultats.iloc[i]['Confiance Down'] > filtre_down:\n",
    "        plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Actual'],c='r',marker='o')\n",
    "        #doob = 1\n",
    "        green.append(0)\n",
    "        red.append(0)\n",
    "        green_close.append(0)\n",
    "        red_close.append(1)\n",
    "\n",
    "    elif waab == 1 :#and resultats.iloc[i]['Confiance Down'] > filtre_down:\n",
    "        plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Actual'],c='r',marker='o')\n",
    "        #doob = 1\n",
    "        green.append(0)\n",
    "        red.append(0)\n",
    "        green_close.append(1)\n",
    "        red_close.append(0)  \n",
    "\n",
    "    else:\n",
    "        green.append(0)\n",
    "        red.append(0)\n",
    "        green_close.append(0)\n",
    "        red_close.append(0)  \n",
    "\n",
    "        #doob = 0\n",
    "\n",
    "\n",
    "plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Actual'],c='g',marker='o',label='Buy Signal')\n",
    "plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Actual'],c='r',marker='o',label='Sell Signal')\n",
    "plt.legend()\n",
    "plt.savefig('backtest de '+str(ticker)+'_01.pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "green.append(0)\n",
    "red.append(0)\n",
    "green_close.append(0)\n",
    "red_close.append(0)\n",
    "resultats['Green'] = green\n",
    "resultats['Red'] = red\n",
    "resultats['Green_Close'] = green_close\n",
    "resultats['Red_Close'] = red_close\n",
    "#resultats['Actual'] = df['Close'][bloc1:]\n",
    "\n",
    "########################\n",
    "####### BACKTEST########\n",
    "########################\n",
    "pos_long = 0\n",
    "pos_short = 0\n",
    "pactol = 10000/beta\n",
    "price_buy = 0\n",
    "price_sell = 0\n",
    "x = 0\n",
    "winners = []\n",
    "loosers = []\n",
    "nb_win = 0\n",
    "nb_los = 0\n",
    "mini_pnl = 0\n",
    "pos_duration = []\n",
    "average_duration = resultats.iloc[0,0] - resultats.iloc[0,0]\n",
    "trades = []\n",
    "eq_curx = []\n",
    "eq_cury = []\n",
    "maxdd = []\n",
    "nbS = 0\n",
    "nbL = 0\n",
    "\n",
    "for i in range(0,len(resultats)-1):\n",
    "    if pos_long == 0 and pos_short == 0 and resultats.iloc[i]['Green'] == 1 :\n",
    "        pos_long = 1\n",
    "        nbL+=1\n",
    "        x = round((10000/beta)/resultats.iloc[i]['Open.S'])\n",
    "        price_buy = round(resultats.iloc[i]['Open.S'],2)\n",
    "        time_enter = resultats.iloc[i]['Date']\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 1,\\\n",
    "                           'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                           'Buy/Sell Price' : price_buy, 'Quantity' : x, 'PNL' : 0,\\\n",
    "                                   'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),\\\n",
    "                                   'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "        print('\\n Le ',str(resultats.iloc[i]['Date']),', achat de ',x,' actions à',round(resultats.iloc[i]['Open.S'],2),'$')\n",
    "        print('Nouveau pactol : ',round(pactol,2))\n",
    "        trades.append((round(resultats.iloc[i]['Open.S'],2),resultats.iloc[i]['Date'],1))\n",
    "\n",
    "    elif pos_long == 1 and resultats.iloc[i]['Green_Close'] == 0 :\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                           'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                           'Buy/Sell Price' : price_buy, 'Quantity' : x, 'PNL' : 0,\\\n",
    "                                   'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),\\\n",
    "                                   'Latent PNL':round((resultats.iloc[i]['Open.S'] - price_buy)*x,2)}],ignore_index=True)\n",
    "        try:\n",
    "            maxdd.append(round((resultats.iloc[i]['Open.S'] - price_buy)*x,2))\n",
    "        except:\n",
    "            print('Null val of maxdd')\n",
    "            maxdd.append('Null')\n",
    "\n",
    "\n",
    "    elif pos_long == 1 and resultats.iloc[i]['Green_Close'] == 1 :\n",
    "        old_pactol = round(pactol,2)\n",
    "        eq_curx.append(resultats.iloc[i]['Date'])\n",
    "        eq_cury.append(old_pactol)\n",
    "        pos_long = 0\n",
    "        price_sell = round(resultats.iloc[i]['Open.S'],2)\n",
    "        mini_pnl = round(x*(price_sell-price_buy),2)\n",
    "        trades.append((round(resultats.iloc[i]['Open.S'],2),resultats.iloc[i]['Date'],2))\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                           'Close Long' : 1, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                           'Buy/Sell Price' : price_sell, 'Quantity' : x, 'PNL' : mini_pnl,\\\n",
    "                                   'Cumulative PNL':round(signals.iloc[:i]['PNL'].sum(),2),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "        pactol = round((pactol + mini_pnl),2)\n",
    "        print('\\n Le ',str(resultats.iloc[i]['Date']),', vente pour close de ',x,' actions à',round(resultats.iloc[i]['Open.S'],2),'$')\n",
    "        print('Nouveau pactol : ',pactol)\n",
    "        print('pnl:', mini_pnl)\n",
    "        print('prix de vente',price_sell)\n",
    "        print('prix d achat',price_buy)\n",
    "\n",
    "        pos_duration.append(resultats.iloc[i]['Date'] - time_enter)\n",
    "\n",
    "        if mini_pnl > 0:\n",
    "            winners.append(mini_pnl)\n",
    "            mini_pnl = 0\n",
    "            nb_win +=1\n",
    "        else :\n",
    "            loosers.append(mini_pnl)\n",
    "            mini_pnl = 0\n",
    "            nb_los +=1\n",
    "\n",
    "\n",
    "    elif pos_short == 0 and pos_long == 0 and resultats.iloc[i]['Red']:\n",
    "        pos_short = 1\n",
    "        nbS+=1\n",
    "        x = round((10000/beta)/resultats.iloc[i]['Open.S'])\n",
    "        price_sell = round(resultats.iloc[i]['Open.S'],2)\n",
    "        time_enter = resultats.iloc[i]['Date']\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                           'Close Long' : 0, 'Open Short' : 1, 'Close Short' : 0,\\\n",
    "                           'Buy/Sell Price' : price_sell, 'Quantity' : x, 'PNL' : 0,\\\n",
    "                                   'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "        print('\\n Le ',str(resultats.iloc[i]['Date']),', vente de ',x,' actions à',round(resultats.iloc[i]['Open.S'],2),'$')\n",
    "        print('Nouveau pactol : ',pactol)\n",
    "        trades.append((round(resultats.iloc[i]['Open.S'],2),resultats.iloc[i]['Date'],-1))\n",
    "\n",
    "\n",
    "    elif pos_short == 1 and resultats.iloc[i]['Red_Close'] == 0 :\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                           'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                           'Buy/Sell Price' : price_sell, 'Quantity' : x, 'PNL' : 0,\\\n",
    "                                   'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),\\\n",
    "                                   'Latent PNL':-round((resultats.iloc[i]['Open.S'] - price_sell)*x,2)}],ignore_index=True)\n",
    "        try:\n",
    "            maxdd.append(round((resultats.iloc[i]['Open.S'] - price_sell)*x,2))\n",
    "        except:\n",
    "            print('Null val of maxdd')\n",
    "            maxdd.append(0)\n",
    "\n",
    "    elif pos_short == 1 and resultats.iloc[i]['Red_Close'] == 1 :\n",
    "        old_pactol = round(pactol,2)\n",
    "        eq_curx.append(resultats.iloc[i]['Date'])\n",
    "        eq_cury.append(old_pactol)\n",
    "        pos_short = 0\n",
    "        price_buy = round(resultats.iloc[i]['Open.S'],2)\n",
    "        trades.append((round(resultats.iloc[i]['Open.S'],2),resultats.iloc[i]['Date'],-2))\n",
    "        mini_pnl = round(x*(price_sell-price_buy),2)\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                           'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 1,\\\n",
    "                           'Buy/Sell Price' : price_buy, 'Quantity' : x, 'PNL' : mini_pnl,\\\n",
    "                                   'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "        pactol = round((pactol + mini_pnl),2)\n",
    "        print('\\n Le ',str(resultats.iloc[i]['Date']),', achat pour close de ',x,' actions à',round(resultats.iloc[i]['Open.S'],2),'$')\n",
    "        print('Nouveau pactol : ',pactol)\n",
    "\n",
    "        print('prix de vente',price_sell)\n",
    "        print('prix d achat',price_buy)\n",
    "\n",
    "        print('pnl:', mini_pnl)\n",
    "        pos_duration.append(resultats.iloc[i]['Date'] - time_enter)\n",
    "        if mini_pnl > 0:\n",
    "            winners.append(mini_pnl)\n",
    "            mini_pnl = 0\n",
    "            nb_win +=1\n",
    "        else :\n",
    "            loosers.append(mini_pnl)\n",
    "            mini_pnl = 0\n",
    "            nb_los +=1\n",
    "    else:\n",
    "\n",
    "        signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                       'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                       'Buy/Sell Price' : 0, 'Quantity' : 0, 'PNL' : 0,\\\n",
    "                                   'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "if pos_long == 1:\n",
    "    pos_long = 0\n",
    "    print('Cutting non resolved position')\n",
    "    print(' Le price buy était de : ',price_buy)\n",
    "    x = round((10000/beta)/resultats.iloc[i]['Open.S'])\n",
    "    print('x = ',x)\n",
    "    price_sell = round(resultats.iloc[i]['Open.S'],2)\n",
    "    print('Et le price sell : ',price_sell)\n",
    "    mini_pnl = round(x*(price_sell-price_buy),2)\n",
    "\n",
    "    signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                           'Close Long' : 1, 'Open Short' : 0, 'Close Short' : 0,\\\n",
    "                           'Buy/Sell Price' : price_sell, 'Quantity' : x, 'PNL' : mini_pnl,\\\n",
    "                               'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "    pactol = round((pactol + mini_pnl),2)\n",
    "    print('pnl : ',mini_pnl)\n",
    "    if mini_pnl > 0:\n",
    "        winners.append(mini_pnl)\n",
    "        mini_pnl = 0\n",
    "        nb_win +=1\n",
    "    else :\n",
    "        loosers.append(mini_pnl)\n",
    "        mini_pnl = 0\n",
    "        nb_los +=1\n",
    "\n",
    "\n",
    "if pos_short == 1:\n",
    "    pos_short = 0\n",
    "    print('Cutting non resolved position')\n",
    "    print(' Le price sell était de : ',price_sell)\n",
    "    x = round((10000/beta)/resultats.iloc[i]['Open.S'])\n",
    "    print('x = ',x)\n",
    "    price_buy = round(resultats.iloc[i]['Open.S'],2)\n",
    "    print('Et le price_buy : ',price_buy)\n",
    "    mini_pnl = round(x*(price_sell-price_buy),2)\n",
    "\n",
    "    signals = signals.append([{ 'Date': resultats.iloc[i]['Date'], 'Ticker' : ticker, 'Open Long' : 0,\\\n",
    "                           'Close Long' : 0, 'Open Short' : 0, 'Close Short' : 1,\\\n",
    "                           'Buy/Sell Price' : price_buy, 'Quantity' : x, 'PNL' : mini_pnl,\\\n",
    "                               'Cumulative PNL':signals.iloc[:i]['PNL'].sum(),'Latent PNL':0}],ignore_index=True)\n",
    "\n",
    "    pactol = round((pactol + mini_pnl),2)\n",
    "    print('pnl : ',mini_pnl)\n",
    "\n",
    "    if mini_pnl > 0:\n",
    "        winners.append(mini_pnl)\n",
    "        mini_pnl = 0\n",
    "        nb_win +=1\n",
    "    else :\n",
    "        loosers.append(mini_pnl)\n",
    "        mini_pnl = 0\n",
    "        nb_los +=1\n",
    "\n",
    "\n",
    "pnl = round(pactol - (10000/beta),2)\n",
    "print('\\n Begining of BackTest :',resultats.iloc[0]['Date'])\n",
    "print('Instrument :',ticker)\n",
    "print('Face value per trade : $',10000/beta)\n",
    "print('End of BackTest :',resultats.iloc[-1]['Date'])\n",
    "duration = pd.to_timedelta((resultats.iloc[-1]['Date'] - resultats.iloc[0]['Date']),unit='d')\n",
    "print(\"BackTest's period :\",duration)\n",
    "print('Pnl :',round(pnl,2),'$')\n",
    "print('% Pnl : ',round(pnl/(10000/beta)*100,2))\n",
    "print('Total winners :',round(sum(winners),2),'$')\n",
    "print('Total loosers :',round(sum(loosers),2),'$')\n",
    "print('Number of winners :',round(nb_win))\n",
    "print('Number of loosers :',round(nb_los))\n",
    "print('Maximum Drawdown : ',round(min(maxdd),2))\n",
    "print('% Max Drawdown : ',round(min(maxdd)/(10000/beta)*100,2),'%')\n",
    "print('Nombre toatl de trades : ',round(nbL+nbS,2))\n",
    "print('% de trades Long : ',round((nbL*100)/(nbL+nbS),2))\n",
    "print('% de trades Short : ',round((nbS*100)/(nbL+nbS),2))\n",
    "try:\n",
    "    print('% winners :', round((nb_win/(nb_win+nb_los) * 100),2),'%')\n",
    "    print('Average winners :',(round(sum(winners)/(nb_win))))\n",
    "except:\n",
    "    print('% winners : null')\n",
    "try:\n",
    "    print('Average losers :',(round(sum(loosers)/(nb_los))))\n",
    "except:\n",
    "    print('Average losers : Inf')\n",
    "try:\n",
    "    for t in range(0,len(pos_duration)):\n",
    "        average_duration = pd.to_timedelta((average_duration + pos_duration[t]),unit='d')\n",
    "    average_duration = average_duration/(nb_los+nb_win)\n",
    "    print('Average Duration :', average_duration)\n",
    "except:\n",
    "    print('No Average Duration available')\n",
    "try:\n",
    "    print('Profit Factor : ',abs(round((sum(winners)/sum(loosers)),2)))\n",
    "except:\n",
    "    print('Profit Factor : null')\n",
    "\n",
    "########################\n",
    "##### PLOT TRADES ######\n",
    "########################\n",
    "\n",
    "plt.figure(figsize=(26,8),dpi=300)\n",
    "plt.title('Deep Learning '+ticker+' Trades')\n",
    "plt.plot(resultats['Open.S'],color='blue',lw=0.9)\n",
    "for i in range(0,len(trades)):\n",
    "    if trades[i][2] == 1:\n",
    "        plt.scatter(x=trades[i][1],y=trades[i][0],c='green',marker='^',lw=2.5)\n",
    "    elif trades[i][2] == -1:\n",
    "        plt.scatter(x=trades[i][1],y=trades[i][0],c='red',marker='^',lw=2.5)\n",
    "    elif trades[i][2] == 2:\n",
    "        plt.scatter(x=trades[i][1],y=trades[i][0],c='g',marker='x',lw=2.5)\n",
    "    elif trades[i][2] == -2:\n",
    "        plt.scatter(x=trades[i][1],y=trades[i][0],c='r',marker='x',lw=2.5)\n",
    "\n",
    "plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Open.S'],c='g',marker='^',label='Open Long')\n",
    "plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Open.S'],c='r',marker='^',label='Open Short')\n",
    "plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Open.S'],c='g',marker='x',label='Close Long')\n",
    "plt.scatter(x=resultats.index[i],y=resultats.iloc[i]['Open.S'],c='r',marker='x',label='Close Short')\n",
    "plt.legend()\n",
    "plt.savefig('backtest de '+str(ticker)+'_02.pdf')\n",
    "plt.close()\n",
    "\n",
    "#########################\n",
    "##### PLOT E-CURVE ######\n",
    "#########################\n",
    "plt.figure(figsize=(26,8),dpi=300)\n",
    "plt.title('Deep Learning '+ticker+' Equity Curve')\n",
    "plt.plot(eq_curx,eq_cury)\n",
    "plt.scatter(x=eq_curx,y=eq_cury,c='orange',marker='o',lw=2.5)\n",
    "plt.savefig('backtest de '+str(ticker)+'_03.pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "f.close()\n",
    "sys.stdout = orig_stdout\n",
    "\n",
    "#print('\\r Boucle ', loop, 'terminée...',end='')\n",
    "#print('Opération restantes :', len(constituents)-loop,'/',len(constituents),'\\n')\n",
    "\n",
    "\n",
    "backtest = backtest.append([{'Symb.':ticker,'Name':name,'Sector':sector,'Period':duration,'Begin.':resultats.iloc[0,0],'End':resultats.iloc[-1,0],\\\n",
    "                  'Pnl $':pnl,'Pnl %':round(pnl/(10000/beta)*100,2),'Gross Profit':round(sum(winners),2),'Gross Loss':round(sum(loosers),2),'# Winners':nb_win,'# Loosers':nb_los,\\\n",
    "                  '% Winners':round((nb_win/(nb_win+nb_los) * 100),2),'MaxDD $':round(min(maxdd),2),'MaxDD %':round(min(maxdd)/(10000/beta)*100,2),'Aver. Win $':(round(sum(winners)/(nb_win))),\\\n",
    "                  'Aver. Loos $':(round(sum(loosers)/(nb_los))),'Aver. Duration':average_duration,\\\n",
    "                  'Total Trades':nbL+nbS,'% Long':round((nbL*100)/(nbL+nbS),2),'% Short':round((nbS*100)/(nbL+nbS),2), 'Profit Factor':abs(round((sum(winners)/sum(loosers)),2))}], ignore_index=True)\n",
    "\n",
    "\n",
    "#signals = signals.append([{ 'Date': list_signals[0], 'Ticker' : list_signals[8], 'Open Long' : list_signals[1],\\\n",
    "                           #'Close Long' : list_signals[2], 'Open Short' : list_signals[3], 'Close Short' : list_signals[4],\\\n",
    "                           #'Buy/Sell Price' : list_signals[5], 'Quantity' : list_signals[6], ' tPNL' : list_signals[7]}])\n",
    "\n",
    "#signals['Date'] = list_signals[0]\n",
    "#signals['Ticker'] = list_signals[8]\n",
    "#signals['Open Long'] = list_signals[1]\n",
    "#signals['Close Long'] = list_signals[2]\n",
    "#signals['Open Short'] = list_signals[3]\n",
    "#signals['Close Short'] = list_signals[4]\n",
    "#signals['Buy/Sell Price'] = list_signals[5]\n",
    "#signals['Quantity'] = list_signals[6]\n",
    "#signals['tPNL'] = list_signals[7]\n",
    "\n",
    "# symbol / name / sector / period of backtest / debut / fin / pnl / total winners / total loosers / Nb winners / nb loosers / \n",
    "# / % winners / Max DD / Aver Win / Aver Loos / Average duration / Profit Factor\n",
    "print(Fore.YELLOW,'Writing BACKTEST CSV AND SIGNALS.CSV',Style.RESET_ALL)\n",
    "backtest.to_csv('BackTest.csv')\n",
    "signals.sort_values(by=['Date'])\n",
    "signals.to_csv('SIGNALS.csv')\n",
    "\n",
    "print(Fore.CYAN,'BACKTEST CSV WRITED AND SIGNALS.CSV',Style.RESET_ALL)\n",
    "#except:\n",
    " #   print(Fore.RED,'Problème loop : ',loop,Style.RESET_ALL)\n",
    "  #  error.append((loop,ticker))\n",
    "\n",
    "    #continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('MMM_BasePrep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#orig_stdout = sys.stdout\n",
    "#f = open('backtestv2_4.txt', 'w')\n",
    "#sys.stdout = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f.close()\n",
    "#sys.stdout = orig_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "backtest = pd.DataFrame(columns = ['Symb.','Name','Sector','period','Begin.','End',\\\n",
    "                          'Pnl','%Pnl','Total Winners','Total Loosers','Nb Win','Nb Los',\\\n",
    "                          '% Winners','MaxDD','%MaxDD','Aver. Win',\\\n",
    "                          'Aver. Los','Aver. Duration',\\\n",
    "                          'Total Trades','% Long','% Short','Profit Factor'])\n",
    "backtest.to_csv('BackTest.csv')\n",
    "\n",
    "signals = pd.DataFrame(columns = ['Date','Ticker','Open Long','Close Long','Open Short','Close Short','Buy/Sell Price','Quantity','tPNL'])\n",
    "signals.to_csv('SIGNALS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['Close'])\n",
    "plt.plot(df['Close.S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.index>='2018-09-01')&(df.index<='2018-11-01')]['Close.S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'High','Low','Open','Volume','Close','Varop_Spy','Varhl_spy','RSI','70 - RSI','RSI - 30','BBD_Delta_Up','delta5_8','delta8_10','delta10_12','delta12_15','delta15_30','delta30_35','delta35_40','delta40_45','delta45_50','Stoc_Slowk','Stoc_Slowd','KC_High','KC_Low','upper','lower','var_bollup_kchigh','var_bolllow_kclow','Aroon Up','Aroon Down','Delta Aroon','Close.S','Close.S2','%Futur','%Futur2','target_up','target_down'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
