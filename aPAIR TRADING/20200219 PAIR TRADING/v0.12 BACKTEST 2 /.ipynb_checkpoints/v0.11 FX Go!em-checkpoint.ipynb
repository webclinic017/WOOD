{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearall():\n",
    "    all = [var for var in globals() if var[0] != \"_\"]\n",
    "    for var in all:\n",
    "        del globals()[var]\n",
    "clearall()\n",
    "\n",
    "# https://www.datacamp.com/community/tutorials/introduction-factor-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "######## LIBRAIRIES ########\n",
    "############################\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from colorama import Fore, Back, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import time\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "######## FONCTIONS ########\n",
    "###########################\n",
    "def ols(model,results,residuals):\n",
    "    jb = sm.stats.stattools.jarque_bera(residuals)[0]\n",
    "    p_value = sm.stats.stattools.jarque_bera(residuals)[1]\n",
    "    skew = round(sm.stats.stattools.robust_skewness(residuals)[0],4)\n",
    "    kurtosis = round(sm.stats.stattools.robust_kurtosis(residuals)[0],4)\n",
    "    print (name+' : ',results.summary())\n",
    "    durbinwatson = sm.stats.stattools.durbin_watson(residuals, axis=0)\n",
    "    print (name+' : ',durbinwatson)\n",
    "    return(jb,p_value,skew,kurtosis,durbinwatson)\n",
    "\n",
    "def ols_diff(diff):\n",
    "    model_diff = sm.OLS(diff[1:],df.index[1:])\n",
    "    results_diff = model_diff.fit()\n",
    "    residuals_diff = results_diff.resid\n",
    "    summary_diff = results_diff.summary()\n",
    "\n",
    "    jb_diff = sm.stats.stattools.jarque_bera(residuals_diff)[0]\n",
    "    p_value_diff = sm.stats.stattools.jarque_bera(residuals_diff)[1]\n",
    "    skew_diff = round(sm.stats.stattools.robust_skewness(residuals_diff)[0],4)\n",
    "    kurtosis_diff = round(sm.stats.stattools.robust_kurtosis(residuals_diff)[0],4)\n",
    "    print (name+' : ',results_diff.summary())\n",
    "    durbinwatson_diff = sm.stats.stattools.durbin_watson(residuals_diff, axis=0)\n",
    "    print (name+' : ',durbinwatson_diff)\n",
    "    return(jb_diff,p_value_diff,skew_diff,kurtosis_diff,durbinwatson_diff)\n",
    "\n",
    "def jarque_berra(df):\n",
    "    print(Fore.LIGHTBLUE_EX,'\\nTEST DE NORMALITE : JARQUE-BERA '+name,Style.RESET_ALL)\n",
    "    if p_value <= 0.05:\n",
    "        print(\"Puisque la p-value (\",round(p_value,4),\") de la statistique de Jarque-Bera est inférieure au seuil de signification de 5%, donc on \",\\\n",
    "        \"refuse l’hypothèse de la normalité de la série \")\n",
    "        print(Fore.GREEN,'TEST JARQUE-BERRA VALIDE',Style.RESET_ALL)\n",
    "    else:\n",
    "        print(\"Puisque la p-value (\",round(p_value,4),\") de la statistique de Jarque-Bera est supérieure au seuil de signification de 5%\",\\\n",
    "        \" donc on refusel’hypothèse de la normalité de la série \")\n",
    "        print(Fore.RED,\"TEST JARQUE-BERA ECHOUE\",Style.RESET_ALL)\n",
    "    return()\n",
    "\n",
    "def skewness(df):\n",
    "    print(Fore.LIGHTBLUE_EX,\"\\nTEST D'ASSYMETRIE: SKEWNESS \"+name,Style.RESET_ALL)\n",
    "    if skew < -0.1 or skew > 0.1:\n",
    "        print(\"Puisque le skewness (\",round(skew,4),\") de la statistiqest éloigné de 0, donc on valide en niveau 1 une distribution NON NORMALE\")\n",
    "        print(Fore.GREEN,'TEST SKEWNESS VALIDE',Style.RESET_ALL)\n",
    "    else:\n",
    "        print(Fore.RED,'/!\\ ATTENTION SUPISCION DE NORMALITE /!\\ ')\n",
    "        print(Fore.RED,\"TEST SKEWNESS ECHOUE\",Style.RESET_ALL)\n",
    "    return()\n",
    "\n",
    "def kurtos(df):\n",
    "    print(Fore.LIGHTBLUE_EX,\"\\nTEST D'ASSYMETRIE: KURTOSIS \"+name,Style.RESET_ALL)\n",
    "    if kurtosis > -3.1 or kurtosis < 3.1:\n",
    "        print(\"Puisque le skewness (\",round(kurtosis,4),\") de la statistiqest éloigné de 3, donc on valide en niveau 2 une distribution NON NORMALE\")\n",
    "        print(Fore.GREEN,'TEST DE KURTOSIS VALIDE',Style.RESET_ALL)\n",
    "    else:\n",
    "        print(Fore.RED,'/!\\ ATTENTION SUPISCION DE NORMALITE /!\\ ')\n",
    "        print(Fore.RED,\"TEST KURTOSIS ECHOUE\",Style.RESET_ALL)\n",
    "    return()\n",
    "def autocor(df):\n",
    "    print(Fore.LIGHTBLUE_EX,\"\\nCORRELOGRAMME D'AUTOCORRELATION DE LA PAIRE \"+name,Style.RESET_ALL)\n",
    "    plot_acf(df['Close'])\n",
    "    plot_pacf(df['Close'], lags=50)\n",
    "    autocorell = pd.DataFrame()\n",
    "    autocorell['ACF'] = sm.tsa.stattools.acf(df['Close'],qstat=True,fft=False)[0]\n",
    "    autocorell['PACF'] = sm.tsa.stattools.pacf(df['Close'])\n",
    "    QSTAT = list(sm.tsa.stattools.acf(df['Close'],qstat=True,fft=False)[1])\n",
    "    QSTAT.append(df.iloc[-1]['Close'])\n",
    "    PROB = list(sm.tsa.stattools.acf(df['Close'],qstat=True,alpha=0.05,fft=False)[3])\n",
    "    PROB.append(0.5)\n",
    "    autocorell['QSTAT'] = QSTAT\n",
    "    autocorell['PROB'] = PROB\n",
    "    print(name+' : ',autocorell.head())\n",
    "    index = 0\n",
    "    for i in range(len(autocorell)-1):\n",
    "        if autocorell.iloc[i]['PACF']>autocorell.iloc[i]['PROB']+0.1:\n",
    "            index += 1\n",
    "    if index >= 1:\n",
    "        print(\"L'index de sortie de l'intervalle de confiance à 5% est de\",index,\". Il apparait donc clairement que la série n'est pas un bruit blanc\")\n",
    "        print(Fore.GREEN,'TEST AUTOCORRELATION VALIDE',Style.RESET_ALL)\n",
    "    else:\n",
    "        print(\"L'index de sortie de l'intervalle de confiance à 5% est de\",index,\". Nous ne pouvons pas déterminer que la série n'est pas un bruit blanc\")\n",
    "    return()\n",
    "\n",
    "def autocor_diff(diff):\n",
    "    print(Fore.LIGHTBLUE_EX,\"\\nCORRELOGRAMME D'AUTOCORRELATION DE LA PAIRE EUR/USD EN PREMIERE DIFFERENCE\",Style.RESET_ALL)\n",
    "    plot_acf(diff)\n",
    "    plot_pacf(diff, lags=50)\n",
    "    autocorell = pd.DataFrame()\n",
    "    autocorell['ACF'] = sm.tsa.stattools.acf(diff,qstat=True,fft=False)[0]\n",
    "    autocorell['PACF'] = sm.tsa.stattools.pacf(diff)\n",
    "    QSTAT = list(sm.tsa.stattools.acf(diff,qstat=True)[1],fft=False)\n",
    "    QSTAT.append(0)\n",
    "    PROB = list(sm.tsa.stattools.acf(diff,qstat=True,alpha=0.05)[3],fft=False)\n",
    "    PROB.append(0.5)\n",
    "    autocorell['QSTAT'] = QSTAT\n",
    "    autocorell['PROB'] = PROB\n",
    "    print(name+' : ',autocorell.head())\n",
    "    index = 0\n",
    "    for i in range(len(autocorell)-1):\n",
    "        if autocorell.iloc[i]['PACF']>autocorell.iloc[i]['PROB']+0.1:\n",
    "            index += 1\n",
    "    if index >= 1:\n",
    "        print(\"L'index de sortie de l'intervalle de confiance à 5% est de\",index,\". Il apparait donc clairement que la série n'est pas un bruit blanc\")\n",
    "        print(Fore.GREEN,'TEST AUTOCORRELATION VALIDE',Style.RESET_ALL)\n",
    "        print(\"D’après le corrélogramme de la série ‘EURUSD’ en différence première, nous constatons que la première bande associée à la fonction    d’auto-corrélation partielle sort significativement de l’intervalle de confiance représenté par les pointillés, donc nous retenons p = 1 comme nombre de retards pour les régressions des tests ADF\")\n",
    "        p = 1\n",
    "    else:\n",
    "        print(\"L'index de sortie de l'intervalle de confiance à 5% est de\",index,\". Nous ne pouvons pas déterminer que la série n'est pas un bruit blanc\")\n",
    "    return()\n",
    "\n",
    "def test_stationarity(timeseries,lag):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(window=12).mean()\n",
    "    rolstd = timeseries.rolling(window=12).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    plt.figure(figsize=(20,6))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation for '+name)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test pour la paire : '+name)\n",
    "    dftest = adfuller(timeseries, autolag=None,maxlag=lag )#'AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "    return(dfoutput)\n",
    "\n",
    "def test_adf(df):\n",
    "    print(Fore.BLUE,\"\\nADF MODELE 3 pour la paire : \"+name,Style.RESET_ALL)\n",
    "    X = df['Close'].values\n",
    "    result_adf = adfuller(X)\n",
    "    print('ADF Statistic: %f' % result_adf[0])\n",
    "    print('p-value: %f' % result_adf[1])\n",
    "    print('Critical Values:')\n",
    "\n",
    "    for key, value in result_adf[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if result_adf[1] >= 0.05:\n",
    "        print(\"La p_value est de \",result_adf[1],\"et est bien supérieure à 0.05. On accèpte l'hypothèse nulle Ho. Il n'y a pas de trend significatif\")\n",
    "        print(Fore.GREEN,'TEST ADF => NON STATIONNAIRE',Style.RESET_ALL)\n",
    "\n",
    "    else:\n",
    "        print(Fore.RED,\"TEST ADF => STATIONNAIRE\",Style.RESET_ALL)\n",
    "\n",
    "    print(Fore.BLUE,\"\\nADF MODELE 2 (LAG)\",Style.RESET_ALL)\n",
    "    X = diff[1:].values\n",
    "    result_adf = adfuller(X)\n",
    "    print('ADF Statistic: %f' % result_adf[0])\n",
    "    print('p-value: %f' % result_adf[1])\n",
    "    print('Critical Values:')\n",
    "\n",
    "    for key, value in result_adf[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if result_adf[1] >= 0.05 :\n",
    "        print(Fore.GREEN,'TEST ADF => NON STATIONNAIRE',Style.RESET_ALL)\n",
    "\n",
    "    elif result_adf[0] >= min([result_adf[4]['1%'],result_adf[4]['5%'],result_adf[4]['10%']]):\n",
    "        print(Fore.GREEN,'TEST ADF => NON STATIONNAIRE',Style.RESET_ALL)\n",
    "\n",
    "    else:\n",
    "        print(\"La série est stationnaire en intégration d'ordre 1\")\n",
    "        print(Fore.RED,\"TEST ADF => STATIONNAIRE\",Style.RESET_ALL)\n",
    "    return()\n",
    "\n",
    "def isname(pair):\n",
    "    \n",
    "    if pair.equals(eurusd):\n",
    "        name = 'EUR/USD'\n",
    "    elif pair.equals(audusd):\n",
    "        name = 'AUD/USD'\n",
    "    elif pair.equals(chfusd):\n",
    "        name = 'CHF/USD'\n",
    "    elif pair.equals(gbpusd):\n",
    "        name = 'GBP/USD'\n",
    "    elif pair.equals(jpyusd):\n",
    "        name = 'JPY/USD'\n",
    "    \n",
    "    return(name)\n",
    "\n",
    "def revname(name):\n",
    "    if name == 'EUR/USD':\n",
    "        pair = eurusd\n",
    "    elif name == 'AUD/USD':\n",
    "        pair = audusd\n",
    "    elif name == 'CHF/USD':\n",
    "        pair = chfusd\n",
    "    elif name == 'GBP/USD':\n",
    "        pair = gbpusd\n",
    "    elif name == 'JPY/USD':\n",
    "        pair = jpyusd\n",
    "        \n",
    "    return(pair)\n",
    "\n",
    "def transform(df):\n",
    "    df['Open'] = 1 / df['Open']\n",
    "    df['High'] = 1 / df['High']\n",
    "    df['Low'] = 1 / df['Low']\n",
    "    df['Close'] = 1 / df['Close']\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification des longueur de bases ( 225648 ) :\n",
      "\u001b[32m ========================= > VALIDE \u001b[0m\n",
      "\n",
      "EUR/USD : \n",
      "Début :  28.02.2017 00:00:00.000 GMT+0100\n",
      "Fin :  28.02.2020 11:55:00.000 GMT+0100\n",
      "Shape :  (225648, 6)\n",
      "\n",
      "AUD/USD : \n",
      "Début :  28.02.2017 00:00:00.000 GMT+0100\n",
      "Fin :  28.02.2020 11:55:00.000 GMT+0100\n",
      "Shape :  (225648, 6)\n",
      "\n",
      "CHF/USD : \n",
      "Début :  28.02.2017 00:00:00.000 GMT+0100\n",
      "Fin :  28.02.2020 11:55:00.000 GMT+0100\n",
      "Shape :  (225648, 6)\n",
      "\n",
      "GBP/USD : \n",
      "Début :  28.02.2017 00:00:00.000 GMT+0100\n",
      "Fin :  28.02.2020 11:55:00.000 GMT+0100\n",
      "Shape :  (225648, 6)\n",
      "\n",
      "JPY/USD : \n",
      "Début :  28.02.2017 00:00:00.000 GMT+0100\n",
      "Fin :  28.02.2020 11:55:00.000 GMT+0100\n",
      "Shape :  (225648, 6)\n",
      "\n",
      "Première date :  28.02.2017 00:00:00.000 GMT+0100 ['Local time']\n",
      "\n",
      "Dernière date :  28.02.2020 11:55:00.000 GMT+0100 ['Local time'] \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrez la valeur du début (JJ.MM.AAAA HH:MM:SS) :  28.02.2019 00:00:00\n",
      "Entrez la valeur du split (JJ.MM.AAAA HH:MM:SS) :  06.03.2019 11:30:00\n",
      "Entrez la valeur de la fin (JJ.MM.AAAA HH:MM:SS) :  07.03.2019 13:30:00\n"
     ]
    }
   ],
   "source": [
    "base_eurusd = pd.read_csv('EURUSD.csv')\n",
    "\n",
    "try:\n",
    "    base_eurusd = base_eurusd.drop(['Unnamed: 0'],axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "base_audusd = pd.read_csv('AUDUSD.csv')\n",
    "\n",
    "try:\n",
    "    base_audusd = base_audusd.drop(['Unnamed: 0'],axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "base_chfusd = pd.read_csv('USDCHF.csv')\n",
    "base_chfusd = transform(base_chfusd)\n",
    "try:\n",
    "    base_chfusd = base_chfusd.drop(['Unnamed: 0'],axis=1)\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "base_gbpusd = pd.read_csv('GBPUSD.csv')\n",
    "\n",
    "try:\n",
    "    base_gbpusd = base_gbpusd.drop(['Unnamed: 0'],axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "base_jpyusd = pd.read_csv('USDJPY.csv')\n",
    "base_jpyusd = transform(base_jpyusd)\n",
    "\n",
    "try:\n",
    "    base_jpyusd = base_jpyusd.drop(['Unnamed: 0'],axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "print('Vérification des longueur de bases (',base_eurusd.shape[0],') :')\n",
    "\n",
    "if base_eurusd.shape[0] != base_audusd.shape[0] or base_eurusd.shape[0] != base_chfusd.shape[0] \\\n",
    "or base_eurusd.shape[0] != base_gbpusd.shape[0] or base_eurusd.shape[0] != base_jpyusd.shape[0] :\n",
    "    print(Fore.RED,'=================== > NON VALIDE',Style.RESET_ALL)\n",
    "\n",
    "else:\n",
    "    print(Fore.GREEN,'========================= > VALIDE',Style.RESET_ALL)\n",
    "    \n",
    "print('\\nEUR/USD : ')\n",
    "print('Début : ',base_eurusd.iloc[0]['Local time'])\n",
    "print('Fin : ',base_eurusd.iloc[-1]['Local time'])\n",
    "print('Shape : ',base_eurusd.shape)\n",
    "\n",
    "print('\\nAUD/USD : ')\n",
    "print('Début : ',base_audusd.iloc[0]['Local time'])\n",
    "print('Fin : ',base_audusd.iloc[-1]['Local time'])\n",
    "print('Shape : ',base_audusd.shape)\n",
    "\n",
    "print('\\nCHF/USD : ')\n",
    "print('Début : ',base_chfusd.iloc[0]['Local time'])\n",
    "print('Fin : ',base_chfusd.iloc[-1]['Local time'])\n",
    "print('Shape : ',base_chfusd.shape)\n",
    "\n",
    "print('\\nGBP/USD : ')\n",
    "print('Début : ',base_gbpusd.iloc[0]['Local time'])\n",
    "print('Fin : ',base_gbpusd.iloc[-1]['Local time'])\n",
    "print('Shape : ',base_gbpusd.shape)\n",
    "\n",
    "print('\\nJPY/USD : ')\n",
    "print('Début : ',base_jpyusd.iloc[0]['Local time'])\n",
    "print('Fin : ',base_jpyusd.iloc[-1]['Local time'])\n",
    "print('Shape : ',base_jpyusd.shape)\n",
    "\n",
    "\n",
    "debut = base_eurusd.iloc[0]['Local time']\n",
    "fin = base_eurusd.iloc[-1]['Local time']\n",
    "\n",
    "print('\\nPremière date : ',debut,['Local time'])\n",
    "print('\\nDernière date : ',fin,['Local time'],'\\n')\n",
    "\n",
    "début = input('Entrez la valeur du début (JJ.MM.AAAA HH:MM:SS) : ')\n",
    "split = input('Entrez la valeur du split (JJ.MM.AAAA HH:MM:SS) : ')\n",
    "fin = input('Entrez la valeur de la fin (JJ.MM.AAAA HH:MM:SS) : ')\n",
    "\n",
    "eurusd = base_eurusd[(base_eurusd['Local time'] >= debut)&(base_eurusd['Local time'] < split)]\n",
    "audusd = base_audusd[(base_audusd['Local time'] >= debut)&(base_audusd['Local time'] < split)]\n",
    "chfusd = base_chfusd[(base_chfusd['Local time'] >= debut)&(base_chfusd['Local time'] < split)]\n",
    "gbpusd = base_gbpusd[(base_gbpusd['Local time'] >= debut)&(base_gbpusd['Local time'] < split)]\n",
    "jpyusd = base_jpyusd[(base_jpyusd['Local time'] >= debut)&(base_jpyusd['Local time'] < split)]\n",
    "\n",
    "bt_eurusd = base_eurusd[(base_eurusd['Local time'] >= split)&(base_eurusd['Local time'] <= fin)]\n",
    "bt_audusd = base_audusd[(base_audusd['Local time'] >= split)&(base_audusd['Local time'] <= fin)]\n",
    "bt_chfusd = base_chfusd[(base_chfusd['Local time'] >= split)&(base_chfusd['Local time'] <= fin)]\n",
    "bt_gbpusd = base_gbpusd[(base_gbpusd['Local time'] >= split)&(base_gbpusd['Local time'] <= fin)]\n",
    "bt_jpyusd = base_jpyusd[(base_jpyusd['Local time'] >= split)&(base_jpyusd['Local time'] <= fin)]\n",
    "\n",
    "PAIR = [base_eurusd,base_audusd,base_chfusd,base_gbpusd,base_jpyusd]\n",
    "bt_PAIR = [bt_eurusd,bt_audusd,bt_chfusd,bt_gbpusd,bt_jpyusd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                              Local time     Open     High      Low    Close  \\\n",
       " 0       28.02.2017 00:00:00.000 GMT+0100  1.05872  1.05875  1.05853  1.05853   \n",
       " 1       28.02.2017 00:05:00.000 GMT+0100  1.05853  1.05870  1.05850  1.05864   \n",
       " 2       28.02.2017 00:10:00.000 GMT+0100  1.05865  1.05872  1.05862  1.05867   \n",
       " 3       28.02.2017 00:15:00.000 GMT+0100  1.05867  1.05867  1.05853  1.05863   \n",
       " 4       28.02.2017 00:20:00.000 GMT+0100  1.05862  1.05864  1.05841  1.05843   \n",
       " ...                                  ...      ...      ...      ...      ...   \n",
       " 225643  28.02.2020 11:35:00.000 GMT+0100  1.10308  1.10343  1.10292  1.10298   \n",
       " 225644  28.02.2020 11:40:00.000 GMT+0100  1.10298  1.10315  1.10288  1.10300   \n",
       " 225645  28.02.2020 11:45:00.000 GMT+0100  1.10301  1.10372  1.10298  1.10372   \n",
       " 225646  28.02.2020 11:50:00.000 GMT+0100  1.10374  1.10393  1.10358  1.10381   \n",
       " 225647  28.02.2020 11:55:00.000 GMT+0100  1.10380  1.10417  1.10334  1.10340   \n",
       " \n",
       "             Volume  \n",
       " 0       274.230000  \n",
       " 1       239.860000  \n",
       " 2       166.080000  \n",
       " 3       159.670000  \n",
       " 4       176.650000  \n",
       " ...            ...  \n",
       " 225643    0.001117  \n",
       " 225644    0.000994  \n",
       " 225645    0.000957  \n",
       " 225646    0.001033  \n",
       " 225647    0.001076  \n",
       " \n",
       " [225648 rows x 6 columns],\n",
       "                               Local time     Open     High      Low    Close  \\\n",
       " 0       28.02.2017 00:00:00.000 GMT+0100  0.76743  0.76760  0.76743  0.76759   \n",
       " 1       28.02.2017 00:05:00.000 GMT+0100  0.76758  0.76769  0.76758  0.76769   \n",
       " 2       28.02.2017 00:10:00.000 GMT+0100  0.76769  0.76787  0.76768  0.76784   \n",
       " 3       28.02.2017 00:15:00.000 GMT+0100  0.76784  0.76789  0.76754  0.76769   \n",
       " 4       28.02.2017 00:20:00.000 GMT+0100  0.76769  0.76781  0.76741  0.76743   \n",
       " ...                                  ...      ...      ...      ...      ...   \n",
       " 225643  28.02.2020 11:35:00.000 GMT+0100  0.65256  0.65296  0.65256  0.65275   \n",
       " 225644  28.02.2020 11:40:00.000 GMT+0100  0.65274  0.65275  0.65216  0.65222   \n",
       " 225645  28.02.2020 11:45:00.000 GMT+0100  0.65220  0.65229  0.65164  0.65170   \n",
       " 225646  28.02.2020 11:50:00.000 GMT+0100  0.65172  0.65180  0.65122  0.65132   \n",
       " 225647  28.02.2020 11:55:00.000 GMT+0100  0.65133  0.65146  0.65105  0.65119   \n",
       " \n",
       "             Volume  \n",
       " 0       150.070000  \n",
       " 1        91.870000  \n",
       " 2       174.440000  \n",
       " 3       160.840000  \n",
       " 4       211.160000  \n",
       " ...            ...  \n",
       " 225643    0.000402  \n",
       " 225644    0.000769  \n",
       " 225645    0.000597  \n",
       " 225646    0.000580  \n",
       " 225647    0.000662  \n",
       " \n",
       " [225648 rows x 6 columns],\n",
       "                               Local time      Open      High       Low  \\\n",
       " 0       28.02.2017 00:00:00.000 GMT+0100  0.991002  0.990796  0.991090   \n",
       " 1       28.02.2017 00:05:00.000 GMT+0100  0.990864  0.990835  0.990864   \n",
       " 2       28.02.2017 00:10:00.000 GMT+0100  0.990864  0.990845  0.990992   \n",
       " 3       28.02.2017 00:15:00.000 GMT+0100  0.990972  0.990884  0.990972   \n",
       " 4       28.02.2017 00:20:00.000 GMT+0100  0.990953  0.990796  0.990962   \n",
       " ...                                  ...       ...       ...       ...   \n",
       " 225643  28.02.2020 11:35:00.000 GMT+0100  1.037054  1.036667  1.037226   \n",
       " 225644  28.02.2020 11:40:00.000 GMT+0100  1.036667  1.036667  1.037011   \n",
       " 225645  28.02.2020 11:45:00.000 GMT+0100  1.036914  1.036785  1.037797   \n",
       " 225646  28.02.2020 11:50:00.000 GMT+0100  1.037786  1.037506  1.037861   \n",
       " 225647  28.02.2020 11:55:00.000 GMT+0100  1.037689  1.037549  1.037893   \n",
       " \n",
       "            Close      Volume  \n",
       " 0       0.990864  125.430000  \n",
       " 1       0.990845   38.370000  \n",
       " 2       0.990972   62.680000  \n",
       " 3       0.990943   47.020000  \n",
       " 4       0.990796   70.290000  \n",
       " ...          ...         ...  \n",
       " 225643  1.036667    0.000560  \n",
       " 225644  1.036925    0.000469  \n",
       " 225645  1.037764    0.000484  \n",
       " 225646  1.037689    0.000472  \n",
       " 225647  1.037549    0.000680  \n",
       " \n",
       " [225648 rows x 6 columns],\n",
       "                               Local time     Open     High      Low    Close  \\\n",
       " 0       28.02.2017 00:00:00.000 GMT+0100  1.24399  1.24413  1.24396  1.24401   \n",
       " 1       28.02.2017 00:05:00.000 GMT+0100  1.24403  1.24405  1.24374  1.24380   \n",
       " 2       28.02.2017 00:10:00.000 GMT+0100  1.24381  1.24420  1.24380  1.24411   \n",
       " 3       28.02.2017 00:15:00.000 GMT+0100  1.24409  1.24413  1.24381  1.24386   \n",
       " 4       28.02.2017 00:20:00.000 GMT+0100  1.24390  1.24390  1.24344  1.24349   \n",
       " ...                                  ...      ...      ...      ...      ...   \n",
       " 225643  28.02.2020 11:35:00.000 GMT+0100  1.28913  1.28979  1.28908  1.28957   \n",
       " 225644  28.02.2020 11:40:00.000 GMT+0100  1.28957  1.28969  1.28867  1.28875   \n",
       " 225645  28.02.2020 11:45:00.000 GMT+0100  1.28876  1.28944  1.28876  1.28925   \n",
       " 225646  28.02.2020 11:50:00.000 GMT+0100  1.28924  1.28941  1.28865  1.28866   \n",
       " 225647  28.02.2020 11:55:00.000 GMT+0100  1.28866  1.28909  1.28821  1.28827   \n",
       " \n",
       "             Volume  \n",
       " 0       200.080000  \n",
       " 1       134.050000  \n",
       " 2       155.450000  \n",
       " 3       247.190000  \n",
       " 4       182.310000  \n",
       " ...            ...  \n",
       " 225643    0.000912  \n",
       " 225644    0.000927  \n",
       " 225645    0.000904  \n",
       " 225646    0.000876  \n",
       " 225647    0.001031  \n",
       " \n",
       " [225648 rows x 6 columns],\n",
       "                               Local time      Open      High       Low  \\\n",
       " 0       28.02.2017 00:00:00.000 GMT+0100  0.008870  0.008869  0.008872   \n",
       " 1       28.02.2017 00:05:00.000 GMT+0100  0.008869  0.008869  0.008870   \n",
       " 2       28.02.2017 00:10:00.000 GMT+0100  0.008869  0.008869  0.008874   \n",
       " 3       28.02.2017 00:15:00.000 GMT+0100  0.008873  0.008871  0.008874   \n",
       " 4       28.02.2017 00:20:00.000 GMT+0100  0.008873  0.008871  0.008874   \n",
       " ...                                  ...       ...       ...       ...   \n",
       " 225643  28.02.2020 11:35:00.000 GMT+0100  0.009197  0.009195  0.009198   \n",
       " 225644  28.02.2020 11:40:00.000 GMT+0100  0.009195  0.009195  0.009198   \n",
       " 225645  28.02.2020 11:45:00.000 GMT+0100  0.009198  0.009197  0.009201   \n",
       " 225646  28.02.2020 11:50:00.000 GMT+0100  0.009201  0.009199  0.009201   \n",
       " 225647  28.02.2020 11:55:00.000 GMT+0100  0.009201  0.009200  0.009205   \n",
       " \n",
       "            Close      Volume  \n",
       " 0       0.008869  245.860000  \n",
       " 1       0.008869  269.770000  \n",
       " 2       0.008873  396.290000  \n",
       " 3       0.008873  236.610000  \n",
       " 4       0.008872  315.910000  \n",
       " ...          ...         ...  \n",
       " 225643  0.009195    0.001306  \n",
       " 225644  0.009198    0.001362  \n",
       " 225645  0.009201    0.001162  \n",
       " 225646  0.009200    0.001224  \n",
       " 225647  0.009205    0.001400  \n",
       " \n",
       " [225648 rows x 6 columns]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-83efd0535897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPAIR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#plt.figure(figsize=(16,4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-34f3cc7d98a8>\u001b[0m in \u001b[0;36misname\u001b[0;34m(pair)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'JPY/USD'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrevname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1584x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(22,6))\n",
    "\n",
    "for pair in PAIR:\n",
    "    name = isname(pair)\n",
    "\n",
    "    #plt.figure(figsize=(16,4))\n",
    "    plt.ylim(-3, 3)\n",
    "    plt.title(label='Comparaison des closes standardisés')\n",
    "    plt.plot(preprocessing.scale(pair['Close']),label='Close de la paire '+name,)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,6))\n",
    "\n",
    "for pair in PAIR:\n",
    "    name = isname(pair)\n",
    "\n",
    "    #plt.figure(figsize=(16,4))\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.title(label='Comparaison des diff des closes standardisés')\n",
    "    plt.plot(preprocessing.scale(pair['Close'].diff()),label='Close.diff() de la paire '+name,)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in PAIR:\n",
    "    \n",
    "    name = isname(pair)\n",
    "    \n",
    "    model = sm.OLS(pair['Close'],pair.index)\n",
    "    results = model.fit()\n",
    "    residuals = results.resid\n",
    "    summary = results.summary()\n",
    "\n",
    "    jb,p_value,skew,kurtosis,durbinwatson = ols(model,results, residuals)\n",
    "    \n",
    "    print(Fore.YELLOW,'POUR LA PAIRE '+name,Style.RESET_ALL)\n",
    "    jarque_berra(pair)\n",
    "    skewness(pair)\n",
    "    kurtos(pair)\n",
    "    autocor(pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import lag_plot\n",
    "\n",
    "for pair in PAIR:\n",
    "    name = isname(pair)\n",
    "    plt.rcParams.update({'ytick.left' : False, 'axes.titlepad':10})\n",
    "\n",
    "    ss = pair[['Local time','Close']]\n",
    "    #ss = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/sunspotarea.csv')\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(14,4), sharex=True, sharey=True, dpi=100)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        lag_plot(ss.Close, lag=i+1, ax=ax, c='firebrick')\n",
    "        ax.set_title('Lag ' + str(i+1))\n",
    "\n",
    "    fig.suptitle('Lag Plots of '+name+' Closes \\n(Points get wide and scattered with increasing lag -> lesser correlation)\\n', y=1.15)    \n",
    "\n",
    "\n",
    "    fig.suptitle('Lag Plots of '+name, y=1.05)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in PAIR:\n",
    "    name = isname(pair)\n",
    "    diff = pair.Close.diff()\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(diff,label='First Difference Close')\n",
    "    plt.title(label='First Difference Plot for '+name)\n",
    "    plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in PAIR:\n",
    "    name = isname(pair)\n",
    "    diff = pair.Close.diff()\n",
    "    plt.figure(figsize=(16,4))\n",
    "\n",
    "    pd.plotting.autocorrelation_plot(diff[1:])\n",
    "    plt.title(label='Autocorrelation Plot for '+name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for pair in PAIR:\n",
    "    name = isname(pair)\n",
    "    timeseries = pair['Close']\n",
    "    timeseries.index = pair['Local time']\n",
    "    test_stationarity(timeseries)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for pair in PAIR:\n",
    "    name = isname(pair)\n",
    "    df[name] = list(pair['Close'])\n",
    "df.corr().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTEGRE = []\n",
    "for col in range(1,len(df.corr())):\n",
    "    for ind in range(col):\n",
    "        if df.corr().iloc[ind,col] > 0.5 and df.corr().iloc[ind,col] != 1:\n",
    "            INTEGRE.append((df.corr().index[ind],df.corr().columns[col]))\n",
    "        \n",
    "INTEGRE  = list(set(INTEGRE))\n",
    "print('Les paires ',INTEGRE,' sont correlées et permettent un factorisation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "kmo_all,kmo_model=calculate_kmo(df)\n",
    "print('Le KMO du modèle est de :',kmo_model)\n",
    "for loop,pair in enumerate(PAIR):\n",
    "    name = isname(pair)\n",
    "    if kmo_all[loop] >= 0.6:\n",
    "        print(Fore.GREEN,name,Style.RESET_ALL,' a un kmo considéré comme ',Fore.GREEN,'adéquet',Style.RESET_ALL)\n",
    "    else:\n",
    "        print(Fore.RED,name,Style.RESET_ALL,' a un kmo donsidéré comme ',Fore.RED,'inadéquat',Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(df)\n",
    "print('Dans le test de Barlett, on ibserve un chi2 à ',chi_square_value,' et une p_value à', p_value)\n",
    "if p_value < 0.05:\n",
    "    print(Fore.GREEN,'Statistically significant',Style.RESET_ALL,\" ce qui signifie que la matrice de correlation observée n'est pas une identity matrix\" )\n",
    "else:\n",
    "    print(Fore.RED,'Statistically non significant',Style.RESET_ALL,\" ce qui signifie que la matrice de correlation observée peut être une identity matrix\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "fa = FactorAnalyzer(rotation=None)\n",
    "fa.fit(df)\n",
    "print(fa.loadings_)\n",
    "#fa.analyze(df, 25, rotation=None)\n",
    "# Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scree plot using matplotlib\n",
    "plt.scatter(range(1,df.shape[1]+1),ev)\n",
    "plt.plot(range(1,df.shape[1]+1),ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINCIPAL_COMPOSANT = []\n",
    "for loop,pair in enumerate(PAIR):\n",
    "    name = isname(pair)\n",
    "    print('\\r\\n'+name+' : ',ev[loop],\" ===> \",end='')\n",
    "    if ev[loop] >= 1:\n",
    "        print('On garde le facteur car >1')\n",
    "        PRINCIPAL_COMPOSANT.append((name,ev[loop]))\n",
    "    else:\n",
    "        print('On retire le facteur car <1')\n",
    "\n",
    "print('\\nRésumé des composants principaux gardés :')        \n",
    "PRINCIPAL_COMPOSANT        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca = pca.transform(df)\n",
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,6))\n",
    "plt.scatter( x_pca[:,0],x_pca[:,1],c=df['EUR/USD'],cmap='rainbow')\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second Principal Component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loop,pair in enumerate(PAIR):\n",
    "    name = isname(pair)\n",
    "    print(name,' : ',pca.components_[0][loop],' - ',pca.components_[1][loop])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen as johasen\n",
    "jh_results = johasen(df,0,1)\n",
    "print('\\nTrace Statistisque \\n',jh_results.lr1)                           # dim = (n,) Trace statistic\n",
    "print('\\n\\nCritical Value \\n',jh_results.cvt)                           # dim = (n,3) critical value table (90%, 95%, 99%)\n",
    "print('\\n\\nEigein Velue ec \\n',jh_results.evec)                          # dim = (n, n), columnwise eigen-vectors\n",
    "v1 = jh_results.evec[:, 0]\n",
    "v2 = jh_results.evec[:, 1]\n",
    "print('\\n\\nProbabilité de Eigein \\n',jh_results.eig)\n",
    "if jh_results.eig[0] <= 0.05:\n",
    "    print('\\nTest de cointiégration de Johasen ',Fore.GREEN,'VALIDE!',Style.RESET_ALL)\n",
    "else:\n",
    "    print('\\nTest de cointiégration de Johasen',Fore.RED,'INVALIDE!',Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "reg = LinearRegression().fit(X, y)\n",
    "score = reg.score(X, y) *100\n",
    "coef = reg.coef_\n",
    "cste = reg.intercept_\n",
    "\n",
    "if score > 70:\n",
    "    print('Test ',Fore.GREEN,'VALIDE',Style.RESET_ALL,' avec un score de ',Fore.GREEN,score,Style.RESET_ALL,' %')\n",
    "    print(\"Les poids respectifs sont de :\")\n",
    "    loop = -1\n",
    "    for pair in PAIR:\n",
    "        name = isname(pair)\n",
    "        if name == 'EUR/USD':\n",
    "            continue\n",
    "        loop += 1\n",
    "        print(name,' : ',coef[loop])\n",
    "    print('Et la constante est : ',cste)\n",
    "\n",
    "elif score > 50:\n",
    "    print('Test ',Fore.YELLOW,'MITIGE',Style.RESET_ALL,' avec un score de ',Fore.YELLOW,score,Style.RESET_ALL,' %')\n",
    "    print(\"Les poids respectifs sont de :\")\n",
    "    loop = 0\n",
    "    for pair in PAIR:\n",
    "        name = isname(pair)\n",
    "        if name == 'EUR/USD':\n",
    "            continue\n",
    "        loop += 1\n",
    "        print(name,' : ',coef[loop])\n",
    "    print('Et la constante est : ',cste)\n",
    "\n",
    "else:\n",
    "    print('Test ',Fore.RED,'NON VALIDE',Style.RESET_ALL,' avec un score de ',Fore.YELLOW,score,Style.RESET_ALL,' %')\n",
    "    print(\"Les poids respectifs sont de :\")\n",
    "    loop = 0\n",
    "    for pair in PAIR:\n",
    "        name = isname(pair)\n",
    "        if name == 'EUR/USD':\n",
    "            continue\n",
    "        loop += 1\n",
    "        print(name,' : ',coef[loop])\n",
    "    print('Et la constante est : ',cste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = cste + coef[0] * df['AUD/USD'] + coef[1] * df['CHF/USD'] + coef[2] * df['GBP/USD'] + coef[3] * df['JPY/USD']\n",
    "plt.figure(figsize=(22,5))\n",
    "plt.plot(df['EUR/USD'],label = 'EUR/USD',c='dodgerblue')\n",
    "plt.plot(combo,label = 'Combo',c='darkorange')\n",
    "plt.title('Comparaison de la paire de Référence et du composite')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "### RESIDUS\n",
    "########\n",
    "residu = df['EUR/USD']-combo\n",
    "S = (residu - residu.mean())/residu.std()\n",
    "plt.figure(figsize=(22,5))\n",
    "plt.plot(residu,label = 'Résidu')\n",
    "plt.title('Plot de la différence entre la paire de Référence et le composite : Résidu')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "## ANALYSE DES RESIDUS\n",
    "###\n",
    "\n",
    "jarque_berra(residu)\n",
    "skewness(residu)\n",
    "kurtos(residu)\n",
    "residu_autocor = pd.DataFrame()\n",
    "residu_autocor['Close'] = residu.iloc[:]\n",
    "autocor(residu_autocor)\n",
    "print(\"La moyenne des résidus est de \",residu.mean(),\", et leur ecart-type vaut \",residu.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(residu,residu.index)\n",
    "results = model.fit()\n",
    "residuals = results.resid\n",
    "summary = results.summary()\n",
    "name = 'Analyse des Résidus'\n",
    "jb,p_value,skew,kurtosis,durbinwatson = ols(model,results, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp['Close'] = residu.iloc[:]\n",
    "autocor(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoutput =  test_stationarity(residu,lag = 1)\n",
    "if dfoutput[1] < 0.05 and dfoutput[0] < dfoutput[6]:\n",
    "    print('Le test est ',Fore.GREEN,'VALIDE',Style.RESET_ALL,'et le résidu est : ',Fore.GREEN,'STATIONNAIRE',Style.RESET_ALL)\n",
    "else:\n",
    "    print('Le test est ',Fore.RED,'NON VALIDE',Style.RESET_ALL,'et le résidu  : ',Fore.RED,'NON STATIONNAIRE',Style.RESET_ALL)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "### RETOUR A LA MOYENNE\n",
    "#######\n",
    "dfoutput =  test_stationarity(residu,lag = 0)\n",
    "if dfoutput[1] < 0.05 and dfoutput[0] < dfoutput[6]:\n",
    "    print('Le test est ',Fore.GREEN,'VALIDE',Style.RESET_ALL,'et il y a : ',Fore.GREEN,'RETOUR A LA MOYENNE',Style.RESET_ALL)\n",
    "else:\n",
    "    print('Le test est ',Fore.RED,'NON VALIDE',Style.RESET_ALL,\"et il n'y a \",Fore.RED,'PAS RETOUR A LA MOYENNE',Style.RESET_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,5))\n",
    "plt.plot(S,label='Score')\n",
    "plt.axhline(y=0,c='crimson',alpha=0.4,linestyle='-.',label='Zéro')\n",
    "plt.axhline(y=1,c='orange',alpha=0.8,linestyle='--',label='Open Short')\n",
    "plt.axhline(y=0.5,c='orange',alpha=0.8,label ='Close Short')\n",
    "plt.axhline(y=-1,c='darkgreen',alpha=0.8,linestyle='--', label='Open Long')\n",
    "plt.axhline(y=-0.5,c='darkgreen',alpha=0.8,label='Close Long')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "### BT\n",
    "#######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_df = pd.DataFrame()\n",
    "for bt_pair in bt_PAIR:\n",
    "    \n",
    "    if bt_pair.equals(bt_eurusd):\n",
    "        name = 'EUR/USD'\n",
    "    elif bt_pair.equals(bt_audusd):\n",
    "        name = 'AUD/USD'\n",
    "    elif bt_pair.equals(bt_chfusd):\n",
    "        name = 'CHF/USD'\n",
    "    elif bt_pair.equals(bt_gbpusd):\n",
    "        name = 'GBP/USD'\n",
    "    elif bt_pair.equals(bt_jpyusd):\n",
    "        name = 'JPY/USD'\n",
    "    \n",
    "    \n",
    "    bt_df[name] = list(bt_pair['Close'])\n",
    "df.corr().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_combo = cste + coef[0] * bt_df['AUD/USD'] + coef[1] * bt_df['CHF/USD'] + coef[2] * bt_df['GBP/USD'] + coef[3] * bt_df['JPY/USD']\n",
    "bt_residu = bt_df['EUR/USD']-bt_combo\n",
    "bt_S = (bt_residu - bt_residu.mean())/bt_residu.std()\n",
    "plt.figure(figsize=(22,5))\n",
    "plt.plot(bt_residu,label = 'Résidu')\n",
    "plt.title('Plot de la différence entre la paire de Référence et le composite : Résidu')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jarque_berra(bt_residu)\n",
    "skewness(bt_residu)\n",
    "kurtos(bt_residu)\n",
    "bt_residu_autocor = pd.DataFrame()\n",
    "bt_residu_autocor['Close'] = bt_residu.iloc[:]\n",
    "autocor(bt_residu_autocor)\n",
    "print(\"La moyenne des résidus est de \",bt_residu.mean(),\", et leur ecart-type vaut \",bt_residu.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model = sm.OLS(bt_residu,bt_residu.index)\n",
    "bt_results = bt_model.fit()\n",
    "bt_residuals = bt_results.resid\n",
    "bt_summary = bt_results.summary()\n",
    "name = 'Analyse des Résidus'\n",
    "jb,p_value,skew,kurtosis,durbinwatson = ols(bt_model,bt_results, bt_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp['Close'] = bt_residu.iloc[:]\n",
    "autocor(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoutput =  test_stationarity(bt_residu,lag = 1)\n",
    "if dfoutput[1] < 0.05 and dfoutput[0] < dfoutput[6]:\n",
    "    print('Le test est ',Fore.GREEN,'VALIDE',Style.RESET_ALL,'et le résidu est : ',Fore.GREEN,'STATIONNAIRE',Style.RESET_ALL)\n",
    "else:\n",
    "    print('Le test est ',Fore.RED,'NON VALIDE',Style.RESET_ALL,'et le résidu  : ',Fore.RED,'NON STATIONNAIRE',Style.RESET_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "### RETOUR A LA MOYENNE\n",
    "#######\n",
    "dfoutput =  test_stationarity(bt_residu,lag = 0)\n",
    "if dfoutput[1] < 0.05 and dfoutput[0] < dfoutput[6]:\n",
    "    print('Le test est ',Fore.GREEN,'VALIDE',Style.RESET_ALL,'et il y a : ',Fore.GREEN,'RETOUR A LA MOYENNE',Style.RESET_ALL)\n",
    "else:\n",
    "    print('Le test est ',Fore.RED,'NON VALIDE',Style.RESET_ALL,\"et il n'y a \",Fore.RED,'PAS RETOUR A LA MOYENNE',Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,5))\n",
    "plt.plot(bt_S,label='Score')\n",
    "plt.axhline(y=0,c='crimson',alpha=0.4,linestyle='-.',label='Zéro')\n",
    "plt.axhline(y=1,c='orange',alpha=0.8,linestyle='--',label='Open Short')\n",
    "plt.axhline(y=0.5,c='orange',alpha=0.8,label ='Close Short')\n",
    "plt.axhline(y=-1,c='darkgreen',alpha=0.8,linestyle='--', label='Open Long')\n",
    "plt.axhline(y=-0.5,c='darkgreen',alpha=0.8,label='Close Long')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_df = pd.DataFrame()\n",
    "backtest_df = bt_df\n",
    "backtest_df.index = bt_pair['Local time']\n",
    "backtest_df['Spread'] = bt_residu.to_list()\n",
    "backtest_df['Signals'] = bt_S.to_list()\n",
    "backtest_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,5))\n",
    "_plot = plt.plot(bt_S,label = 'Score')\n",
    "os,cs,ol,cl = 0,0,0,0\n",
    "\n",
    "mise = 100000\n",
    "pactol = 100000\n",
    "profit_long = 0\n",
    "profit_short = 0\n",
    "profit = 0\n",
    "nbre_trade = 0\n",
    "nbre_trade_long = 0\n",
    "nbre_trade_short = 0\n",
    "pnls = 0\n",
    "pnll = 0\n",
    "\n",
    "for mark in range(0,len(backtest_df)):\n",
    "    if backtest_df.iloc[mark]['Signals'] > 1 and os == 0:\n",
    "        _os = scatter =  plt.scatter(x=mark,y=bt_S[mark],c='r',marker='o',label='Open Short')\n",
    "        os = 1\n",
    "        cs = 0\n",
    "        #pactol = pactol + mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        #pactol = pactol - mise * (coef[0] * backtest_df.iloc[mark]['AUD/USD'] + coef[1] * backtest_df.iloc[mark]['CHF/USD'] +\\\n",
    "                                 #coef[2] * backtest_df.iloc[mark]['GBP/USD'] + coef[3] * backtest_df.iloc[mark]['JPY/USD'])\n",
    "        eos = mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        auos = -  mise * coef[0] * backtest_df.iloc[mark]['AUD/USD']\n",
    "        chos = - mise * coef[1] * backtest_df.iloc[mark]['CHF/USD']\n",
    "        gbos = - mise * coef[2] * backtest_df.iloc[mark]['GBP/USD']\n",
    "        jpos = - mise * coef[3] * backtest_df.iloc[mark]['JPY/USD']\n",
    "        \n",
    "        \n",
    "        print('\\n\\nDate : ',backtest_df.index[mark])\n",
    "        print(Fore.GREEN,'ACTION OPEN SHORT',Style.RESET_ALL,\\\n",
    "              '- \\nclose EUR/USA ',backtest_df.iloc[mark]['EUR/USD'],'\\nclose AUD/USD : ',backtest_df.iloc[mark]['AUD/USD'],\\\n",
    "              '\\nClose CHF/USD : ',backtest_df.iloc[mark]['CHF/USD'],'\\nClose GBP/USD : ', backtest_df.iloc[mark]['GBP/USD'],\\\n",
    "             '\\nClose JPY/USD : ',backtest_df.iloc[mark]['JPY/USD'])  \n",
    "    \n",
    "    if backtest_df.iloc[mark]['Signals'] < 0.5 and os == 1:\n",
    "        _cs = scatter = plt.scatter(x=mark,y=bt_S[mark],c='r',marker='x',label='Close Short : ')\n",
    "        os = 0\n",
    "        cs = 1\n",
    "        #pactol = pactol - mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        #pactol = pactol + mise * (coef[0] * backtest_df.iloc[mark]['AUD/USD'] + coef[1] * backtest_df.iloc[mark]['CHF/USD'] +\\\n",
    "                                 #coef[2] * backtest_df.iloc[mark]['GBP/USD'] + coef[3] * backtest_df.iloc[mark]['JPY/USD'])\n",
    "        print('\\n\\nDate : ',backtest_df.index[mark])\n",
    "        print(Fore.RED,'ACTION CLOSE SHORT',Style.RESET_ALL,\\\n",
    "              '- \\nclose EUR/USA ',backtest_df.iloc[mark]['EUR/USD'],'\\nclose AUD/USD : ',backtest_df.iloc[mark]['AUD/USD'],\\\n",
    "              '\\nClose CHF/USD : ',backtest_df.iloc[mark]['CHF/USD'],'\\nClose GBP/USD : ', backtest_df.iloc[mark]['GBP/USD'],\\\n",
    "             '\\nClose JPY/USD : ',backtest_df.iloc[mark]['JPY/USD']) \n",
    "        \n",
    "        #e = e - mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        #au = au + mise * coef[0] * backtest_df.iloc[mark]['AUD/USD']\n",
    "        #ch = (ch +  mise * coef[1] * backtest_df.iloc[mark]['CHF/USD']) / backtest_df.iloc[mark]['CHF/USD']\n",
    "        #gb = gb + mise * coef[2] * backtest_df.iloc[mark]['GBP/USD']\n",
    "        #jp = (jp + mise * coef[3] * backtest_df.iloc[mark]['JPY/USD']) / backtest_df.iloc[mark]['JPY/USD']\n",
    "        \n",
    "        ecs = - mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        aucs = mise * coef[0] * backtest_df.iloc[mark]['AUD/USD']\n",
    "        chcs = mise * coef[1] * backtest_df.iloc[mark]['CHF/USD']\n",
    "        gbcs = mise * coef[2] * backtest_df.iloc[mark]['GBP/USD']\n",
    "        jpcs = mise * coef[3] * backtest_df.iloc[mark]['JPY/USD']\n",
    "        \n",
    "        pnles = eos + ecs\n",
    "        pnlaus = auos + aucs\n",
    "        pnlchs = (chos + chcs) \n",
    "        pnlgbs = gbos + gbcs\n",
    "        pnljps = (jpos + jpcs) \n",
    "        pnlcombos = pnlaus + pnlchs + pnlgbs + pnljps\n",
    "        pnls = pnles + pnlcombos\n",
    "        \n",
    "        nbre_trade += 1\n",
    "        nbre_trade_short +=1\n",
    "        \n",
    "        profit = profit + pnls\n",
    "        \n",
    "        print('pnl EUR/USd :',pnles,'\\npnl au :',pnlaus,'\\npnl ch :',pnlchs,'\\npnl gp',pnlgbs,'\\npnl jp :',pnljps,\\\n",
    "              '\\ntotal combo : ',pnlcombos,'\\npnl total :',pnls)\n",
    "        \n",
    "        \n",
    "    if backtest_df.iloc[mark]['Signals'] < -1 and ol == 0:\n",
    "        _ol = scatter = plt.scatter(x=mark,y=bt_S[mark],c='g',marker='o',label='Open Long')\n",
    "        ol = 1\n",
    "        os = 0\n",
    "        #pactol = pactol - mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        #pactol = pactol + mise * (coef[0] * backtest_df.iloc[mark]['AUD/USD'] + coef[1] * backtest_df.iloc[mark]['CHF/USD'] +\\\n",
    "        #                         coef[2] * backtest_df.iloc[mark]['GBP/USD'] + coef[3] * backtest_df.iloc[mark]['JPY/USD'])\n",
    "        print('\\n\\nDate : ',backtest_df.index[mark])\n",
    "        print(Fore.GREEN,'ACTION OPEN LONG',Style.RESET_ALL,\\\n",
    "              '- \\nclose EUR/USA ',backtest_df.iloc[mark]['EUR/USD'],'\\nclose AUD/USD : ',backtest_df.iloc[mark]['AUD/USD'],\\\n",
    "              '\\nClose CHF/USD : ',backtest_df.iloc[mark]['CHF/USD'],'\\nClose GBP/USD : ', backtest_df.iloc[mark]['GBP/USD'],\\\n",
    "             '\\nClose JPY/USD : ',backtest_df.iloc[mark]['JPY/USD'])\n",
    "        \n",
    "        eol = - mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        auol = mise * coef[0] * backtest_df.iloc[mark]['AUD/USD']\n",
    "        chol = mise * coef[1] * backtest_df.iloc[mark]['CHF/USD']\n",
    "        gbol = mise * coef[2] * backtest_df.iloc[mark]['GBP/USD']\n",
    "        jpol = mise * coef[3] * backtest_df.iloc[mark]['JPY/USD']\n",
    "        \n",
    "        \n",
    "        \n",
    "    if backtest_df.iloc[mark]['Signals'] > -0.5 and ol == 1 :\n",
    "        _cl = scatter = plt.scatter(x=mark,y=bt_S[mark],c='g',marker='x',label='Close Long')\n",
    "        ol = 0\n",
    "        cl = 1\n",
    "        #pactol = pactol + mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        #pactol = pactol - mise * (coef[0] * backtest_df.iloc[mark]['AUD/USD'] + coef[1] * backtest_df.iloc[mark]['CHF/USD'] +\\\n",
    "        #                         coef[2] * backtest_df.iloc[mark]['GBP/USD'] + coef[3] * backtest_df.iloc[mark]['JPY/USD'])\n",
    "        \n",
    "        print('\\n\\nDate : ',backtest_df.index[mark])\n",
    "        print(Fore.RED,'ACTION CLOSE LONG',Style.RESET_ALL,\\\n",
    "              '- \\nclose EUR/USA ',backtest_df.iloc[mark]['EUR/USD'],'\\nclose AUD/USD : ',backtest_df.iloc[mark]['AUD/USD'],\\\n",
    "              '\\nClose CHF/USD : ',backtest_df.iloc[mark]['CHF/USD'],' \\nClose GBP/USD : ', backtest_df.iloc[mark]['GBP/USD'],\\\n",
    "             '\\nClose JPY/USD : ',backtest_df.iloc[mark]['JPY/USD'])\n",
    "        \n",
    "        ecl = mise * backtest_df.iloc[mark]['EUR/USD']\n",
    "        aucl = -  mise * coef[0] * backtest_df.iloc[mark]['AUD/USD']\n",
    "        chcl = - mise * coef[1] * backtest_df.iloc[mark]['CHF/USD']\n",
    "        gbcl = - mise * coef[2] * backtest_df.iloc[mark]['GBP/USD']\n",
    "        jpcl = - mise * coef[3] * backtest_df.iloc[mark]['JPY/USD']\n",
    "        \n",
    "        pnlel = eol + ecl\n",
    "        pnlaul = auol + aucl\n",
    "        pnlchl = (chol + chcl) \n",
    "        pnlgbl = gbol + gbcl\n",
    "        pnljpl = (jpol + jpcl) \n",
    "        pnlcombol = pnlaul + pnlchl + pnlgbl + pnljpl\n",
    "        pnll = pnlel + pnlcombol\n",
    "        \n",
    "        nbre_trade += 1\n",
    "        nbre_trade_long +=1\n",
    "        \n",
    "        profit = profit + pnll\n",
    "        \n",
    "        print('pnl EUR/USd :',pnlel,'\\npnl au :',pnlaul,'\\npnl ch :',pnlchl,'\\npnl gp',pnlgbl,'\\npnl jp :',pnljpl,\\\n",
    "              '\\ntotal combo : ',pnlcombol,'\\npnl total :',pnll)\n",
    "        \n",
    "        print('\\n\\nProfit en Long :',pnll)\n",
    "        print('Profit en Short : ',pnls)\n",
    "\n",
    "\n",
    "    \n",
    "plt.title('Plot Signaux Achat / Vente sur le Score')\n",
    "#plt.legend((_os,_cs,_ol,_cl),('Open Short','Close Short','Open Long','Close Long'),scatterpoints=1 )\n",
    "\n",
    "'''if ol == 1:\n",
    "    pactol = pactol - qty * backtest_df.iloc[mark]['EUR/USD']\n",
    "    pactol = pactol + qty * (coef[0] * backtest_df.iloc[mark]['AUD/USD'] + coef[1] * backtest_df.iloc[mark]['CHF/USD'] +\\\n",
    "                             coef[2] * backtest_df.iloc[mark]['GBP/USD'] + coef[3] * backtest_df.iloc[mark]['JPY/USD']) \n",
    "    \n",
    "if os == 1:\n",
    "    pactol = pactol + qty * backtest_df.iloc[mark]['EUR/USD']\n",
    "    pactol = pactol - qty * (coef[0] * backtest_df.iloc[mark]['AUD/USD'] + coef[1] * backtest_df.iloc[mark]['CHF/USD'] +\\\n",
    "                             coef[2] * backtest_df.iloc[mark]['GBP/USD'] + coef[3] * backtest_df.iloc[mark]['JPY/USD'])'''\n",
    "    \n",
    "print(Fore.YELLOW,'------------------------------------------------------------------------')\n",
    "print(' --------------------------------RESULTATS--------------------------------')\n",
    "print(' ------------------------------------------------------------------------',Style.RESET_ALL)\n",
    "if profit < 0:\n",
    "    print('Le profit généré en $',Fore.RED,round(profit,2),Style.RESET_ALL)\n",
    "    \n",
    "\n",
    "if profit > 0:\n",
    "    print('Le profit généré en $',Fore.GREEN,round(profit,2),Style.RESET_ALL)\n",
    "\n",
    "print('Nombre de trades long : ',nbre_trade_long)\n",
    "print('Nombre de trades short : ',nbre_trade_short)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut, split, fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[0],coef[1],coef[2],coef[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('USDJPY.csv')\n",
    "a = a.iloc[:-12,:]\n",
    "try:\n",
    "    a = a.drop(['Unnamed: 0'],axis=1)\n",
    "except:\n",
    "    pass\n",
    "a.to_csv('USDJPY.csv')\n",
    "a.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('USDJPY.csv')\n",
    "\n",
    "a.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.iloc[:,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('FinTech': conda)",
   "language": "python",
   "name": "python37664bitfintechcondac76ab263fd6941b2a7e8b27983583628"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
