{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd07f9c69b77f8cb78a9d8b8acc2d09c3972908e6673afd8bfd04ee2f6acaaac495",
   "display_name": "Python 3.8.5 64-bit ('DataSciences': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "7f9c69b77f8cb78a9d8b8acc2d09c3972908e6673afd8bfd04ee2f6acaaac495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as data_reader\n",
    "import time\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from natsort import natsorted\n",
    "from collections import deque\n",
    "import joblib\n",
    "import colorama as col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'EUR/USD'\n",
    "_period = 'm5'\n",
    "_period2 = 'H1'\n",
    "_ticker = x.replace('/','')\n",
    "_start = '2010-01-01' # start the train there '2010-01-01'\n",
    "_mid = '2016-06-30' # stop the train and begin the test there '2016-08-31'\n",
    "_stop = '2017-12-31' # stop the test there. After that, it is kept for oos '2017-12-31'\n",
    "_last = '2021-04-29' # '2020-12-31'"
   ]
  },
  {
   "source": [
    "def sigmoid(x):\n",
    "  return 1 - (1 + math.exp(-x))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def stock_price_format(n):\n",
    "  if n < 0:\n",
    "    return \"- # {0:2f}\".format(abs(n))\n",
    "  else:\n",
    "    return \"$ {0:2f}\".format(abs(n))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_loader():\n",
    "\n",
    "    data = joblib.load('BASES/EURUSD_m5')\n",
    "\n",
    "    start_date = str(data.index[0]).split()[0]\n",
    "    end_date = str(data.index[1]).split()[0]\n",
    "\n",
    "    _sl = 0.001\n",
    "    _target = 0.002\n",
    "\n",
    "    # scaler = Normalizer()\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    # scaler = StandardScaler()\n",
    "\n",
    "    def strategy(df):\n",
    "        ##### CONDITIONS LONG\n",
    "        _condition_1 = (df.slow_K5 < 20) & (df.slow_K5.shift(1) < df.slow_D5.shift(1)) & (df.slow_K5 > df.slow_D5)\n",
    "\n",
    "        ##### CONDITIONS SHORT\n",
    "        _condition_1_bar = (df.slow_K5 > 80) & (df.slow_K5.shift(1) > df.slow_D5.shift(1)) & (df.slow_K5 < df.slow_D5)\n",
    "\n",
    "        ##### 1 condition\n",
    "        df['Signal'] = np.where(_condition_1,1,np.where(_condition_1_bar,-1,0))\n",
    "        df = df.drop(['Symbol','Date','DateIndex','SB_Gamma'], axis=1)\n",
    "        return(df.sort_index(axis=0)) \n",
    "\n",
    "    def strategy5(df,_window=40):\n",
    "\n",
    "        #df['RSI_2'] = TA.RSI(ohlc=df,int=2,str='Close')\n",
    "\n",
    "        df['Window_High_Ask'] = df.HighAsk.iloc[::-1].rolling(_window).max().iloc[::-1] # Limite SL Short\n",
    "        df['Window_High_Bid'] = df.HighBid.iloc[::-1].rolling(_window).max().iloc[::-1] # Limite Target Long\n",
    "        df['Window_Low_Ask'] = df.LowAsk.iloc[::-1].rolling(_window).min().iloc[::-1] # Limite Target Short\n",
    "        df['Window_Low_Bid'] = df.LowBid.iloc[::-1].rolling(_window).min().iloc[::-1] # Limite SL Long\n",
    "        df['Window_sl_Short'] = df.CloseBid + (df.CloseBid * _sl) # Short pour SL\n",
    "        df['Window_sl_Long'] = df.CloseAsk - (df.CloseAsk * _sl) # Long pour SL\n",
    "        df['Window_tp_Short'] = df.CloseBid - (df.CloseBid * _target) # Short pour TP\n",
    "        df['Window_tp_Long'] = df.CloseAsk + (df.CloseAsk * _target) # Long pour TP\n",
    "\n",
    "        ##### CONDITIONS LONG\n",
    "        _condition_1 = (df['Window_tp_Long'] <= df['Window_High_Bid']) & (df['Window_sl_Long'] <= df['Window_Low_Bid'])\n",
    "\n",
    "        ##### CONDITIONS SHORT\n",
    "        _condition_1_bar = (df['Window_tp_Short'] >= df['Window_Low_Ask']) & (df['Window_sl_Short'] >= df['Window_High_Ask'])\n",
    "\n",
    "        ##### 1 condition\n",
    "        df['Signal'] = np.where(_condition_1,1,np.where(_condition_1_bar,-1,0))\n",
    "        df = df.drop(['Symbol','Date','DateIndex','Window_High_Ask','Window_High_Bid','Window_Low_Ask','Window_Low_Bid','Window_sl_Short','Window_sl_Long','Window_tp_Short','Window_tp_Long'], axis=1)\n",
    "        return(df.sort_index(axis=0))\n",
    "\n",
    "\n",
    "    data = klines(data)\n",
    "\n",
    "    data = strategy(data)\n",
    "\n",
    "    data = data[['Body','Color','UpperShadow','LowerShadow','Signal']]\n",
    "\n",
    "    data['Body1'] = data['Body'] - data['Body'].shift(1)\n",
    "    data['Body2'] = data['Body'] - data['Body'].shift(2)\n",
    "    data['Body3'] = data['Body'] - data['Body'].shift(3)\n",
    "    data['Body4'] = data['Body'] - data['Body'].shift(4)\n",
    "    data['Body5'] = data['Body'] - data['Body'].shift(5)\n",
    "\n",
    "    data['UpperShadow1'] = data['UpperShadow'] - data['UpperShadow'].shift(1)\n",
    "    data['UpperShadow2'] = data['UpperShadow'] - data['UpperShadow'].shift(2)\n",
    "    data['UpperShadow3'] = data['UpperShadow'] - data['UpperShadow'].shift(3)\n",
    "    data['UpperShadow4'] = data['UpperShadow'] - data['UpperShadow'].shift(4)\n",
    "    data['UpperShadow5'] = data['UpperShadow'] - data['UpperShadow'].shift(5)\n",
    "\n",
    "    data['LowerShadow1'] = data['LowerShadow'] - data['LowerShadow'].shift(1)\n",
    "    data['LowerShadow2'] = data['LowerShadow'] - data['LowerShadow'].shift(2)\n",
    "    data['LowerShadow3'] = data['LowerShadow'] - data['LowerShadow'].shift(3)\n",
    "    data['LowerShadow4'] = data['LowerShadow'] - data['LowerShadow'].shift(4)\n",
    "    data['LowerShadow5'] = data['LowerShadow'] - data['LowerShadow'].shift(5)\n",
    "\n",
    "\n",
    "    df_train, df_test, df_oos = split_df(data)\n",
    "\n",
    "    df_oos_raw = df_oos.copy().dropna()\n",
    "\n",
    "    df_train.sort_index(inplace=True)\n",
    "    \n",
    "    for i in df_train.columns.unique():\n",
    "        if i != 'Signal' and i != 'Color':\n",
    "            df_train[i] = scaler.fit_transform(df_train[i].values.reshape(-1, 1))\n",
    "            df_test[i] = scaler.fit_transform(df_test[i].values.reshape(-1, 1))\n",
    "            df_oos[i] = scaler.fit_transform(df_oos[i].values.reshape(-1, 1))\n",
    "\n",
    "    df_train = df_train.dropna()\n",
    "    df_test = df_test.dropna()\n",
    "    df_oos = df_oos.dropna()\n",
    "\n",
    "    signal_train = df_train['Signal']\n",
    "    signal_test = df_test['Signal']\n",
    "    signal_oos = df_oos['Signal']\n",
    "\n",
    "    df_train = df_train.drop(['Signal'],axis=1)\n",
    "    df_test = df_test.drop(['Signal'],axis=1)\n",
    "    df_oos = df_oos.drop(['Signal'],axis=1)\n",
    "\n",
    "    df_oos = df_oos.reindex(natsorted(df_oos.columns), axis=1)\n",
    "    df_test = df_test.reindex(natsorted(df_test.columns), axis=1)\n",
    "    df_train = df_train.reindex(natsorted(df_train.columns), axis=1)\n",
    "    df_oos_raw = df_oos_raw.reindex(natsorted(df_oos_raw.columns), axis=1)\n",
    "\n",
    "    return df_train, df_test, df_oos, df_oos_raw, signal_train, signal_test, signal_oos"
   ]
  },
  {
   "source": [
    "def state_creator(data, timestep): #, window_size):\n",
    "\n",
    "  state = []\n",
    "  state.append(data.iloc[timestep,:])\n",
    "    \n",
    "  return np.array([state])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klines(df):\n",
    "    _condition1 = df.Close >= df.Open\n",
    "    df['Color'] = np.where(_condition1,1,-1)\n",
    "    _condition2 = df.Color = 1\n",
    "    df['UpperShadow'] = np.where(_condition2,(df.High-df.Close),(df.High-df.Open))\n",
    "    df['LowerShadow'] = np.where(_condition2,(df.Open-df.Low),(df.Close-df.Low))\n",
    "    df['Body'] = abs(df.Close-df.Open)\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    \"\"\"[Split the dtaframe in train/test/oos and reduce train and test to dataframe with signal!=0 only]\n",
    "\n",
    "    Args:\n",
    "        df ([pandas]): [the datframe to split already featured]\n",
    "        _start ([date]): [beginning of the df]\n",
    "        _mid ([date]): [stop of the train and beginning of the test]\n",
    "        _stop ([date]): [stop of the test and beginning of the oos]\n",
    "        _last ([date]): [end of the oos]\n",
    "    \"\"\"    \n",
    "    df = df.dropna()\n",
    "    df['Date'] = pd.to_datetime(df.index)\n",
    "    \n",
    "    df_train = df[(df.Date>=_start)&(df.Date<=_mid)]\n",
    "    df_test = df[(df.Date>_mid)&(df.Date<=_stop)]\n",
    "    df_oos = df[(df.Date>_stop)&(df.Date <= _last)]\n",
    "    df_train = df_train.drop(['Date'],axis=1)\n",
    "    df_test = df_test.drop(['Date'],axis=1)\n",
    "    df_oos = df_oos.drop(['Date'],axis=1)\n",
    "    return(df_train, df_test,df_oos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-0658ba4c6534>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = pd.to_datetime(df.index)\n",
      "CPU times: user 1.39 s, sys: 842 ms, total: 2.23 s\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train, df_test, df_oos, df_oos_raw, signal_train, signal_test, signal_oos = dataset_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "episodes = 1000\n",
    "state_size = df_train.shape[1]\n",
    "batch_size = 50000\n",
    "data_samples = 500 #len(df_train) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Trader():\n",
    "  \n",
    "    def __init__(self, state_size=state_size, action_space=3, model_name=\"AITrader\"):\n",
    "\n",
    "        self.state_size = state_size\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=5000)\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_final = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = self.model_builder()\n",
    "\n",
    "    def model_builder(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Input(df_train.shape[1]))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='relu')) # , input_dim=self.state_size))\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(units=3, activation='tanh'))\n",
    "        #model = tf.model({inputs: input, outputs: dense2})\n",
    "        model.output_shape\n",
    "        model.compile(optimizers.Adam(lr=0.001),loss='mse')\n",
    "        return model  \n",
    "\n",
    "    \n",
    "\n",
    "    def trade(self, state):\n",
    "        if random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_space)\n",
    "        \n",
    "        actions = self.model.predict(state)\n",
    "        return actions\n",
    "\n",
    "    def batch_train(self, batch_size):\n",
    "\n",
    "        batch = []\n",
    "        for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "            batch.append(self.memory[i])\n",
    "\n",
    "            for state, action, reward, next_state, done in batch:\n",
    "                reward = reward\n",
    "            \n",
    "            if not done:\n",
    "                reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "\n",
    "            target = self.model.predict(state)\n",
    "            target[0][action] = reward\n",
    "\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "        if self.epsilon > self.epsilon_final:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "        \n",
    "#return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                1280      \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 195       \n=================================================================\nTotal params: 18,051\nTrainable params: 18,051\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trader = AI_Trader(df_train,window_size,state_size)\n",
    "trader.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 93%|█████████▎| 465/500 [00:00<00:00, 4646.28it/s]Episode: 1/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1619.40it/s]\n",
      " 29%|██▉       | 146/500 [00:00<00:00, 1333.58it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -425 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 2/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1254.38it/s]\n",
      " 93%|█████████▎| 464/500 [00:00<00:00, 4626.35it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -433 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 3/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1619.38it/s]\n",
      " 93%|█████████▎| 467/500 [00:00<00:00, 4666.30it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -433 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 4/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1609.48it/s]\n",
      " 93%|█████████▎| 466/500 [00:00<00:00, 4657.15it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -430 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 5/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1618.14it/s]\n",
      " 81%|████████▏ | 407/500 [00:00<00:00, 2366.91it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -427 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 6/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1260.56it/s]\n",
      " 89%|████████▉ | 445/500 [00:00<00:00, 4448.53it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -443 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 7/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1597.76it/s]\n",
      " 88%|████████▊ | 438/500 [00:00<00:00, 4373.92it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -421 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 8/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1573.20it/s]\n",
      " 92%|█████████▏| 460/500 [00:00<00:00, 4585.51it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -420 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 9/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1599.23it/s]\n",
      " 89%|████████▉ | 445/500 [00:00<00:00, 4447.73it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -424 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 10/1000\n",
      "100%|██████████| 500/500 [00:00<00:00, 1599.51it/s]\n",
      " 32%|███▏      | 159/500 [00:00<00:00, 4342.35it/s]\n",
      "\u001b[36m########################\u001b[32m\n",
      "TOTAL PROFIT:  -437 \n",
      "\u001b[36m########################\u001b[0m\n",
      "\n",
      "Episode: 11/1000\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-903c3821cc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# next_state = state_creator(data, t+1, window_size + 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataSciences/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataSciences/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataSciences/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataSciences/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataSciences/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_positional_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataSciences/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   3809\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3810\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3811\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3813\u001b[0m         \u001b[0;31m# this could be a view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataSciences/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__finalize__\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   5430\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5432\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallows_duplicate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5433\u001b[0m             \u001b[0;31m# For subclasses using _metadata.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5434\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DataSciences/lib/python3.8/site-packages/pandas/core/flags.py\u001b[0m in \u001b[0;36mallows_duplicate_labels\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This flag's object has been deleted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(1, episodes + 1):\n",
    "  \n",
    "  print(\"Episode: {}/{}\".format(episode, episodes))\n",
    "  \n",
    "  # state = state_creator(df_train, 0)\n",
    "  \n",
    "  \n",
    "  total_profit = 0\n",
    "  trader.inventory = []\n",
    "  \n",
    "  for t in tqdm(range(data_samples)):\n",
    "    \n",
    "    state = df_train.iloc[t:t+1,:]\n",
    "    # next_state = state_creator(data, t+1, window_size + 1)\n",
    "    next_state = df_train.iloc[t+1:t+2,:]\n",
    "    action = trader.trade(state)\n",
    "    reward = 0\n",
    "    \n",
    "    if action == 1 and signal_train[t] == 1: #Buying\n",
    "      reward = 1\n",
    "      total_profit += reward\n",
    "      \n",
    "    elif action == 2 and signal_train[t] == -1: #Selling\n",
    "      reward = 1\n",
    "      total_profit += reward\n",
    "    \n",
    "    elif action == 0 and signal_train[t] == 0: #Selling\n",
    "      reward = 0\n",
    "      total_profit += reward\n",
    "    \n",
    "    elif action == 0 and signal_train[t] != 0: #Selling\n",
    "      reward = -1\n",
    "      total_profit += reward\n",
    "    \n",
    "    elif action != 0 and signal_train[t] == 0: #Selling\n",
    "      reward = -1\n",
    "      total_profit += reward\n",
    "      \n",
    "    if t == data_samples - 1:\n",
    "      done = True\n",
    "    else:\n",
    "      done = False\n",
    "      \n",
    "    trader.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    state = next_state\n",
    "    \n",
    "    if done:\n",
    "        time.sleep(0.2)\n",
    "        print(\"\\n\"+col.Fore.CYAN+\"########################\"+col.Fore.GREEN)\n",
    "        print(\"TOTAL PROFIT:  {} \".format(total_profit))\n",
    "        print(col.Fore.CYAN+\"########################\"+col.Style.RESET_ALL)\n",
    "        print()\n",
    "    \n",
    "    if len(trader.memory) > batch_size:\n",
    "      trader.batch_train(batch_size)\n",
    "      \n",
    "  if episode % 10 == 0:\n",
    "    trader.model.save(\"ai_trader_{}.h5\".format(episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### VERIFICATION DU PREDICT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(df_train.shape[1]))\n",
    "model.add(tf.keras.layers.Dense(units=64, activation='relu')) # , input_dim=self.state_size))\n",
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=3, activation='relu'))\n",
    "#model = tf.model({inputs: input, outputs: dense2})\n",
    "model.output_shape\n",
    "model.compile(optimizers.Adam(lr=0.001),loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[-8.07986406e-01, -4.24607155e-02,  7.20850086e-02,\n",
       "          7.17761557e-02,  9.38559010e-02,  7.33825445e-02,\n",
       "          1.00000000e+00, -9.95541401e-01, -9.68655923e-02,\n",
       "         -5.92381272e-02, -5.84250635e-02,  2.26923733e-02,\n",
       "         -3.06564479e-02, -9.61700747e-01, -9.58855098e-02,\n",
       "         -2.90933694e-02,  3.27332242e-04,  1.52162763e-02,\n",
       "         -5.42367007e-02]]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "np.array([state])"
   ]
  },
  {
   "source": [
    "### VERIFICATION DE LA GENERATION DES ACTIONS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "trader.trade(state)"
   ]
  },
  {
   "source": [
    "### VERIFICAYION BATCH"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'memory' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ab30bb47a3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'memory' is not defined"
     ]
    }
   ],
   "source": [
    "batch = []\n",
    "memory = df_train.iloc[:5000,:]\n",
    "for i in range(len(memory) - batch_size + 1, len(memory)):\n",
    "    batch.append(memory[i])\n",
    "\n",
    "    for state, action, reward, next_state, done in batch:\n",
    "        reward = reward\n",
    "    \n",
    "    if not done:\n",
    "        reward = reward + gamma * np.amax(model.predict(next_state)[0])\n",
    "\n",
    "    target = model.predict(state)\n",
    "    target[0][action] = reward\n",
    "\n",
    "    model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "if epsilon > epsilon_final:\n",
    "    epsilon *= epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### VERIFICATION INTEGRITE DES DATA => CORRESPONDANCE DF ET SIGNAL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load('BASES/EURUSD_m5')\n",
    "\n",
    "start_date = str(data.index[0]).split()[0]\n",
    "end_date = str(data.index[1]).split()[0]\n",
    "\n",
    "_sl = 0.001\n",
    "_target = 0.002\n",
    "\n",
    "# scaler = Normalizer()\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "def strategy(df):\n",
    "    ##### CONDITIONS LONG\n",
    "    _condition_1 = (df.slow_K5 < 20) & (df.slow_K5.shift(1) < df.slow_D5.shift(1)) & (df.slow_K5 > df.slow_D5)\n",
    "\n",
    "    ##### CONDITIONS SHORT\n",
    "    _condition_1_bar = (df.slow_K5 > 80) & (df.slow_K5.shift(1) > df.slow_D5.shift(1)) & (df.slow_K5 < df.slow_D5)\n",
    "\n",
    "    ##### 1 condition\n",
    "    df['Signal'] = np.where(_condition_1,1,np.where(_condition_1_bar,-1,0))\n",
    "    df = df.drop(['Symbol','Date','DateIndex','SB_Gamma'], axis=1)\n",
    "    return(df.sort_index(axis=0)) \n",
    "\n",
    "def strategy5(df,_window=40):\n",
    "\n",
    "    #df['RSI_2'] = TA.RSI(ohlc=df,int=2,str='Close')\n",
    "\n",
    "    df['Window_High_Ask'] = df.HighAsk.iloc[::-1].rolling(_window).max().iloc[::-1] # Limite SL Short\n",
    "    df['Window_High_Bid'] = df.HighBid.iloc[::-1].rolling(_window).max().iloc[::-1] # Limite Target Long\n",
    "    df['Window_Low_Ask'] = df.LowAsk.iloc[::-1].rolling(_window).min().iloc[::-1] # Limite Target Short\n",
    "    df['Window_Low_Bid'] = df.LowBid.iloc[::-1].rolling(_window).min().iloc[::-1] # Limite SL Long\n",
    "    df['Window_sl_Short'] = df.CloseBid + (df.CloseBid * _sl) # Short pour SL\n",
    "    df['Window_sl_Long'] = df.CloseAsk - (df.CloseAsk * _sl) # Long pour SL\n",
    "    df['Window_tp_Short'] = df.CloseBid - (df.CloseBid * _target) # Short pour TP\n",
    "    df['Window_tp_Long'] = df.CloseAsk + (df.CloseAsk * _target) # Long pour TP\n",
    "\n",
    "    ##### CONDITIONS LONG\n",
    "    _condition_1 = (df['Window_tp_Long'] <= df['Window_High_Bid']) & (df['Window_sl_Long'] <= df['Window_Low_Bid'])\n",
    "\n",
    "    ##### CONDITIONS SHORT\n",
    "    _condition_1_bar = (df['Window_tp_Short'] >= df['Window_Low_Ask']) & (df['Window_sl_Short'] >= df['Window_High_Ask'])\n",
    "\n",
    "    ##### 1 condition\n",
    "    df['Signal'] = np.where(_condition_1,1,np.where(_condition_1_bar,-1,0))\n",
    "    df = df.drop(['Symbol','Date','DateIndex','Window_High_Ask','Window_High_Bid','Window_Low_Ask','Window_Low_Bid','Window_sl_Short','Window_sl_Long','Window_tp_Short','Window_tp_Long'], axis=1)\n",
    "    return(df.sort_index(axis=0))\n",
    "\n",
    "\n",
    "data = klines(data)\n",
    "\n",
    "data = strategy(data)\n",
    "\n",
    "data = data[['Body','Color','UpperShadow','LowerShadow','Signal']]\n",
    "\n",
    "data['Body1'] = data['Body'] - data['Body'].shift(1)\n",
    "data['Body2'] = data['Body'] - data['Body'].shift(2)\n",
    "data['Body3'] = data['Body'] - data['Body'].shift(3)\n",
    "data['Body4'] = data['Body'] - data['Body'].shift(4)\n",
    "data['Body5'] = data['Body'] - data['Body'].shift(5)\n",
    "\n",
    "data['UpperShadow1'] = data['UpperShadow'] - data['UpperShadow'].shift(1)\n",
    "data['UpperShadow2'] = data['UpperShadow'] - data['UpperShadow'].shift(2)\n",
    "data['UpperShadow3'] = data['UpperShadow'] - data['UpperShadow'].shift(3)\n",
    "data['UpperShadow4'] = data['UpperShadow'] - data['UpperShadow'].shift(4)\n",
    "data['UpperShadow5'] = data['UpperShadow'] - data['UpperShadow'].shift(5)\n",
    "\n",
    "data['LowerShadow1'] = data['LowerShadow'] - data['LowerShadow'].shift(1)\n",
    "data['LowerShadow2'] = data['LowerShadow'] - data['LowerShadow'].shift(2)\n",
    "data['LowerShadow3'] = data['LowerShadow'] - data['LowerShadow'].shift(3)\n",
    "data['LowerShadow4'] = data['LowerShadow'] - data['LowerShadow'].shift(4)\n",
    "data['LowerShadow5'] = data['LowerShadow'] - data['LowerShadow'].shift(5)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "df_train, df_test, df_oos = split_df(data)\n",
    "\n",
    "df_oos_raw = df_oos.copy().dropna()\n",
    "\n",
    "df_train.sort_index(inplace=True)\n",
    "\n",
    "for i in df_train.columns.unique():\n",
    "    if i != 'Signal' and i != 'Color':\n",
    "        df_train[i] = scaler.fit_transform(df_train[i].values.reshape(-1, 1))\n",
    "        df_test[i] = scaler.fit_transform(df_test[i].values.reshape(-1, 1))\n",
    "        df_oos[i] = scaler.fit_transform(df_oos[i].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "signal_train = df_train['Signal']\n",
    "signal_test = df_test['Signal']\n",
    "signal_oos = df_oos['Signal']\n",
    "\n",
    "df_train = df_train.drop(['Signal'],axis=1)\n",
    "df_test = df_test.drop(['Signal'],axis=1)\n",
    "df_oos = df_oos.drop(['Signal'],axis=1)\n",
    "\n",
    "df_oos = df_oos.reindex(natsorted(df_oos.columns), axis=1)\n",
    "df_test = df_test.reindex(natsorted(df_test.columns), axis=1)\n",
    "df_train = df_train.reindex(natsorted(df_train.columns), axis=1)\n",
    "df_oos_raw = df_oos_raw.reindex(natsorted(df_oos_raw.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         Body    Body1     Body2     Body3     Body4  \\\n",
       "2010-01-04 04:15:00 -0.960918 -0.07556 -0.005744 -0.010341  0.004273   \n",
       "\n",
       "                        Body5  Color  LowerShadow  LowerShadow1  LowerShadow2  \\\n",
       "2010-01-04 04:15:00  0.004487      1    -0.978981     -0.107845     -0.026682   \n",
       "\n",
       "                     LowerShadow3  LowerShadow4  LowerShadow5  UpperShadow  \\\n",
       "2010-01-04 04:15:00     -0.048264      0.014844     -0.031656    -0.998702   \n",
       "\n",
       "                     UpperShadow1  UpperShadow2  UpperShadow3  UpperShadow4  \\\n",
       "2010-01-04 04:15:00     -0.106977     -0.019959     -0.002619      0.019661   \n",
       "\n",
       "                     UpperShadow5  \n",
       "2010-01-04 04:15:00     -0.039335  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Body</th>\n      <th>Body1</th>\n      <th>Body2</th>\n      <th>Body3</th>\n      <th>Body4</th>\n      <th>Body5</th>\n      <th>Color</th>\n      <th>LowerShadow</th>\n      <th>LowerShadow1</th>\n      <th>LowerShadow2</th>\n      <th>LowerShadow3</th>\n      <th>LowerShadow4</th>\n      <th>LowerShadow5</th>\n      <th>UpperShadow</th>\n      <th>UpperShadow1</th>\n      <th>UpperShadow2</th>\n      <th>UpperShadow3</th>\n      <th>UpperShadow4</th>\n      <th>UpperShadow5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2010-01-04 04:15:00</th>\n      <td>-0.960918</td>\n      <td>-0.07556</td>\n      <td>-0.005744</td>\n      <td>-0.010341</td>\n      <td>0.004273</td>\n      <td>0.004487</td>\n      <td>1</td>\n      <td>-0.978981</td>\n      <td>-0.107845</td>\n      <td>-0.026682</td>\n      <td>-0.048264</td>\n      <td>0.014844</td>\n      <td>-0.031656</td>\n      <td>-0.998702</td>\n      <td>-0.106977</td>\n      <td>-0.019959</td>\n      <td>-0.002619</td>\n      <td>0.019661</td>\n      <td>-0.039335</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df_train.iloc[46:47,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "signal_train.iloc[46] # 8, 16, 22, 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2010-01-04 04:15:00   -1\n",
       "Name: Signal, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data.iloc[46:47,:].Signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}